# ğŸ“º èª°ã‚‚æ°—ã¥ã„ã¦ã„ãªã„ï¼ˆGoogleã‚’é™¤ã„ã¦ï¼‰

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: no one sees it coming (except Google)
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=LQfSfVFc4Ss](https://www.youtube.com/watch?v=LQfSfVFc4Ss)
- **å‹•ç”»ID**: LQfSfVFc4Ss
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ11æ—¥ 14:41
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã§ã¯ã€GoogleãŒé™ã‹ã«ç™ºè¡¨ã—ã¦ã„ã‚‹è¤‡æ•°ã®é©æ–°çš„ãªç ”ç©¶è«–æ–‡ã‚’ç´¹ä»‹ã—ã€ãªãœGoogleãŒAIç«¶äº‰ã®æœ€çµ‚çš„ãªå‹è€…ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ã‚’è§£èª¬ã—ã¦ã„ã¾ã™ã€‚AIæ¥­ç•ŒãŒç›´é¢ã™ã‚‹æœ€å¤§ã®èª²é¡Œâ€”ãƒãƒƒãƒ—ä¸è¶³ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼å•é¡Œã€ç¶™ç¶šå­¦ç¿’ã€åç›Šæ€§â€”ã®ã™ã¹ã¦ã«å¯¾ã—ã¦ã€GoogleãŒå…·ä½“çš„ãªè§£æ±ºç­–ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ç‰¹ã«ã€Œãƒã‚¹ãƒ†ãƒƒãƒ‰ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã«ã‚ˆã‚‹ç¶™ç¶šå­¦ç¿’ã®å®Ÿç¾ã€ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸå‰µè–¬AIã€ŒGemmaã€ã€å®‡å®™AIãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼è¨ˆç”»ã€ãã—ã¦ç‹¬è‡ªTPUãƒãƒƒãƒ—ã«ã‚ˆã‚‹Nvidiaä¾å­˜ã‹ã‚‰ã®è„±å´ãªã©ã€é•·æœŸçš„ãªæˆ¦ç•¥ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã™ã€‚AIç ”ç©¶è€…ã€æŠ•è³‡å®¶ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ¥­ç•Œã«é–¢ã‚ã‚‹å…¨ã¦ã®äººã«ã¨ã£ã¦ã€Googleã®åŒ…æ‹¬çš„ãªAIæˆ¦ç•¥ã‚’ç†è§£ã™ã‚‹ä¸Šã§å¿…è¦‹ã®å†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **ç¶™ç¶šå­¦ç¿’ã®å®Ÿç¾**: ã€Œãƒã‚¹ãƒ†ãƒƒãƒ‰ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã¨ã„ã†æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã‚ˆã‚Šã€AIãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®ç¥çµŒå¯å¡‘æ€§ã®ã‚ˆã†ã«ç¶™ç¶šçš„ã«å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚ŠLLMã®æœ€å¤§ã®åˆ¶ç´„ãŒè§£æ¶ˆã•ã‚Œã‚‹å¯èƒ½æ€§
- **ç”Ÿç‰©å­¦çš„AI (Gemma)**: 270å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãŒã€å˜ç´°èƒãƒ¬ãƒ™ãƒ«ã®ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ã‚’ç†è§£ã—ã€æ–°ã—ã„ãŒã‚“æ²»ç™‚æ³•ã®å€™è£œã‚’ç™ºè¦‹ã€‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ãŒç”Ÿç‰©å­¦ã«ã‚‚é©ç”¨ã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼
- **åç›ŠåŒ–ã®é“ç­‹**: å‰µè–¬ã€ç–¾æ‚£æ²»ç™‚ã€ææ–™ç§‘å­¦ãªã©ã€AIã‚’æ´»ç”¨ã—ãŸç§‘å­¦çš„ç™ºè¦‹ã«ã‚ˆã‚Šæ•°å…†ãƒ‰ãƒ«è¦æ¨¡ã®å¸‚å ´ã‹ã‚‰åç›Šã‚’å¾—ã‚‹å…·ä½“çš„ãªæˆ¦ç•¥ã‚’æŒã¤
- **å®‡å®™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼è¨ˆç”»**: 2027å¹´ã«ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—æ‰“ã¡ä¸Šã’ã€2035å¹´ã¾ã§ã«åœ°ä¸Šã¨åŒç­‰ã‚³ã‚¹ãƒˆã§ã®å®‡å®™AIãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å®Ÿç¾ã‚’ç›®æŒ‡ã™ã€‚ã‚¨ãƒãƒ«ã‚®ãƒ¼å•é¡Œã‚’æ ¹æœ¬çš„ã«è§£æ±º
- **TPUãƒãƒƒãƒ—æˆ¦ç•¥**: ç¬¬7ä¸–ä»£TPUã€ŒIronwoodã€ã«ã‚ˆã‚Šã€Nvidiaã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã—ã€AIå°‚ç”¨ãƒãƒƒãƒ—å¸‚å ´ã§ç«¶äº‰åŠ›ã‚’ç¢ºç«‹ã€‚Anthropicã¸ã®ãƒ¬ãƒ³ã‚¿ãƒ«æä¾›ã‚‚é–‹å§‹æ¸ˆã¿

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

These are the founders of the hottest AI startup in the Bay Area. Their names are Sergey Brin and Larry Page. And yes, they founded Google. Everyone knows Google. Here's what you don't know.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

There were a few papers published by Google just in the last month or so that really give us a glimpse into where they're going. The impacts of these papers should be massive. This is not clickbait. This is not hype. The implications of this papers are staggering.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

However, this just gets lost in the noise of AI news and everything that's happening. In this video, I'll show you what Google is quietly publishing. These are papers that most people missed. And I'll also show you why the next Google just might be Google and the other Frontier AI labs might be Cooked. Now, I know that's a very bold claim, but I'll show you why it's not absolutely insane.

### ğŸ“ è©³ç´°èª¬æ˜

Now, you may have seen that Michael J. Bur shorted the living Jesus out of Nvidia and Palanteer. A lot of people are talking about a bubble. Michael J. Bry, by the way, is the guy that shorted the 2008 2009 housing market crash and did really, really well for himself.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

He just nailed that call and a lot of people listen to him when he's shorting something or pointing out certain bubbles or things that are about to pop. He doesn't always get them right, but when he does, it's pretty spectacular. So, with that in mind, what are the biggest issues that are stopping AI progress? Number one is chips, compute, GPUs. We have a limit in how much we can produce.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

Nvidia is getting very, very wealthy from this shortage and they're selling GPUs like hotcakes. Number two is energy, aka electricity. We're not producing anywhere near the amount of electricity we need to power all these AI data centers. These two, you can probably reverse them depending on how you look at it. Energy might be the biggest problem.

### ğŸ¯ å¿œç”¨ä¾‹

Next is continuous learning. This is the big stumbling block with large language models. In fact, at this point, Demi Hassabus and lots of other leaders in the AI space basically said that without continuous learning, these models won't ever be truly useful. It's like if you have a brilliant co-worker that just immediately forgets any new information. He can't remember your name, where he sits, he's completely incapable of retaining any new skills or data or knowledge that he learns.

### ğŸ’­ è€ƒå¯Ÿ

How useful is that person? I mean, they're probably still pretty useful if they're smart. They know a lot of things. They can draw on their past knowledge. They're still useful just like a large language model can be extremely useful.

### ğŸ“Œ ã¾ã¨ã‚

But without that ability to keep learning, it's just severely limited. That's where LLMs are right now. Without continuous learning, well, we won't really crack AGI. And finally, we have profit, revenue, income. A lot of people are saying that the capital expenditures of these AI labs, the amount of money that they're spending on chips and factories and AI data centers is is staggering, right?

### âœ… çµè«–

It's in the trillions. Now, how are they going to make that money back? How are they going to make profit or revenue or income on these AI technologies? Each one of these is kind of an open problem. Who's going to be the one to step up and solve these issues?

### ğŸ“š è¿½åŠ æƒ…å ±

Google might have already solved them all. Now, that might be a little bit hyperbolic. They didn't solve them completely, but I'll show you why they have been working on them and why these just might be solved by Google within the next few years. Have you ever wished you could literally talk to your codebase? Like, you just tell your site, add a checkout page, make it dark mode, and fix the layout, and it just happens.

### ğŸ”– è£œè¶³

That's exactly what Matter from Jet Brains, the sponsor of today's video, does. It's an AI development companion that lets you prototype directly in the real codebase. No coding required. Most AI builders out there stop at mockups or quick demos. Matter goes further.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

It actually works inside your repo. So if you're a product designer or a PM, you can open matter, connect your GitHub project, and start changing the real app by chatting just like you would with Chad GBT, except now you're changing the live code and seeing it update instantly in the preview. Let me show you how. Here's a simple e-commerce store. Our checkout abandonment rate is rather high.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Matter gets to work, making this into a single page checkout. Checkout flow redesigned as a single page. And instantly, there it is. The UI updates right beside the chat window. I can test it, click through, and if I like it, can even create a GitHub pull request directly from Matter.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

Everything happens in an isolated environment so my production code stays safe. And because it's collaborative, I can invite team members right into the same chat. We can tweak colors, layouts, or flows together live and share the preview like a Figma file. Matter basically kills the handoff problem. No more endless back and forth between design and engineering.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Designers and PMS can build prototypes with real data. Developers get clear context, generated code, and documentation they can merge instantly. If you're tired of throwaway prototypes and want to move straight from idea to real app, check out Matter by Jet Brains. It's the AI development companion that helps teams build twice as fast. You can try it right now using the link in the description.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Let's start with continuous learning. Google recently published this paper just a few days ago introducing nested learning, a new machine learning paradigm for continual learning. So what we're talking about here is something that's similar to how the human brain processes and stores information. We refer to it as neuroplasticity or at least that's one of the important processes that allow us to do all the wonderful things that we do. As Google states here, when it comes to continual learning and self-improvement, the human brain is the gold standard.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

It adapts through neuroplasticity, the remarkable capacity to change its structure in response to new experiences, memories, and learning. Without this ability, a person is limited to the immediate context. Kind of like antagrade amnesia. Antrograde amnesia is the inability to create new memories after an event that caused amnesia. So you're continuously forgetting all the new information that's coming in.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

You're just not able to store it. You can rely on your past experiences and you can kind of rely on the short-term kind of context that's in front of you. Like if you're having a conversation, you you might be able to keep up with the conversation, but once you get outside of that sort of a context window, you can no longer recall those details. And they're saying we see a similar limitation in current LLMs. their knowledge is confined to either the immediate context of their input window or the static information that they learned during pre-training.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So this new approach the nested loops you can almost think of it as quick fast inside loops right these go very very fast and they update continuously or quickly. This is kind of like shortterm memory. Those are like the red quick inside loops. And you have these longer loops that update not as frequently and they run slower. This is like the longterm memory.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

So they are kind of operating at different time scales. This unifies kind of the architecture of these models as well as the optimization of these models under kind of one umbrella. By the way, the people behind this paper, these are the same researchers that proposed the Titans architecture, learning to memorize at test time. Google has a group of researchers that seemingly are approaching potentially cracking this problem of continuous learning. Not only that, but they're publishing the results and they've tested this approach, this nested learning through a proof of concept self-modifying architecture they call hope.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So basically this is showing that potentially we'll have large language models that will be capable of learning on the job if you will kind of a big deal. Okay. So let's say we're approaching potentially cracking this continuous learning problem. Google seems to have some architectures some approaches in place that may in the future let these large language models learn on the job. That's great.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

So what how do we turn that into printing money? We like money. We like profit. How does that make us money? Here's something that I think a lot of people don't understand about these AI models.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

These models are tokens in and then tokens out. We put tokens in, we take tokens out. So tokens in is the data. It's the data that we feed into it. And tokens out are predictions.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So right now when we think about AI, the most common thing that we know about is large language models where tokens are words, right? So we take words, we tokenize them and we feed them into this AI model, the large language model and those words are basically the entire internet textbooks just everything everything that humans have written. We feed it into it and we train it to predict the next token that comes out. This is why people often times will try to dismiss these AI models. Large language models are just advanced autocomplete, next word prediction.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

Now, if you've been following my channel, I've often complained about this take, saying it's not a very good take. It's not a very smart take. It's it's probably not correct. Or if it's correct technically, then it's still meaningless because obviously these models are doing a lot more than just statistically predicting the thing that comes next. There's a paper out of hardware, for example, showing that they build something that can be thought of as mental models in order to be better able to predict what the output should be.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

And there's even more confirmation now. So this is yet another research paper from Google. Shockingly, are you surprised? Google's doing also fundamental research into how this stuff works. They're saying LM don't just memorize.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

They build a geometric map that helps them reason. So the people that don't really believe in the power of LMS or whatever you want to call it that think it's just a stochastic parrot. Their big sort of counterargument is well, they're just predicting the next word. So if I say I like my coffee with sugar and right they they look at all the text that they've seen and just based on statistics they're like oh so the next word would be I forget why I said sugar and cream right so they're just making an association between those words so they're able to predict what comes next. Well I'm I'm really sorry to say that that theory is just blown out of the water by this paper.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

So they're saying here that transformers, so kind of the architecture of these large language models, their reasoning that is incompatible with memory as strictly a storage of the local co-occurrences specified during training. So in our in our coffee and cream and sugar example, it's not that they're just memorizing coffee and cream and sugar, how they go together, those kind of local cluster of concepts like, oh, if they're talking about coffee, then what are other words that are sort of statistically relevant? Well, sugar and cream and those things are kind of clustered together and and that's how it knows that, you know, when you say coffee, it thinks, oh, maybe we talk about sugar and cream. So, that would be a local relationship, right? But they're saying here that their findings show that this explanation is incompatible with what they're seeing.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

So, the idea that just clustered local pairs, that that's not doesn't seem to be what's happening. Instead, the model must have somehow synthesized its own geometry of atomic facts, encoding global relationships between all entities, including non-co. This in turn has simplified a hard reasoning task involving let's say a complex sequence or ways of connecting two facts into an easy tolearn onestep task. So how we visualize how these AIs store information and they're in these like vector relationships between different words, right? So man has some relationship to the word woman.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

King has some relationship to the word queen. And if I asked you like a question like a man is to a woman as a king is to a right and I left this blank. You would be able to guess what this is based on the relationship of these two but also kind of the the relationships of this vector and and this vector of meaning. And this is kind of a good simple way to kind of illustrate how they sort of map meaning onto words. Each word is connected to other words that are related.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

That's what we thought. What this paper seemingly shows that each word or each knowledge cluster is connected to all other knowledge clusters or all other concepts or as they call it here atomic facts. These models encode global relationships between all entities including non-co. So these would be co-occurring ones. Right?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

So yes, it has a some relationship between man and woman, king and queen, but also each one of these is connected to everything else. So I think a good way of thinking about this is each star in the universe has some relationship to another star like the distance in 3D space, right? So you can kind of say how far they are apart in which direction. So there's kind of a a vector connecting them. Vector is like distance plus magnitude.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

So it's over there far away kind of as a vector and each star you can make a vector between it and every other star in the universe. You can describe the relationship between all of the stars not just ones that are clustered together that share some sort of meaning or co-occurrence just to everything. So coming back to our words and tokens you know tokens in tokens out right so right now we tend to think of them as tokens. In fact, a lot of people out there that don't really follow AI, they think of AI as the sort of the output, whatever it is, right? So, you make a an image of something, they're like, "That's AI." Or, you know, it's a chatbot, that's AI.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

And if the image is good, right, they're like, "Oh, AI is good." And if the image is bad, they're like, "Oh, AI is bad." That's kind of like judging how valuable electricity is based on how well one particular light bulb works, right? This light bulb kind of sucks. It's flickering. Therefore, electricity as just a an invention as a as a concept. Like all of it is just bad, right?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

That's kind of a silly take to have. AI is taking massive amounts of data and using computers to compress them so that it forms these relationships between all of these little data points. And then we can ask it questions about how those different points are interconnected. And we can pretty much do this with anything, assuming we we we have enough data. Why is that important?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Well, in part because of this recent Google paper released October 15th, 2025, less than 1 month ago, saying how a JAMA model helped discover a new potential cancer therapy pathway. So, this is a new 27 billion parameter foundation model designed to understand the language of individual cells. So, Gemma, you might have heard. So there's other large language models under the Gemma family of umbrellas. They are open source and they're language models, right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So they're tokens in, tokens out, but our tokens, they're words. That makes it a large language model, right? Words, large language model. But here's the thing. It doesn't have to be words.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

It can be DNA. It can be proteins. It can be biology. It can be anything. It doesn't have to be words.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

that same architecture, if you feed enough stuff into it, it can start predicting useful information about that stuff. So in this case, in this example, they're taking this large language model and they're training it on a corpus comprising of over 1 billion tokens of transcripttoic data, biological text, and metadata. So this is a single cell RNA sequencing, etc. So the point is you don't have to understand what exactly this is. The point is that we have a bunch of sort of letters that make up sentences and those sentences tell us how our bodies work, right?

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

I mean that's kind of how DNA works, right? You have letters, you have sentences and that creates this and that encodes how we are made, how we exist, etc. Amino acids are also you can think of them as you know words or sentences. They make up proteins. That's kind of the building blocks of life kind of works very similar to again words and sentences in you know the language that we speak.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

This is not too dissimilar right. So instead of words right so we take words and then this thing predicts how a sentence gets completed or how to answer a question. We can feed it like life. All right. So the sequenced DNA the sequence of amino acids.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

We can feed that into the AI and then get predictions about what? Well, in this case, how to treat cancer, but also think about it for anything, how to treat any disease, how to create any drug, how to modify any biological process potentially. So, why is that important? Well, we know that as we scale these models up, they get better at certain tasks. So, this is large language models, right?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

On various different tasks. This black line here, that's the human level, right? So as we scale them up, they sometimes cross the human level, right? So more data, bigger models, those are kind of the the scaling laws. Scale them up enough, they get better than humans at certain tasks and potentially superhuman and on.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

So with this Gemma model, they asked it to find a very specific treatment for cancer under certain very specific conditions. So it was kind of like a very complicated question, right? So instead of asking it like what is 2 plus 2 which is a very simple question that even a small model can answer they're saying solve this very complicated puzzle with these specific constraints and it does it creates some novel approaches that could be potentially new pathways for developing cancer therapies to fight cancer. Why is that important? Because they're saying we demonstrate that biological models follow clear scaling laws just like with natural language.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

larger models perform better on biology. The question is, do they just get better at existing tasks or can they acquire entirely new capabilities? Well, the thing that they were able to find, well, this required a level of conditional reasoning that appeared to be an emergent capability of scale. Our smaller models could not resolve this context dependent effect. So that means that these biological models kind of work just the same that these large language models do.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

So just like this approach can get it really good at coding or writing stories or whatever even things like math and science but we can also apply that to just about anything where we have data right so we can put in you know how life works and ask questions about okay sort of based on this how do we create a cancer treatment how do we solve this disease how do we create this drug so we put data in whatever type of data that is and we get predictions out and these could be images, right? And we get things like midjourney that creates beautiful images. We can put music in and we get something like sunno that can create beautiful music. LMS create words and uh math proofs etc. They have this general reasoning abilities.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

Google used these models to help them with their quantum research. Some sort of a quantum correcting mechanism, right? So we feed in the data on quantum fluctuations and it helps us predict these quantum fluctuations. Alpha fold it learned to predict the 3D structure of proteins that Gemma model right. So we fed in I'm not exactly sure what they did.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

So it's some sort of a cell sequences plus biological data like tons of stuff that they fed in and now it's spitting out candidates for therapy treatments under these like very specific conditions. So some pretty complicated stuff with things like Alpha Valve from Google. We've seen it create better hardware. We've seen it optimize data centers. So ask yourself this question.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

If these systems, these large language models that we're working on and doing a lot of research into and improving, if they could be also used, you know, in a little bit different format like this Gemma model, right? Still the same kind of large language model structure, but it's fed in biological data. So, if we could use that same technology to make better drugs, to solve disease, to create better building materials, to create better energy sources, to create better business plan, like there's not a limit to uh how much it can do, but what Google's focusing on right now quite a bit is the medical side of it, drug discovery, etc. If they were able to discover better drugs faster, solve all sorts of diseases, maybe at some point even expand human lifespan. Do you think they could make a buck or two off of these models?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

I think so. So, next two things, chips and energy. Let's talk about energy. I've covered this at length in a different video, but there's this thing called Project Suncatcher. This is Google's mission to put AI data centers in space.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

In space, the solar panels can take in a lot more energy, right? There's no day and night cycle if you're in the right orbit, right? Sun shines 24 hours a day. Also, if you think about the fact that if we keep 10xing how much energy we produce, even if we find some good approach, some efficient approach to doing that, eventually just the amount of heat that we're dumping into our atmosphere, becomes a problem. So, we can't just keep 10xing it even if there's some really cheap energy source.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

Putting out in space greatly solves that problem. Like, you can dump a lot of heat in space without an issue. In this paper, and again, I covered in a different video if you want to watch, but basically they go line by line and they're like, how realistic is this? And they show us line by line that it's very realistic. Space radiation is not a problem.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

Energy efficiency is not a problem. transferring data between these uh solar powered satellites is not a problem. They they have a solution to every single problem. The only problem right now is this that if you build a power plant here on Earth, you know, it's going to cost you this much per unit of electricity, let's say. And if you build these power centers in space, right, it's going to cost you many, many times more.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

Like so much more. It's not really feasible to do it, right? It's a lot more expensive to send stuff up there and build everything there. The reason it's so expensive is because of the price per kilogram for sending stuff into low Earth orbit. Right?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

So, right now, this number is like $1,500 per kilo to send the stuff needed to space in order for this to be the same as building a factory on Earth. That has to be $200 per kilo. So, 1,500, we need to get it to 200. So, not quite feasible yet. But guess what?

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

Based on current projections, this will hit this number by 2035. So if all the assumptions are correct, by 2035, it will be the same price to build AI data centers with their own energy sources. So you don't need a separate power plant. It's all in one self-powered AI data center, training these models, doing inference, and just beaming everything back to Earth. That'll be the same price kind of per unit of electricity as building this on Earth by 2035.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

And by 2027, you know, in a year and change, Google is sending an actual prototype of two satellites into space to test this out like in reality. So really, they kind of have a solution planned for energy. Now, you might be saying, "Yeah, but that's not, you know, anytime soon. Who cares? those 5 years, 10 years, they will pass.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

These issues, these problems, they will still exist. Google isn't trying to win this year or next year or 3 years from now. It's like that saying, he who laughs last the hardest. Is that the saying? Basically, it doesn't matter how much you win in the short term.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

You just want to be the winner at the end. Google is setting up to be the winner at the end of this race with enough energy to power their data centers with continuous learning models with profitable models that they can make billions and perhaps trillions of dollars with. I mean, if you're solving all disease, how much money do you think that's worth? You can probably make a buck or two off of that. So, everything comes down to chips.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

Does this mean that Nvidia just becomes a super mega wealthy off of the back of Google because they're the supplier chips? Well, not quite. Google has some very impressive chips. Recently, they have announced the seven of generation TPU Ironwood. Even Elon Musk is impressed by their ability to make these chips.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

Will Google start selling their TPUs and compete with Nvidia? We're not sure, but yes. Yes, they will. In fact, they already have a deal with Anthropic that allows them to rent those chips out to Anthropic for their purposes. Very likely, they're not going to sell them kind of like Nvidia does to where you can just like take it home and install it somewhere.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

It's probably going to be mostly through the cloud with all that infrastructure built in. So, you're just like renting them for your needs. So, more of a closed kind of ecosystem. Out of all the options on the market today, TPUs are the closest alternative to Nvidia's GPUs. And TPUs are specialized for machine learning and AI workloads.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

In the right application, they can deliver significantly better performance per dollar compared to GPUs, requiring much less energy and producing less heat. And we believe that Google is at least 2 years away because they're building the ecosystem, right? So, they're not trying to announce before they're ready. By the time they announce this initiative, they're going to have massive capacity. They're going to have everything just humming along optimized, you know, no bugs, no issues.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

TPUs are also, it sounds like, according to this person, are becoming more multimodal. They're not only used for training, but effective at both training and inference. Google might become a very serious competitor to Nvidia. That's what makes it different from XAI, OpenAI, Anthropic, all the Chinese labs, everybody else in the game of training up models. there's only one model that has behind it a fairly serious chip, you know, manufacturer, designer, etc.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

And that AI model is Gemini and the company is Google. So, I hope you see now that the biggest issues facing a lot of these frontier AI labs, Google has solutions to them. So, I'm not saying problem solved quite yet, but they have a roadmap to achieving them in the future. They have the capital, the money to achieve it in the future. They have the the resources, the infrastructure to create all the chips that they might need, plus sell them to other players.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

They have a very interesting kind of medium to long-term solution for energy issues specifically for data centers, right? So, if they're doing that, it's not going to affect our energy bill. It's not going to take away from the capacity of power plants here, you know, on the planet. And it's not going to heat up the atmosphere if we keep 10xing our need for energy. Now, that energy production is limited to anything that we can put out of space.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

Right now, we can't really beam energy back to the planet. I mean, there's some proposals for using um microwave energy to generate energy in space and then beam it back to the planet. But that's also a little bit scary, right? That could be used as a weapon or like what if you miss it? It just sounds like a problem.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

Imagine just beaming tons of energy at the Earth's surface. I mean, that's kind of literally the Death Star, right? But for anything that we can put out in space, assuming it's cheap enough to launch stuff up there, it's it's probably going to be a lot cheaper to just have it generate energy in space. The sun is a massive source of free energy if we can just harvest it. By the way, can you tell what this is an image of?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

Take a look at it. I know it's a little bit blurry, but could you describe what it is? I'll give you a hint. It's a satellite image. So, it's an image from space.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

So, what are you looking at? What is this line here? This centerpiece. It's kind of hard to tell, but it's a river, right? You can maybe kind of guess at it.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

So, interestingly, Gemini 2.5 is pretty good at identifying these images, like images from space. We give it satellite data and it kind can figure out what is agriculture versus a river versus a forest versus a population center. It couldn't get this one, but I think it makes sense why. It's kind of hard to understand what you're looking at, but the scientists at Google, you guessed it. So, this is unlocking a multi-spectral data with Gemini, they decided to test it if it could become better at figuring out these satellite images with uh well, if if it could see more colors than we do.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

What if you could give your AI superhuman vision? What if it could see in wavelengths invisible to the human eye to understand the world in a fundamental new way? And thanks to Gemini, you don't need a customtrained specialized model anymore. You can start analyzing complex satellite data right out of the box. Simply by giving Gemini 2.5 the same model we have access to, not some specially trained model, but you give it access to that multisspectrum vision data.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

All of a sudden starts classifying these things a lot better. Now, how does this affect Google's stock price? Are we in a bubble? Is there going to be a correction? I have no idea.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

I love the quote in the Wolf of Wall Street. And that is a number one rule of Wall Street. Nobody, and I don't care if you're Warren Buffett or if you're Jimmy Buffett, nobody knows if a stock is going to go up, down, sideways, or in circle. It's a fugazi. It's a wazi.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

It's a woodsy. It's a fairy dust. It doesn't exist. So, are stocks going to go up? Are they going to go down?

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

Are they going to go all over the place? I don't know. I don't really care. And I'm not really talking about stock prices here. what I'm seeing and let me know what you think about this.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

But I'm definitely seeing that Google is kind of beginning to snowball. It's thinking long term and it's building out the AI infrastructure, solar power AI data centers in space, continuous learning models, the massive amounts of chips needed to run training, to run inference. Specifically, those chips are created for machine learning and AI, not sort of general parallelization use. GBS are great for everything. TPUs are more tailored for AI.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

[snorts] And at the same time, they're beginning to start that drug discovery process, you know, trying to work with pharmaceutical companies. They're planning at least 20 years in the future thinking about where is this heading? Let's start building the infrastructure we need to get there. So keep that in mind as people are talking about the bubble and whether or not chatbots are going to displace all workers and if chatbots are going to be able to make trillions of dollars. This post going to make me crack up inside you.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

There are two walls. One is AI is a bubble and two is no one is pricing in AGI. Point being is AI and AGI that's coming. All the insane scientific and technological progress that comes with it that's coming. Are the stock price charts between a now and then?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

Are they going to be a straight line or a squiggly one? I don't know. And I don't care. A lot of people seem to think that if the AI bubble pops, then AI is just ceases to exist. It goes away, disappears.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

Whatever happens, that is not happening. So, pay attention. I hope you enjoyed this one. Please make sure you like and subscribe. My name is Wes Roth.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
