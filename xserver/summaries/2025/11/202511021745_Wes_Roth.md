# ğŸ“º LLMã¯æ¨è«–ã§ããªã„ã®ã‹ï¼Ÿ

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: LLMs can't reason
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=VJUK_NIma6Q](https://www.youtube.com/watch?v=VJUK_NIma6Q)
- **å‹•ç”»ID**: VJUK_NIma6Q
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ02æ—¥ 17:45
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã§ã¯ã€ã€ŒAIã¯æœ¬å½“ã«æ¨è«–ã§ãã‚‹ã®ã‹ï¼Ÿã€ã¨ã„ã†è­°è«–ã®æœ¬è³ªã«è¿«ã‚Šã¾ã™ã€‚å¤šãã®äººãŒã€ŒLLMã¯å˜ãªã‚‹æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬å™¨ã€ã¨ã„ã£ãŸã€Œã‚¸ãƒ£ã‚¹ãƒ†ã‚£ã‚ºãƒ ï¼ˆjust-ismï¼‰ã€ã®ç½ ã«é™¥ã‚Šã€æ„Ÿæƒ…çš„ãªåè«–ã‚’å±•é–‹ã—ã¦ã„ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚æ™‚è¨ˆã®ä»•çµ„ã¿ã¨åŒæ§˜ã«ã€ã€Œä½•ã§ã§ãã¦ã„ã‚‹ã‹ã€ã§ã¯ãªãã€Œä½•ãŒã§ãã‚‹ã‹ã€ã‚’å®¢è¦³çš„ãªãƒ†ã‚¹ãƒˆã§æ¤œè¨¼ã™ã¹ãã ã¨ä¸»å¼µã—ã€AIæ‰¹åˆ¤ã®èƒŒå¾Œã«ã‚ã‚‹ææ€–å¿ƒç†ã‚’åˆ†æã—ã¦ã„ã¾ã™ã€‚æŠ€è¡“è€…ã‚„AIæ‡ç–‘è«–è€…ã«ã€ã‚ˆã‚Šè«–ç†çš„ã§å»ºè¨­çš„ãªè­°è«–ã‚’ä¿ƒã™å†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **ã€Œã‚¸ãƒ£ã‚¹ãƒ†ã‚£ã‚ºãƒ ã€ã¯è«–ç†çš„èª¤è¬¬** - ã€ŒLLMã¯å˜ãªã‚‹çµ±è¨ˆçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã€ã€Œè„³ã®åŒ–å­¦åå¿œãŒãªã„ã‹ã‚‰æ€è€ƒã§ããªã„ã€ã¨ã„ã£ãŸã€Œjust a...ã€ã®ä¸»å¼µã¯ã€æ­¯è»Šæ™‚è¨ˆãŒã€Œå˜ãªã‚‹é‡‘å±ç‰‡ã€ã§ã‚‚æ™‚é–“ã‚’æ¸¬ã‚Œã‚‹ã“ã¨ã‚’ç„¡è¦–ã—ãŸèª¤ã£ãŸè«–æ³•
- **èƒ½åŠ›ã®è¨¼æ˜ã«ã¯å®¢è¦³çš„ãƒ†ã‚¹ãƒˆãŒå¿…è¦** - 4åˆ†ãƒã‚¤ãƒ«ã®ä¾‹ã®ã‚ˆã†ã«ã€ä¸€ã¤ã®æˆåŠŸä¾‹ãŒã‚ã‚Œã°èƒ½åŠ›ãŒè¨¼æ˜ã•ã‚Œã‚‹ã€‚é€†ã«ä½•ç™¾ä¸‡å›ã®å¤±æ•—ä¾‹ã‚’ç¤ºã—ã¦ã‚‚ã€ãã®èƒ½åŠ›ãŒãªã„ã“ã¨ã¯è¨¼æ˜ã§ããªã„
- **AIæ‰¹åˆ¤ã®èƒŒå¾Œã«ã¯ææ€–å¿ƒãŒã‚ã‚‹** - çŸ¥æ€§ã‚’äººé–“ã®ä¾¡å€¤ã®ä¸­å¿ƒã«ç½®ãäººã€…ã«ã¨ã£ã¦ã€AIã®çŸ¥çš„èƒ½åŠ›å‘ä¸Šã¯å­˜åœ¨æ„ç¾©ã®è„…å¨ã¨ãªã‚Šã€éè«–ç†çš„ã§æ„Ÿæƒ…çš„ãªåå¿œã‚’å¼•ãèµ·ã“ã™
- **ã‚´ãƒ¼ãƒ«ãƒã‚¹ãƒˆã¯å¸¸ã«ç§»å‹•ã™ã‚‹** - ãƒã‚§ã‚¹ã€ç”»åƒèªè­˜ã€Goãªã©ã€AIãŒé”æˆã™ã‚‹ãŸã³ã«ã€Œãã‚Œã¯çœŸã®çŸ¥æ€§ã§ã¯ãªã„ã€ã¨åŸºæº–ãŒå¤‰æ›´ã•ã‚Œç¶šã‘ã¦ããŸæ­´å²ãŒã‚ã‚‹
- **AIã‚¢ãƒ¼ãƒˆæ‰¹åˆ¤ã‚‚åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³** - äººã€…ã¯ç›²ç›®ãƒ†ã‚¹ãƒˆã§AIç”Ÿæˆä½œå“ã‚’å¥½ã‚€ãŒã€AIè£½ã¨çŸ¥ã‚‹ã¨æ€¥ã«ã€Œé­‚ãŒãªã„ã€ã€Œæ·±ã¿ãŒãªã„ã€ã¨ã„ã£ãŸæ–°ã—ã„è©•ä¾¡åŸºæº–ã‚’ä½œã‚Šå‡ºã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Today, let's talk about the most frustrating discussion in AI circles, at least to me. That is, can LMS think? Can they reason? Can they understand? So, here's Jeffrey Leish, I believe that's how it's pronounced.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

He's saying, for people who think that AIs aren't really reasoning, don't really understand things or can't really think, what do you mean? Like, how do I test whether an AI can do those things? Now, I knew I was going to be aggravated before I even clicked to see the responses to that tweet. And I decided to retweet it and kind of say that I'll make a prediction. Not one person will comment with an actual proposal for a test for whether AI can reason or not.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Most will say some version of the following. AI can't reason because it's just a something something. I love this take by Scott Aronson who worked with Google on their quantum supremacy project who also worked at OpenAI on AI safety. He worked alongside alias. He talks about this as people that practice the just aism religion.

### ğŸ“ è©³ç´°èª¬æ˜

AI can't do X Y or Z because it's just a stochastic parrot. It's just a next token predictor. It's just a this or just a that. These people never stop and think what am I just a. So I wrote that without looking at the comments, but I just want to briefly show you.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So the very first comments, LMS are just uh giant Plinko boards choosing which story you get, right? They're just this. And by the way, there's different ways to say just a here. For example, uh this person is saying AI basically picks tokens based on known relationships that match existing patterns, right? So it's just a this thing.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

If it can't explain the why behind its answer, not just the what. It demonstrates understanding. Okay? So it just says the what, not the why. Here somebody's saying it's just mechanistic processing.

### ğŸ¯ å¿œç”¨ä¾‹

Here somebody says, well thinking is tied to chemical processes. This is [clears throat] demonstrable. Computers lack these chemical processes. Is thinking tied to just chemical processes? It's how how can we demonstrate that?

### ğŸ’­ è€ƒå¯Ÿ

But the point is they're saying like they don't have these chemical processes. They're just digital or whatever. So it's another way of saying the same thing. Most of these will be some form of justism. So think of it this way.

### ğŸ“Œ ã¾ã¨ã‚

If we asked, can the following things can they reason? And we ask people out there, can humans reason? I feel like most people would say yes. Like in general, does that class of objects or species or whatever you say in general? Does it have the ability to reason?

### âœ… çµè«–

Yes. Yes, it does. You can find examples where people can't reason. Still doesn't disprove that humans in general can reason. If we ask, can a rock reason?

### ğŸ“š è¿½åŠ æƒ…å ±

Most people would say no. Rocks cannot reason. They don't have the ability to reason. Then we get to LMS. And this is where people lose their freaking minds.

### ğŸ”– è£œè¶³

A lot of people get very unreasonable when talking about this. I've said this before. I believe it comes from fear. People get really irrational really fast when we approach the subject. By the way, how do I prove to you that humans can reason?

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

I show you one or more examples of humans reasoning. How do I show you that rocks can reason? I would show you an example of a rock reasoning. I haven't seen that before, so I assume that they can't because there's no example to disprove that. Same thing if we want to know if birds can fly.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

We think that birds can fly. Why? Because uh we've seen a bird fly. So we can kind of test for it, right? So can humans fly?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

Most people would say no. Again, we're talking about unassisted. If you show me one that can levitate, they can flap their arms and fly away, then maybe I'll change my mind. I need one example of that happening to where you might go, hey, yeah, maybe humans can fly. All right, so that's super simple and unambiguous.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Let's make it a little bit more difficult. Let's ask if something can tell time. Can something keep track of time in a way that would be useful to us? That would allow us to know what time it is. All right, so here's a picture of a bunch of metal gears and cogs and just metal pieces.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Well, of course, it can't tell time. It's just a bunch of gears and cogs, right? We're denying its ability to tell time with the justism religion. It It's just a bunch of gears. Therefore, it can't tell time.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

Now, you can probably understand why that's a really bad take. Just saying that it's just a bunch of whatever doesn't mean it can't do something necessarily. Just by looking at the cogs and the wheels, we we have no clue. Here's another thing. Can this tell time?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Well, no. It's just a stick in the mud, right? It's just a little statue. How could it tell time? This is a sund dial, by the way.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So, people have used this to be able to tell time for for well, a long time. saying it's just uh something that sticks out of the ground or sticks out of the plate doesn't negate its ability to tell time. Can this thing tell time? No, it's just a bunch of plastic pieces and a circuit board. Again, that doesn't make any sense.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

Just describing what it is doesn't negate the fact that it can have some ability. The only way to understand if it has that ability is by creating some test that is objective that we can all look at to see if it passes that test or it fails that test. For example, for a clock, you need probably a couple things that it has to have. One, it has to have regular and measurable change. So, if this thing assuming it's working, it will generally over time click and move the arrows, etc.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Does this have, you know, where some of these things work? Does it have a regular and measurable change? Yes, of course. Does this? Yes, of course.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

Does one of those digital watches with a quartz crystal, does that have regular measurable change? Yes, of course. And of course, you'd have to be able to like see or or measure progress from that change. Can you do it with a clock? Yes.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

Can we see and measure change here? Yes. The arrows show us what the change is. Can we measure the change here? Yes.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

The shadow shows us and allows us to measure the change. And does it keep consistent intervals over time? If we double the time, does it double the measured change for a digital watch? Obviously. For a gear clock, obviously.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

So, sundial is a little bit weird. It keeps consistent intervals within the day. Over time, that may change because of seasons, but it's still consistent in that we can adjust. We can still measure it if we can kind of know the seasonality, where the sun is, etc. We can keep consistent time of this.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So all these things have the ability to keep time to to measure time so that we're able to use them to to keep track of time, however however you want to phrase that. They have that ability even though it's just a bunch of cogs or it's just a stick sticking out of the ground or it's just a bunch of plastic pieces and a circuit board and a quartz crystal, right? So it's just this or it's just that. Makes no difference. It either can or it cannot.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So when we're talking about whether something has some ability or not, saying it's just uh something makes no sense. What's the right way to think about it? Well, we have a test. We test to see if it has that ability or no. So now hopefully I've convinced you that we need a test to see if something has the ability to do something or not.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Let's say we want to know if humans can run a 4minute mile. So we don't say, "Well, no, they can't because they're just carbon-based life forms. That's silly, right?" We conduct a test. We make them run around a track. Let's say it's a mile track.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

And we see, you know, we time it and we see if they can run it faster than four minutes. And we add some rules, right? So making sure that there's no loopholes, right? So they can't attach a rocket booster to their back. They can't cut through the grass, right?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So we establish some sort of norms of the test, how that test should be conducted. By the way, we might disagree on some portions of that test. Right? So I might say it's okay for them to let's say have some coffee before they attempt it. You might say no.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

No stimulants allowed. That's totally fine. We can discuss that. But the point is once we have a rule, we can all agree whether or not this test was passed. So next we've designed our test and the first person goes up to the starting line.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Let's say it's me and I run the mile and I come in, you know, I don't know, 10 minutes in. I don't know what's a horrible time. I'm not going to do anywhere near a four-minute mile. Obviously, tech YouTuber, we do not run anyways. So, let's say I come in at a 9-minute mile.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

So, does that mean that humans cannot do a 4-minute mile, right? So, one example of of a human not being able to do it. Does that prove that humans can't do a 4-minute mile? No. It it doesn't prove anything.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

Let's say we run a million people and none of them are able to break the 4-minute mile. Does that prove that humans can't do the 4-minute mile? No, that does not prove it. That's exactly what happened. By the way, if you know the history, for a long time, people thought there was some biological limit until one person broke that limit and then like a whole bunch of other people started breaking that limit.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

So, all it takes is one person to pass that test, the four minute mile test for us to say, okay, humans are able to do that. They have that ability. So, by the way, here's another sort of answer to the person that was asking if LMS can reason. to this person saying, "Oh, I asked it for a file and I had to repeat the instructions two, three times, and it tells you that it provided the file, but there's no file." It means it has no real understanding of what a file is. Right?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

So, that argument is saying, "I ran a 9-minute mile, therefore, humans cannot run a 4-minute mile." So, this result proves this impossible. That logic makes no sense, right? a counter example doesn't disprove that hypothesis, right? So, I'm sure there's a some unhealthy bird out there that can't fly, whereas normally that species of birds are able to fly. That one bird doesn't prove that birds can't fly.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

And there are tons of examples of people commenting examples of these large language models failing to do something or or showing a lack of reasoning. People love doing this. It's meaningless. I can show you a broken clock. That doesn't mean that working clocks can't tell time.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

I can show you a human being doing something foolish. I probably do at least a few foolish things before noon most days probably. My foolishness doesn't prove that humans can't reason. Me running a 9minut mile doesn't prove that humans can't run a 4-minute mile. So most of the people answering let's say 40% of them maybe half are falling into the foolishness of thinking that if they just say oh LMS are just uh this then that somehow disproves that they have some ability which is as I've hopefully convinced you that's absolute nonsense.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

The next biggest group shows basically situations where LMS fail to do something. So they fail to count the number of Rs in a strawberry. Therefore they're useless. Here's an example of where it failed to do this particular task I asked. Therefore, it's useless.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

It can't reason. So, those are arguments one and two in terms of the frequency that I see them. And the third sort of logical fallacy, it's a little bit more subtle and you might be falling into it right now as we speak. Here's the next silly mistake that people make. Right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So, right now in this video, hopefully I've proved to you or shown to you that this statement, this belief that LLMs can't reason, this is a silly belief to have. This is a foolish statement to make. Again, unless you have a specific test that can test for this, then that's a different story. But just believing this without any evidence, it's it's just not smart. And I think it's driven by fear.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

And again, I say this as somebody that's been doing these videos for a couple years now. Every single one of these videos on this subject, you will get hate in the comments. I would not be surprised if there's a lot of hate in the comments of this video. This is very triggering for some people. This spikes a lot of emotions.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

This really triggers that amygdala center in our brain. Some people, some subsection of people because they might have certain beliefs, certain understandings where this triggers mortal fear because something about the machine being able to think and reason and understand similar to how humans scans something about that triggers some fear or or negativity in some subsection of people. You know this is true. I'm sure you've you've seen this. Maybe it even made you uncomfortable.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

I think I set encapsulated this perfectly. very preient. This is October 6, 2023. Like he he knew where this was going. He says, "If you value intelligence above all other human qualities, you're going to have a bad time, right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

Because if you think that our worth is dictated by mainly intelligence and machines become more intelligent, right? Then we the humans, we become the dumb ones. We become the dumbest coworker. We become useless." again if if intelligence is the only metric. So that's why you're seeing a lot of people having a bad time because this strikes fear.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

That's why they make all those logical fallacies like playing the it's just game or I found a mistake I made therefore and then assuming something that that mistake doesn't mean. And this is the third one and this is the most kind of insidious. I guess it's it's hard to spot because if LM's can't reason, if that's a bad take, then what must be true? Well, LM's can reason, right? If if this is the bad take, then logically the opposite is is the good take.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

That's the smart take, the correct one. This also is probably not a great take right now. Again, at least until we have a specific test that we can come up with to see if something can reason or not. It's a slightly better take. The reason it's slightly more defensible is, you know, coming back to our 4minute mile example, no matter how many people run around the track and fail to achieve a 4-minute mile, whether it's 10 people or 10 million or 10 billion, even if we make every single person run around the track that's ever been born, and none of them are able to get the 4-minute mile, none of that proves that humans are incapable of running a 4-minute Whereas one person getting a 4-minute mile proves that they can't.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

The reason I bring this up is because often times when you sort of talk to people that say LM can't reason and you say, "Okay, what's what's a test for reasoning?" Right? So they make this statement. They say, "I believe LMS cannot reason." You say, "Okay, what's what's a test that we can run?" Or at least a counter example that would disprove this. So if you believe that humans can't run a 4minute mile, what would be a case that would change your mind? For example, would a human being run a three-minute mile?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

Right? That would probably change your mind. So what would an LM have to do that would show you that it can reason? Often what people do is they flip it on you. They're like, "Oh no, why don't you prove to me that it can reason?" Right?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

You think it can reason, you prove it. That argument also doesn't make any sense. Just because I'm saying that this is a bad take, that doesn't mean that I subscribe to the opposite take. I'm just saying that this is indefensible. You can't logically defend this position.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

And when people do give you some goalpost for the AI to cross, it's number one, they're always moving and they're moving fast as AI just keeps breaking one after the other. or it's so vague as not to be able to be turned into an actual test that we can look at and say, did it pass or did it fail? Before AI beat world-class chess players, it was believed that when machine intelligence beats world-class chess players, that would be intelligence. After it happened, people were saying, "Nah, that's just brute force and heristics. That's not intelligence." That's the way people said that trivia and various nuance and language could be thought of as intelligence.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

And after LM and some previous AI models crushed that, we were like, nah, that's just statistics, that's not intelligence. Before recognizing objects that can be extremely diverse like cats and people's faces and millions of different objects out there in the world, once AI reached the level that it would be able to recognize all of the objects, we thought, okay, that would be intelligence. You know, after it did that, I was like, nah, that's just pattern matching. It can't explain what it sees. Same thing with go, right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

We thought that go was different from chess because it it required more intuitive understanding. It would be harder to beat with just brute force statistics, heruristics, etc. Once it beats the human le and other grand masters, including the famous move 37 kind of this creative move that no human has a thought of. We still dismissed it. We still said no, it's just narrow intelligence.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

It's not humans general intelligence. A lot of people would say that it can only work within its data set, right? So it can match patterns within its data set. Alpha Fold and all of its offspring are cracking huge biology problems. It's adding to scientific progress.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

Look at the recent findings out of Google DeepMind with their their cancer studies and Gemma, the open- source family of models. It's hard to prove that it's not doing novel scientific research right now. It's still early, but you can't just say that it's working just within its data set because it's finding novel things that humans didn't find. We couldn't do it. It could.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

Some of the people in the comments have just asked their favorite large language models if it can understand things, if it can reason. There's a number of these examples. They screenshotted the answer and they're like, "Haha, here's the truth. The answer, problem solved." But does that really prove anything? Like right now reading these responses, I am doubting that human beings can reason.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

So if you asked me right now, can human beings reason? I might be tempted to say it really doesn't seem so. Do humans understand things? No. Obviously not, right?

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

So would me saying that, would that be proof that that's the case? Probably not. And we're not even taking a reinforcement learning into account. Imagine every time you tweeted out the human beings can't reason or understand like a million people would hit the like button. You'd probably be saying that a lot more.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

So, is this answer just because of reinforcement learning? Because of how these models are trained? It very well could be, as I'll show you in one of these later videos. There's an incredible research paper that's coming out kind of about this. The point being that this means nothing.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

By the way, the comments that say things like, "Oh, thinking is tied to chemical processes and large language models don't have those. Therefore, they can't think. That's basically saying that this digital watch can't tell time because it doesn't have cogs and metal gears. Like, I can show you how telling time uses metal gears. Look, I can show you.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

Therefore, this different approach cannot possibly work and have that same ability. So, think about that for a second. What are these people arguing? I mean, a lot of these people are very smart, educated people. If I told them that this thing can't possibly tell time because it's just a bunch of metal gears, they would laugh at me, right?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

They're like, "That's a stupid thing to say." There's more than one way to create something that can tell time, right? Digital watches, your computer, none of those have metal gears in them and keeping track of time. So, why are these otherwise very smart people, why are they making such silly mistakes in their thinking? Well, it's very simple. They're not hearing the same thing that I'm hearing.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

When you and I hear this question, can LM's reason? We probably hear it as is with no emotional response to it. Like I don't feel outraged or sad or how like it's just a question, right? We're seeing that question as can this object do this thing or does it have the ability to do this thing? It would be the same thing if you ask me, can a microwave run Doom or can your dog do tricks?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

And the answer to those questions is super simple, right? If I can get my microwave to run Doom, then yes, right? So if it runs Doom, if I can get it to do that, then then yes, it can. If I can't get it to run Doom, then the answer is no. Or maybe, right?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

So maybe it can't. Or or maybe I didn't figure out a way that it can. Right? So if I can get it to work, it works. If I can't get it to work, then maybe it doesn't work.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

And can your dog do tricks? Same thing. If I see it doing a trick, then yes, it can do tricks. If I don't see it doing a trick, then maybe it can't. Or maybe I just haven't seen it do a trick.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

I think that the people that are really struggling against this idea of whether LMS can reason or not, they're not hearing that question in the same way. So if they hear a question, can a microwave run Doom? a certain part of the brain logically thinks through it and understands it. Can your dog do tricks? Same thing.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

But you ask them, can LM's reason? And no, that's a completely different part of the brain takes over. That part of the brain goes red alert. There's danger. Some deeper ancient part of our brain takes over.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

It's a lot more primal. It's a lot more emotional. That part goes, well, if yes, if they can reason, then we're just cooked. We're done. If they can reason, well, we're all dead.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

We're all unemployed. We're all not important. So therefore the brain should create reasoning as to why the answer is is no. They can't reason. The reason you can tell that this is happening is because oftent times their answers don't really make sense from the perspective of like is this the question that they're answering?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

Because as I hopefully showed you the answers that they have for for this question those answers don't fit. They don't make sense. What question are they answering? The question they're answering kind of like the prompt that they prompt their own brain with is the following. explain why LMS can't do the thing that makes me feel special and look through that lens at the answers.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

Now, not just these, but anytime you encounter some irrational AI hate or anything like that, see if those answers make more sense if you view it from that perspective. So, this first comment goes, humans produce new insights and they update their weights, right? So, they're learning and they introspect on their reasoning process to evaluate it. By the way, Anthropic just released a paper called the signs of introspection in large language models. Oops.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

So, are just a giant plinko boards, right? So, they're not special. I'm special. By the way, you can tell this is the case based on the fact that different groups of people respond very negatively to different abilities of AI. The responses are just as emotional and irrational as they are with other abilities, but it's just the the thing that they focus on is different.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

So, here's a person that used AI to create this animation. And uh I love the animation. Looks beautiful. If this was some sort of a anime, cartoon, whatever. I I would be kind of interested in seeing it.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

Looks great. This person retweets it. This person is against AI. You can tell it by what they write in their in their bio and other comments. So, they're saying, "Let's reward that." So, the person below is saying that I created this cinematic thing.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

this person that doesn't like AI. So, he's an artist that doesn't like AI. So, he's saying, "Let's reward that." You didn't make anything. You got a computer to make something for you. So, Mad Vidpro retweeted this.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

That's actually how I saw it. Mad Vidpro does get, it seems like, attacked on Twitter by people that are against using AI to do various art, visual, video, etc. Seems like he catches a lot of flak from them. Not for anything bad he did, just for showcasing these tools. Me and not being one to pass up a trolling opportunity jump in here saying, "As a bit of a painter myself, I feel the same about people using cameras to take photos.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

The camera does all the work. The person taking the photo contributes nothing. This photography fad won't last." Right? So, I'm agreeing with Matt here first and foremost, if that's not clear, kind of responding to this person tweet, right? So, you have your computer do everything for you.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

You didn't do anything. So what that person's sort of referring it to how I understand it is that you can take any piece of art and sort of think of it as high craftsmanship and and low amount of craft, right? So if you were to sculpt something, there would be a lot of craft required, right? You have to slowly chisel everything out of stone versus something like AI art where you type in a prompt and it generates usually four different versions for you that you can pick from. So that person is saying because it was low on the craft scale that this is basically worthless.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

Here's the issue. There's tons of other art that's also low on that craft scale. Again, I use the photography example. I mean, with modern digital cameras, you point and you push a button that captures the image. You didn't make anything in the image, right?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

If you're taking a picture of a sunset, you didn't make the sunset. You didn't draw it. You didn't sculpt it. You didn't whatever. You This This is all it takes.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

you push the button. It might be argued that typing out a prompt takes more work than pushing a button on your camera. But obviously that reasoning doesn't make sense. I don't think that even the person that said it would apply that to photography. So for example, here's that same person, right?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 84

He took a picture of a sunrise on his phone. I don't think he would considered this a horrible thing, a bad thing because it was low effort or low craft. He just held up his phone, pushed the button, and captured the image. Would the same reasoning apply? Would he agree with the fact that he didn't make anything?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 85

He got a smartphone to make something for him here. He is saying that this is something that's absolutely horrible, unwatchable. I mean, I don't know. Is it really unwatchable? Doesn't seem that bad.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 86

Here's another shot made by AI. He's saying, "I love how soulless this is." So, is it soulless? I don't know. Point being is those statements don't really make sense. If taken at face value, if this was made by a human director and looked exactly the same, I don't think he'd think it's soulless, if this was made by somebody or it was an animation of some sort, I I don't think he would say to that person, it's unwatchable.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 87

And I don't think he'd tell a photographer that took a picture of a sunset or something like that that, oh, you didn't make anything. You had your camera make it for you. Those statements don't make sense through that lens. Now, let's apply my lens. So I believe that the prompt that these people give their brains in these situations is this.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 88

Explain why LMS can't do the thing that makes me feel special. What makes this person feels special where here he's saying that he's a 3D artist, 3D designer, right? And he pinned his work in Blender. So he creates these scenes by hand. So his craft he's I don't know somewhere here.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 89

I don't know how much work he puts into it, but you know higher than taking a photo or AI art. this is like 3D modeling or whatever. This is what he feels proud of. This is what makes him feel special. So he pinned what I'm assuming is his progress from 2004 to 2005 using Blender using, you know, doing his craft.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 90

So when somebody creates an animation, that makes him feel less special. So he retweets it and says, "Oh, you didn't make it. A computer made it, right? So you shouldn't feel good about your work like I feel good about my work." This thing that Grock imagined it made, well, it's unwatchable. We can't watch it.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 91

And this little animation, it's soulless. Can we define what that means? Can he name something that's soulless that's made by humans? Is there some objective thing there that can be defined? Probably not.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 92

It doesn't make sense from that standpoint of taking at face value. When that statement does make sense, if you think of it as this is the prompt for that person and their experience and the output is what they said, like that's soulless. It's unwatchable. You didn't make it. The computer made it.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 93

Right? All right. So in this case, you know, we're not talking about LLMs. We're talking about, you know, if he feels special by using Blender to create art and somebody can create similar art using AI, right? So he's explaining why those people can't do the things that make him feel special.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 94

Recently, I posted a study that Suno music, AI music is for most people getting indistinguishable from real music. I got a lot of comments. the people with the strongest negative response to that study, that paper, which by the way, again, it wasn't insulting to anyone. It didn't say anything offensive. It just said, "Hey, look, the average person can no longer differentiate between AI music and music made by humans." So, a lot of the negative responses were by people in the music industry, people responding to AI art.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 95

Like if it's a graphic art, then it's people that make graphics, 3D graphics, animations, etc. People that respond, you know, negatively to this idea that LM can reason. I mean, well, this person is a scientist, game designer, player nerd, and occasional writer. And I've seen this for the last couple years, both on X and YouTube. Anytime that I show a particular aspect of AI getting better, especially if it seems like it's getting close to human level, the outcry, the kind of reactive responses, they usually come from people who do that or specifically, I think, really pride themselves on doing that thing.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 96

So, if I post about AI doing music, musicians are mad, coding, coders are mad. Again, not everyone. It's a very special subsection, which might be obvious, but again, the big point here that I'm trying to make is that the way in which those responses are made, they're weird. They're different. They're not often rational.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 97

If you ask a musician to rate a humanmade piece of music, there's certain words and phrases and descriptions that they'll use. They'll say whether they like it or not. They'll talk about the technique. They might talk about like whether they like the style or not. With visual art, they might say how it made them feel.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 98

They might talk about the colors. There's certain ways that people talk about code, whether it's clean, whether it's works, whether whatever, whether it's well commented. So when humans judge other humans outputs, we have a certain way that we talk about it and judge it and describe whether we think it's good or not. And on the other side, when we show people the outputs from AI, I think a lot of people, probably most people, maybe 80% of people, I'm just guessing. I have no idea what this number is.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 99

We tend to analyze that or think about it just like we would about anything else. So, can LM's a reason? We kind of process that question in the same way like we would process can birds fly or can this thing run doom. But for some percent of the people talking about these things tends to trigger that fear response. And again, it seems like what they say about that output, that piece of art or music or that question relating to AI, whatever it might be, that gets morphed to be something completely different.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 100

And you see these people when they talk about AI outputs, they almost make up new terminology. They create new ways of describing these outputs. For AI, it'll be there's no soul, there's no depth. People say AI music sounds tiny or shallow. People say that AI writing doesn't have meaning, right?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 101

Because there's no lived experience behind it. Here's a chart I found on LinkedIn, right? So, this is why readers don't like AI writing. People just hate AI writing because it's just text, right? Whereas for human writing, you don't have text.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 102

You have subtext. You also have author intention. You have contextual impact and dialectical participation. you have this whole like iceberg underneath the surface. So human writing is all of this and and you know AI is just this.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 103

So that's why we don't like AI writing. There's just one tiny tiny tiny problem with that belief statement iceberg diagram. That is that humans prefer AI over human written poems. And this is true for a lot of other writing. We also can't tell AI music from regular music.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 104

I wish they did a comparison of which one people think is better. I think AI music is at some point going to become more liked by average people. But with writing with with poems, keep in mind it's not just poems. There's tons of other examples of this. But humans can't distinguish between AI writing and human writing.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 105

If asked like which one is which, they don't know. But they do rate the AI poems more favorably. They like them more. So what that means is if you show people this picture, people are like, "Oh well, human writing is clearly better. Look at all all the stuff that it has." But and this is super important that everyone understands this because this is true across all AI generated outputs, whether it's text, written text, poems, or audio, visual, what have you.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 106

When we don't give you hints as to which one you should prefer more, where you have to select the blind, people go, "Ooh, I like this one better." they select the AI one more and then when asked why so for example when we take poems by famous human poems versus AI poetry people prefer AI poetry why well it's easier to understand with clearer themes and subjects even those written in ways that intentionally emulated the forms of famous poets when asked to rate the poems on rhythm emotional impact and aesthetic beauty participants consistently preferred pieces written by AI over those written by humans. This is the the big point. Their assessment and ratings dropped when they were told the poem was AI generated showing a general bias against AI created pieces. So if you are asked if you like a certain piece of writing or text or music or whatever and you describe what you like about it, what you don't, why it's clear or unclear, again, whether you like it or not, then you really are describing whether you like it or not. If however you're told that it's a piece generated by AI and all of a sudden your whole language changes and you're talking about soul and depth and if you have to create whole new categories to try to say that AI writing is worse than human writing then seems like you're lying to yourself and you're also lying to yourself.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 107

If you can spot the logical fallacy if I say oh this can't measure time because it's just a bunch of gears. If you understand why that's not a good argument, but you can't catch the fact that saying LMs are just uh whatever stochastic parrot, why that's not a good argument, then then you're kind of deceiving yourself. Whatever you do, above all, don't lie to yourself. That's uh fur dustki. And the reason I want to talk about this is because the next few years, next five years are going to be extremely extremely important.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 108

People are going to lose their minds. people will sound deranged and they will not be able to see their own derangement because they're lying to themselves about what they're perceiving. I think for all of us it makes sense to make sure that we're being very rational about this and not being deceived by either our own fears and insecurities. If AI is getting good to the point where it can affect something that that you're good at that you're doing, make sure you have some specific test to see can it do it? What is it good at?

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 109

what is it bad at? Don't invent some lofty new abstract concepts to try to prove to yourself that it can't replace you. And also pay attention to people that are in a certain profession saying how AI will never affect that particular profession. Make sure they're not comparing it to just like the top 1% of that profession. If AI can code better than 50% of software developers, that's going to have a massive impact.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 110

It doesn't have to be in the top 1%. The average person has a hard time distinguishing it between AI music and human-made music. Their guesses are like coin tosses. It's basically 50/50. So, if you're trying to understand how that will affect the music market, that's the information you should be looking at.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 111

You shouldn't compare AI music to your favorite band and see how you feel about it. You shouldn't compare it to the top 1% most talented musicians that have ever lived. The study says that the average person can't tell the difference. Based on that, how do you think that's going to affect the music market? As AI expands and reaches more and more industries and areas, both overreacting and being kind of crazy about it or underreacting and trying to pretend doesn't exist will probably lead to some issues.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 112

Above all, don't lie to yourself. Really, the only job that I think is safe from AI is being a YouTuber. I can't do this job. You need lived experience. You need like presence on camera.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 113

You need to be present. You need to have a certain spunk, some some grit. You got to have soul. You need a certain X factor, an aura, a vibe, energy or a frequency and an an essence, a certain inner light. You need heart, a certain magneticism or panache.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 114

You just need a certain janiqua. But yeah, but everybody else is in trouble. Oh, and one final thing. If you were wondering what my personal belief is, whether LMS can or cannot reason, here's my answer. Here's the definition of reason.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 115

The power of the mind to think, understand, and form judgments by process of logic. Okay, so we're doing those things by process of logic. Makes sense. What does logic mean? Logic means reasoning conducted.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 116

So to summarize, reason is to think using logic, the process of logic. And logic of course means to reason, right? To to do the process of reasoning. So I hope that answers your question.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ31æ—¥

</div>
