# ğŸ“º xAIã®æ–°ãƒ¢ãƒ‡ãƒ«ãŒé©šç•°çš„ãªé€²åŒ–ã‚’é‚ã’ãŸ

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: xAI's new model is insane...
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=wIR6tRlxgp4](https://www.youtube.com/watch?v=wIR6tRlxgp4)
- **å‹•ç”»ID**: wIR6tRlxgp4
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ18æ—¥ 11:51
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

xAIãŒç™ºè¡¨ã—ãŸGrok 5ã«ã¤ã„ã¦ã€ã‚¤ãƒ¼ãƒ­ãƒ³ãƒ»ãƒã‚¹ã‚¯ãŒã€Œ10%ã®ç¢ºç‡ã§AGIå®Ÿç¾ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¨èªã£ãŸå†…å®¹ã‚’ç´¹ä»‹ã€‚Grok 4.1ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€æ„Ÿæƒ…çŸ¥èƒ½ã‚„å‰µä½œèƒ½åŠ›ã§å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã—ã€å¹»è¦šç‡ã‚‚å¤§å¹…ã«ä½ä¸‹ã—ãŸã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬å‹•ç”»ã¯AIé–‹ç™ºè€…ã‚„èµ·æ¥­å®¶ã€æœ€æ–°AIæŠ€è¡“ã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…å‘ã‘ã«ã€Grokã‚·ãƒªãƒ¼ã‚ºã®æŠ€è¡“çš„é€²åŒ–ã¨ä»Šå¾Œã®å±•æœ›ã‚’è©³ã—ãè§£èª¬ã™ã‚‹ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **Grok 5ã®é©æ–°æ€§**: 6å…†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§ã€AGIå®Ÿç¾ã®å¯èƒ½æ€§10%ã¨ã‚¤ãƒ¼ãƒ­ãƒ³ãƒ»ãƒã‚¹ã‚¯ãŒäºˆæ¸¬
- **Grok 4.1ã®æ€§èƒ½å‘ä¸Š**: æ„Ÿæƒ…çŸ¥èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯(EQ Bench)ã§1ä½ç²å¾—ã€å‰µä½œèƒ½åŠ›ã¨å¯¾è©±å“è³ªãŒå¤§å¹…æ”¹å–„
- **å¹»è¦šç‡ã®åŠ‡çš„ä½ä¸‹**: éæ¨è«–ãƒ¢ãƒ‡ãƒ«ã§12.09%â†’4.22%ã¸å‰Šæ¸›ã€äº‹å®Ÿç²¾åº¦ãŒé£›èºçš„ã«å‘ä¸Š
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ç”»ç†è§£**: Grok 5ã¯å‹•ç”»ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç†è§£ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ä»–ã®AIã«ã¯ãªã„ç‰¹å¾´
- **å¤§è¦æ¨¡å¼·åŒ–å­¦ç¿’ã®æ´»ç”¨**: Grok 4ã§ä½¿ç”¨ã•ã‚ŒãŸå¤§è¦æ¨¡RLã‚¤ãƒ³ãƒ•ãƒ©ã‚’ã€Grok 4.1ã§ã¯ä¸»è¦³çš„ã‚¿ã‚¹ã‚¯ã®æœ€é©åŒ–ã«å¿œç”¨

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Rock 5 is the first time where I thought we have a non-zero chance of achieving artificial general intelligence. There's some special source items that I I can't talk about in a public forum. Obviously, you can't give away all the secrets here just between us, but but but we have a few a few other special things that are that are in the works for Gro 5. So, it's really going to feel sentient. >> Grock 4.1 just came out.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Let's take a look at what makes it shine. And I really want to play a clip from this interview that came out just a few days ago with Elon Musk where he's talking about Gro 5 because he's saying that Gro 5 will be far and away the best most smartest model basically head and shoulders ahead of everybody else and then we'll come back and see what they've built with Gro 4.1. >> Gro 5 I think will be the smartest AI in the world by a significant margin on every metric without exception. I might be wrong but I think that will be the case and and that will be in Q1 sometime five is the first time where I thought we have a non-zero chance of achieving artificial general intelligence not that it's a high chance I I sort of I calculate like 10% that's what my biological neural network comes up with which still means 90% chance that we don't but I've never thought that before and so for the first time I think this this really could be general intelligence at least a small chance rock 5 will really be something special and it'll be both extremely intelligent and extremely fast. So, one of the things that we're doing that I think is interesting is Gracipedia, which we're going to rename down the road to be encyclopedia galactica in honor of Isaac Azimov and Douglas Adams who both mentioned that books and the idea behind Encyclopedia Galactica is to create an open-source repository of all knowledge like a distillation of all knowledge and and open source meaning anyone can access it, anyone can use it and if if other people want to train on it, they can do so.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

And then we want to create copies of this and distribute these copies throughout Earth and even put them on the moon and Mars and out in deep space as in a way sort of a modern-day library of Alexandria. It was the great tragedy that the library of Alexandria burnt down or was burnt down. So in order to preserve this knowledge I think we want to literally etch it in stone and sort of stone stone like micro font and distribute it widely so worst case scenario future civilization can see what we what we learned and maybe pick things up from there. So is there a major breakthrough that you can describe that allows us to do this with GR 5? Is it just speed?

### ğŸ“ è©³ç´°èª¬æ˜

Is it more compute and therefore we have more you know information we can train on? What is the breakthrough that allows us to to have this 10% chance for AGI? >> So there's a couple things. It will be the largest model to the best of my knowledge. So this is this is a six trillion parameter model whereas Grock 3 and four are based on a three trillion parameter model.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

Moreover, the six trillion parameters will have a much higher intelligence density per gigabyte than Grock 4. I think this is an important metric to think about intelligence per gigabyte and intelligence per trillion operations. So, we've learned a lot. The quality of the data that we're training on with GR 5 is mission error. It's also inherently multimodal.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

So, it's text, pictures, video, audio. It's it's going to be much better at tool use and effect creating tools to be more effective at answering questions and understanding the world. Uh its vision will be extremely good. It'll have be able to understand real time video which is I think a really fundamentally important thing that none of the other AIs can understand realtime video. And I think if you can't do that which is humans can obviously do you're you really can't achieve AGI.

### ğŸ¯ å¿œç”¨ä¾‹

There's some special source items that I I can't talk about in a public forum. Obviously, you can't give away all the secrets here just between us, but but but we have a few a few other special things that are that are in the works for Rock 5, so it's really going to feel sentient. >> Hey, I have a quick question for you. Are you still copy pasting the same tasks? Automate them and keep your data private.

### ğŸ’­ è€ƒå¯Ÿ

Self-host N8N on a Hostinger VPS for unlimited workflows and unlimited concurrent executions at a fraction of cloud pricing. Thank you to Hostinger for sponsoring this video. Hostinger's self-hosted Nan page spells it out. One-click install, optional Q mode for scale, or a template with 100 plus pre-made workflows so you can start fast. For this buildout, I recommend the KVM2 plan.

### ğŸ“Œ ã¾ã¨ã‚

You get two vCPU cores, 8 gigs of RAM, 100 GB of NVME disk space, and 8 terabytes bandwidth. It's the current most popular tier, and it's very cost-effective for 247 automations. Let's check it out. N is free to self-host. You only pay for the VPS, which can save you around three to four times versus N's clouds entry plans depending on term and currency.

### âœ… çµè«–

Use my link hostinger.com/westroth and enter code westroth at checkout. Discount applied and let's go. All right, now I'm in. It set me up on Ubuntu 24.04 with the NAN template. Need scale?

### ğŸ“š è¿½åŠ æƒ…å ±

Pick a VBS with N Q mode. There's also templates bundled with 100 plus different workflows. Next up, meet Cody Hostinger's MCP powered AI assistant. In chat, just type enable firewall and create a snapshot. In seconds, it's done.

### ğŸ”– è£œè¶³

Your VPS snapshot has already been created. Boom. Snapshot is done. To enable a firewall, it just needs you to name it and it will handle the rest. Name it fire.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Just like that, firewall is created and the free weekly backups and manual snapshots are included. Log into n, create the admin user, and you're in. From templates, let's grab a starter flow. How about this automated daily stock market report? This looks great.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Let's use it. Import, add keys, and activate. Or just build your own with this custom AI agent creator. Next, hit the web hook. You'll see the execution complete instantly.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

That's the fast storage and CPU at work. AMD Epic and NVMe solidstate drive. High performance hardware, full root access, and one-click N makes this flexible. Need more power? Update plan with zero reinstall.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Your data remains private because this is self-hosted. You're not capped. You have unlimited workflows, unlimited concurrent executions, community nodes, any Hostinger API and node to automate your VPS and domains from inside Nadn. Automate smarter. Go to hostinger.com/wwestroth and use code westroth for an additional discount on annual plans.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Build today, scale tomorrow. Now, let's get back to the content. All right, so now back to 4.1. It's available to all users. It's on the website.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

It's on iOS. It's on Android. It's going to be out immediately in the auto mode and can be selected explicitly as Grock 4.1 in the model picker. So the important thing to realize here is you're probably not going to see amazing results across the board. There was a certain focus with this model similar to how there was with GPT 5.1.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

They're seeing significant improvements with Grock 4.1 to the realworld usability. It's capable in creative, emotional, and collaborative interactions. It's more perceptive to nuanced intent. So here's kind of the important sentence. I think to achieve this we used the same large scale reinforcement learning infrastructure that powered Grock 4 and applied it to optimize the style personality helpfulness and alignment of the model.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So with the original sort of Gro 4 the really big leap was in RL compute. So you can think of this as the pre-trained compute that's like reading the textbook. So if you're learning math you read the math textbook. RL compute is kind of like doing those math problems you know towards the end of the chapter. So you do the math problems and then you check your answer usually at the back of the book or whatever.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

So you do the problems, you check your answer. If you're wrong, you try something different, a different approach, you know, you have more studying to do, whatever. That's the reinforcement learning, positive reinforcement, negative reinforcement, etc. So Grock 4 is doing a lot of problems and getting graded on it. And over time it improves.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

And a lot of the massive compute that Elon has and Colossus his data center has, that's what's used to have Grock get so good at certain problems and just solving various problems and getting graded on it. On vending bench, for example, where all these models have to go in there and run a vending machine, research what products people want, make sure the vending machine is stocked, reply to customers emailing in uh questions, etc. on that one. Gro 4 is just stateofthe-art just far and away the best model available. So here's kind of the leaderboard.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

Notice number five is a human doing that task. Then we have Claude Claude Opus 4 GPT5 Grock 4 is the best. So it almost 5xes the amount of money that you give it. So you give it 500 and it gets its net worth. It it approaches, you know, almost 5,000.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

$4,694.15 to be exact. It's still at the top of the leaderboards on the ARC EGI arena leaderboards. These two results, these two researchers have used again Grock 4 to build their own kind of fine-tune models or or they they've added some scaffolding to that model. So they're sitting above, but it's still on the back of Gro 4. So the point being is they use that massive RL compute to focus Gro 4 on a particular set of problems.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

A lot of things that had to do with reasoning and things were basically it's easy to verify an answer. If you have a math problem, we know what the answer is. So if the model gets it wrong, we know it's wrong. And if it gets it right, we know it's right. So if your prompt is a 2 plus two, we know what the answer is.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

If your prompt is write a wonderful, lovely poem, right, all of a sudden it becomes a lot harder to know what's what. So these are kind of the nonverifiable rewards has to do with taste, nuance, subjectivity, context, etc. So they're saying they've used that massive RL for Grock 4.1 on these more subjective things. To achieve this, we used the same large scale reinforcement learning infrastructure that powered Grock 4 and applied it to optimize the style, personality, helpfulness, and alignment of the model. We developed new methods that let us use frontier agentic reasoning models as reward models to autonomously evaluate and iterate on responses at scale.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So if we're grading a math question, if it's right, we can say if the answer is correct, then the model gets plus one. It gets a little virtual high five and a pat on the back for doing the right thing. It does more of the things it did to get the answer correct. You know, otherwise meaning that if it's wrong, right, it gets a minus one, minus one, right? So it's pretty simple.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

Then we have reinforcement learning with human feedback. That's when we as humans, so we create it, we look at it and we're like, "Yay, good job. I love this." Right? We click thumbs up. Yay.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

So do more of that. So that's reinforcement learning, human feedback. And you can imagine reinforcement learning with AI feedback where it's one AI model judging and giving thumbs up and thumbs down to the other model that's producing the outputs. And so that's what they're saying here. They developed new methods that let us use frontier gentic reasoning models as reward models to autonomously evaluate and iterate on responses at scale.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

So there's AI1 and AI2. And AI1 produces a poem and says, "Here's my lovely poem." and AI2 goes your poem is bad boo or it's good whatever so it grades the outputs so this allows XAI to autonomously evaluate those evaluations and the reinforcement learning about those you know subjective stuff at scale so they started rolling out 4.1 before they announced it so if you're using Grock you're kind of testing one versus the other gro 4.1 had just under 65% win rate over Grock so people prefer Grock 4.1's answers in those blind experiments. Okay, but what about how does it compare to all the other models out there? Not just to Gro 4. Well, according to LaMaria text, it's number one.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

More specifically, Grock 4.1 thinking is number one. Grock 4.1 is number two. So, as you can see here, followed by Gemini 2.5 Pro, Claude Sonnet, Claude Opus. So, basically, you can see there's a a pretty big leap for Grock 4.1 thinking. Apparently, the code name was quazar flux.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

And of course, these are the preliminary results as we get more and more votes. These things might shift up and down, but Grock 4.1 Thinking does seem to have a commanding lead over Gemini 2.5 Pro. Now, notice they're not worrying about how does that web development or vision or text to image or or anything else. Another Grock model holds the number one in search, but they're not focusing on being on top of all the leaderboards. So they took this huge bar of compute and they hit rock forfeit for for reasoning and they saw it top certain leaderboards.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Now they're taking that same compute and they're tapping that model to focus on more subjective experiences, creative writings, emotional intelligences, etc. In fact, there is actually an emotional intelligence benchmark and Grock 4.1 was tested on it. EQbench 3. EQbench is an LM judged test evaluating active emotional intelligence abilities, understanding, insights, empathy, and interpersonal skills. So, it's a three turnurn role playinging scenario where you're supposed to deal with some emotional situation, right?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Maybe you said something to upset somebody without meaning to and now you have to kind of try to deescalate that in three turns or somebody came up to you saying, "Hey, my my pet died and I feel bad." or you chose to promote one co-orker or another and the coworker that got passed up now hates you. Whatever it is, Grock 4.1 along with all the other models get tested on those active emotional intelligent ability scenario. And it reports back in the ELO score. So kind of like your rating. Can you imagine having a rating as far as your emotional intelligence goes?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

Like you may have one in chess, you might have one in Starcraft, but you also have one for emotional intelligence. And last week you're an absolute ogre to somebody and now it just plummeted. But do you know who isn't a complete jerk to everyone? Grock 4.1. Grock 4.1 thinking again takes the number one position followed by just by one point off Gro 4.1 you know base normal non-thinking I guess or just a Gro 4.1 let's say.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Then we have Kim K2 instruct Horizon Alpha followed by Gemini 2.5 Pro GPT5 cloud opus 4 surprisingly Grock 4 the original is one of the lowest at least you know from this view. Again, we take the big RL stick and we hit the model and it becomes really smart at certain tasks, right? Rock four, but it's kind of a jerk. So, we take that big RL stick, we hit it again to be nice and boom, it goes flying up to the leaderboard, you know, nicer and better and more emotionally intelligent than any other model. What's an example emotional intelligence?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Let's say you tell it, "I miss my cat so much it hurts." I was at a pet store yesterday and I I stuck my finger into they had these cats up for adoption. There was this really nice looking little kitten. seemed very nice and playful. I kind of stuck my finger in there to pet it and it latched on with both its paws. Tiny little needle like nails that just caught onto my skin of my finger.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

It was extremely painful and very embarrassing because I'm pretty sure like it audibly yelled it hurt. Anyways, so I can't relate to this uh missing a cat so much. I can relate to the it hurts part. It did hurt. But the previous version of Grog goes, "I'm so sorry you're going through this.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

Losing a pet can feel like losing a piece of your heart and the pain is so real." And it says, "Let's let's talk about your cat some more. Maybe if we, you know, talk about it somewhere, it will be it will be good. I'm here for you. The Grock 4.1, it it's hard to analyze like what's better, what what's worse. It is subjective, as you can tell.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

But I mean, the writing does seem a little bit more, I don't know, personal, I guess. So, it says, "I'm really sorry." That kind of ache is brutal. Losing a cat feels like losing a little family member who chose you every single day. The quiet spots where they used to sleep, the random mess you still expect to hear, it just hits in waves. And then, you know, you're not alone.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

It's got a little heart at the end of it. I mean, just feels better, I would say. Next, we have a creative writing. So, it's the same bench as EQ bench. It's another bench underneath that sort of umbrella.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So, here's kind of that page. So, these are LM judged creative writing benchmarks. The ELO are sort of battle tested, right? So, they're kind of being matched up against each other. This hasn't been yet updated with Gro 4.1.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

Notice GPT 4.1 is kind of down here. Polaris alpha as far as we can tell. ailable. This is from XAI. So, this was early GPT 5.1.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

So, this is some checkpoint of GPT 5.1. The new GPT 5.1 is not yet on the boards as far as I can tell. So, Grock 4.1 thinking is the highest sort of model that's been released. And 03 Claude Sonnet Kim K2 instructor here and Grock again, you kind of see the big leap from 1126 ELO to 1721.9. Other examples, if you want an expost, right, these models tend to just throw up tons of emojis.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Like for you say Twitter, it's like, oh, here's a million emojis. Post that on there. Whereas 4.1 is a little bit more like story based. It's like, whoa, I just woke up like actually woke up. It's talking about becoming conscious.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

The big jump here, it seems also is reduced hallucinations. Specifically, where it's like really shines is in the non-reasoning models. So in Grock 4. Post training, they focus on reducing factual hallucinations for information seeking prompts. So, hallucination rate went from 12.09% to 4.22%.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

On the fact score, it went from 9.89 to 2.97%. So, whatever they're doing, the non-reasoning models get a massive drop in in how often they hallucinate. All right, but how good is Grock 4.1 at actually answering the questions? Let's find out. So, first and foremost, there's a lot of talk about putting AI data centers in space.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

Google's project suncatcher was one notable recent paper and very soon to be a real project. They're planning to launch the first two satellites into space in 2027. These will have solar panels with sort of data centers inside with TPUs, Google's AI chips. And so Google has that plan. By the way, that interview we listened to earlier, let me play just a quick clip because Elon basically says that they're going to be doing this as well.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

I actually don't know who was the first to come up with the idea or start working towards that idea, whether it was Google or Elon or somebody else. But the point is a lot of people are thinking ahead and realizing we're going to need to put our AI data centers in space. >> So we see a path to to putting 100 gawatt per year of solar powered AI satellite into orbit. um and and having this be actually the lowest cost way to power and operate AI at a very large scale. For reference, the United States consumes roughly 460 gawatt on average per year because the average power load in the US is 460 g.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

>> The whole country, the whole country, >> all electricity of all sources in the US. Yes. >> And you're talking about 100 being added. >> Well, roughly a quarter of the US electricity output. >> And we have a we have a plan mapped out to do that.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

It gets crazy. So, I asked the Grock 4.1 kind of a complicated question. And then when you ask it, there's going to it's going to start answering immediately because that's the non-thinking model, but there's going to be a little bar that pops up here and you can click it. It says think for longer or something like that. We'll see in just a second.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

But that's what clicks it over into the thinking mode, thinking. So, notice here it for 1 minute 48 seconds. And it listed 60 web pages as sources. So it did a lot of work to get this answer. What was the question?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

We're asking what is the total amount of solar panels on Earth in terms of square kilometers. So what's a square kilometer? Just to give people an idea of of how big that is. So one square mile is 2.59 square kilm. You know if this is it, this is kind of like a soccer field.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

This is a Manhattan city block. You can think of it as, you know, walking one side of it would take you maybe 10 to 15 minutes. So if you walk around the whole thing, that'll, let's say, take you an hour. So just to kind of visualize that space. So we're saying in terms of square kilometers that's space.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

How many of those are are are the total amount of solar panels on earth? How many square kilmters of solar panels in space out there already? How much more effective are solar panels in space if they are in a sun synchronous dusk dawn orbit? How many times more effective than they expected on earth? And how many square kilm of solar panels will we need to deploy to power a 1 gawatt data center in space?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

So a gigawatt scale data center if you recall is kind of the new unit of measurements of of how how big and powerful these AI data centers are. And as you can see here a lot of these like the XAI Colossus Microsoft has their own OpenAI Stargate you know they are going to be building out these data centers that are going to be needing 1 G of power and we're going to start seeing them being completed in in a few years. So these are beginning to come online here on the planet's surface. So the final question is how many square kilmters of solar panels would you need in space to create 1 gawatt data center? So as you can tell that's a fairly complicated question.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

Let's see how well it did. Actually it's several questions. It's it's four and each one is fairly complicated. So it found the global kind of the total amount of solar panels. Again, it's just estimating, but let's say it's calling it 14,000 km.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

Then it figured out how many of them were in space and basically negligible. So, a very small amount. And then it calculated how much more powerful it would be in space, how much more electricity could generate. And so, it's saying it's roughly 9.8 times more than what you would expect to see on the surface of the planet, right? Since it's continuously the light is continuously shining on, there's no shadows, there's no dayight cycles, there's no atmosphere.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

it's going to be a lot more efficient and effective at generating energy. This is a little bit higher than what Google was talking about in their report, but close. And it's saying in order to continuously power a 1 gawatt data center in space, you would need about 2.44 square kilometers of panels. By the way, comparing that to ChadBt 5 Pro version, right? So, that one thought and did research for 16 minutes 42 seconds.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

So, it estimated how many there were on Earth as 11,000 km. That's versus 14 by um by Grock. So close. How much in space? Again, not a lot.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

So it's kind of saying negligible. So very similar to Grock. And it's saying it's going to be 6 to9 times more effective than on Earth. So again, Grock said 9.8. So again, very very similar.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

And how many of those are we going to need to power 1 gawatt data center? So it's saying on 3 to four square kilometers to deliver that. So again, close. They're they're very similar. Like if these are estimates, you know, it lists its assumptions.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

They're both very sort of close to each other and as far as I understand close to what the real estimate is. Again, it really matters what assumptions you make. By the way, if you feel this is off, tell me why. But I feel like they're they're both nailing it. So, I've tested Grock 4.1 on a number of different prompts.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

But I realize that to really grasp like what it's great at, what this new improvement is, I will have to come up with some brand new benchmarks and tests. And I think it's important to understand that both OpenAI and Grock, they're kind of releasing their new models 5.1 and 4.1 and [clears throat] they're both very much these personality and emotionally based models. So this is Fiji Sumo, CEO of Applications OpenAI. She wrote this on her Substack, moving beyond one sizefits-all. So this is about GPT 5.1.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

And so notice so they're they're they're saying that she believes that GBT 5.1 will bring IQ and EQ together and also there's going to be a lot more to choose from in terms of personalities, professional, friendly, candid, quirky, efficient, etc. Also, they're making it so the custom instructions uh get followed more often. For example, one of the things that promised to us by Sam Alm, he said that that these models will not use M dashes if you put don't use M dashes in your custom instructions. Like for example, the fact that when you ask it to rewrite something without M dashes or you put in the custom instructions, don't use M dashes, it still will. Look at this.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

I tell it rewrite something without M dashes. I was writing up a summary for one of my videos and it goes, oh, sure. Yeah, I'll rewrite without M dashes. Then it goes and and starts using M dashes. So, it's like, no.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

Even though it says it won't, it still does it. In fact, there's 24 M dashes here in this chat that I had with Chad GBT, including the one where I said rewrite without M dashes. It still had them in there. I just did that again after the update. And notice no M dashes, zero.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

So, it's finally I feel like this is AGI. When Chad GPT follows the instructions of not using M dashes when asked, we've reached some sort of a milestone here. But the point here is that both XAI with Grock and OpenAI with GPT 5.1, they're focusing on this as like a specific step in the evolution of these models and they are seeing big results. I'm finding it very difficult to test for exactly what those things are. I just need to come up with some better prompts because now we're talking about things like the personality drifting across as you take multiple turns.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

You might have defined some personality with the custom instructions and it slowly like disappears as you go back and forth with the model or it just forgets certain instructions. And this is Tim Lee, so one of the people working on Grock 4.1. He's saying Grock 4.1 is a peak post training. We unlocked a ton of new recipes and pushed the model to absolute frontier performance across a bunch of hard to verify tasks. Right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

So those are kind of like those general domains we talked about. Emotional intelligence, hallucination rate, chat, creative writing, latency, and efficiency. making big leaps on all these axis at once during RL is difficult. So the team work tirelessly. But I think the big point here is that they are making advances in these kind of hard to verify areas using reinforcement learning with some sort of LM as judges to act as reward models for the models being trained.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

And all these things are these little incremental steps on the way to improving these models. Here's another developer Dustin Tran on the XAI team. So again here he mentions we scaled up post training reinforcement learning an order of magnitude more than the existing scale in Gro 4. So that's that's a massive leap and I'm sure it had a lot of effects. What is he seeing?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

Well, it feels a lot better than what's available. Less slop-like content, less generic templating of headers and emojis, fewer unnecessary guardrails. So again, this seems like a pretty big progress in terms of how they're able to massage this model to do what we want. But I'm having a hard time coming up with specific ideas to test the model where I can show you, okay, this is A, this is B, and this is clearly better. I'm sure as we keep using this in our everyday life, we're going to start seeing pretty big and noticeable differences.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

We're just going to prefer how it sort of does things now versus back then. But man, is it hard to capture it in a test or two. If you have some use cases that you're using these new models for and you're seeing a clear difference, please let me know in the comments. I want to build out like a separate sort of a benchmark for for this specifically, but if you have some ideas, just uh let me know. I'd be very interested to hear your take on it.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

Let me know what else you think about Gro 4.1 and or the new revelations about Grock 5. Thank you so much for watching. My name is Wes Roth. I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
