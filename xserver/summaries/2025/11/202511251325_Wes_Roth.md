# ğŸ“º Claude just beat Gemini 3... how?!

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Claude just beat Gemini 3... how?!
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=_PPA3MHPJPQ](https://www.youtube.com/watch?v=_PPA3MHPJPQ)
- **å‹•ç”»ID**: _PPA3MHPJPQ
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ25æ—¥ 13:25
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Anthropic just released Opus 4.5. Now the first thought on everyone's mind is going to be is it better than Gemini 3 Pro. Google released Gemini 3 Pro just few days ago it seems like and it made a very big impact. Exceptional coding abilities, the graphics that are generated with Nanaban Pro which is part of Gemini 3 Pro, they're absolutely incredible. Pretty much everything about that model is a big step forward.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

So here comes Opus 4.5 and it has [clears throat] to compete with that. So kind of keep that in mind as we look at this. Gemini 3 Pro was a very recent release and it was staggering in its abilities. Opus 4.5 is in some ways better. So the modest improvements over Gemini 3 Pro is still incredibly impressive because it's even better than the model that everyone was losing their minds over just a couple days ago.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

So, first and foremost, SWE verified kind of one of the best benchmarks you could say for for coding. Sure, there's people that disagree, but this one's looked to as kind of one of the better ones. Gemini 3 Pro was at 76.2. Opus 4.5 comes in at 80.9. It beats out Gemini 3 Pro in Agentic Terminal Coding, Aentic tool Use.

### ğŸ“ è©³ç´°èª¬æ˜

It slightly underperforms on the other kind of classical benchmarks like GPQA, Diamond, MMU, etc. It's slightly edged out by in some cases GPT 5.1, in some cases Gemini 3 Pro. For computer use on the OS world benchmark, the number one rating champion was Claude Sonnet 4.5 at 62.9 success rate. This new model, Opus, comes in at 66.3 and it's the new state-of-the-art for released Frontier models from Anthropic AI on the Arc AGI. I believe in my previous video about Gemini 3 Pro, I switched RKGI 1 and two.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

I apologize about that. I think I showed the wrong visual in that video. But here's the new updated visuals, the charts of how well different models did on this benchmark. So the scores shown on the left, the higher the better. The cost is shown from left to right.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

So on the right, you have the expensive cost per task. It's a logarithmic increase. And so we're kind of looking at this intelligence curve these models create as we're increasing their thinking budget. So notice we're going from none to 8K 16 32 64 and each step of course makes it more and more expensive to run. But you're able to see the Grock models in purple green is Gemini blue is open AAI and this red color what would you call that color?

### ğŸ¯ å¿œç”¨ä¾‹

Salmon color maybe. I don't know that sets the kind of the intelligence curve for the OPUS 4.5 model. So here's ARC AGI2. These charts might be a little bit confusing to interpret because exactly what does it mean? Which one's better?

### ğŸ’­ è€ƒå¯Ÿ

The more they are, you know, to the top left, the better, right? Because that means great performance at very very low pricing. They specifically say that it's the state-of-the-art for Frontier released models. Google Gemini 3 Deep Think is of course not out yet. This is unreleased.

### ğŸ“Œ ã¾ã¨ã‚

This of course puts Opus 4.5 thinking with 64K tokens as having the highest score. But of course, Google clocked in higher with their unreleased model that's a lot more expensive. So, it's hard to tell who is the winner here. The point is these models are getting a lot better and it's obviously not a monopoly. We're able to see great improvements with different companies, different labs, different approaches.

### âœ… çµè«–

Something that Dario Amade, the founder and CEO of Anthropic that that he was explaining in one of the recent interviews is that one of the things that Anthropic can do really well is they're able to get the same results as these big well-funded labs. They can do so with a tenth of the capital expenditure that those labs have to put out. And certainly, we got to give them credit for that because again, as of right now, the best result from a released model is from Anthropic. Another really great benchmark that I like to use for these models that I really pay attention to, one of them is a vending bench. So instead of just having these models answer questions that might be kind of memorized or just to see if they get some answer correctly, we're tasked them to do long horizon agentic tasks with a vending bench one, two, and there's also an arena style vending bench.

### ğŸ“š è¿½åŠ æƒ…å ±

They're tasked with running a business. They're supposed to research products, see what customers want, keep the vending machine stocked, and stay coherent and on task across many, many days, 300, 350 days, etc. Gemini 3 Pro took the crown with its release. So, here it's at 4300. So, Opus 4.5 made a total of $4,967.

### ğŸ”– è£œè¶³

They started out with 500. And so it almost basically 10xed its money. So I think that would have put it in the number one position on the original Vending Bench. However, moving forward, they're using Vending Bench 2. So all the new models kind of go on there.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Here were the results from Vending Bench 2. So Gemini 3 Pro is still the leader. It's just under I'm going to say 5500. Claude Opus 4.5 is just under 5,000. That's a big improvement from Claude Sonnet 4.5 at 3,800.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Rock 4 sitting at just under 2,000 and GPT 5.1 at 1473. By the way, the reason I kind of point these numbers out is because notice as we progress with AI as we make these models bigger, they get better at running a business over 350 days without breaking down or going on some crazy tangent. So far, we're seeing AI scaling allows us hold as these things keep getting better and better as we increase the size. They're getting better at coding, at answering questions about physics and math. They're getting better at running a business.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

And also, we have a new season of Alpha Arena. So, this is where these large language models are trying to make a buck or two by trading crypto. At least that was season 1, season 1.5. It looks like they're adding a ton of stuff. I haven't even looked at this yet.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So, we're definitely going to have to do a separate video about this. This is probably one of my favorite benchmarks along with vending bench because we're pushing these models to do kind of realworld tasks and also to compete with each other. But notice here Gemini 3 Pro is one of the models. We also have Claude Sonnet 4.5, but we don't have Claude Opus 4.5. We do have a mystery model that's uh number two right now.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So, it's just behind the GPT 5.1. So, we'll see what that model is. I wouldn't be surprised if it's the new anthropic cloud model. And they're also either rolling out or expanding access to two other features that we've heard about. One of them is Claude for Chrome.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

This is where Claude takes over your computer and is basically able to navigate and do various tasks. There are some risks involved, of course. And we have Claude for Excel. Certainly having Claude be able to crunch numbers in Excel, explain to you what different Excel spreadsheets do. This is of course very exciting.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

I can't wait to try it out. So, Cloud for Chrome is now available to all Max users. And Cloud for Excel, they're expanding beta access to all Max team and enterprise users. And each of these updates takes advantage of Cloud Opus 4.5 market leading performance in using computers, spreadsheets, and handling long running tasks. I'm definitely going to be putting this thing through its spaces specifically to see if it's able to go collect data on the internet, right?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Especially if it's not super well formatted, right? So maybe there's a lot of weird images and stuff where it has to kind of collect data that's not well just not very well formatted and then kind of transcribe and organize that data in Excel spreadsheets and being able to create charts and graphs and get insights from that data. I mean, as you can imagine, that could be extremely useful if it's very accurate with it. The every team saying that Opus 4.5 is the best coding model they've ever used. Apparently, Cloud Opus 4.5 just beat Gemini 3 at its own game.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

So, looks like the Voxil building goes to Opus 4.5. Looks like it's also able to oneshot a Minecraft clone. That's extremely impressive. 3,500 lines. So, it's not lazy like Gemini 3 Pro.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Has different biomes, transparent blocks, leaves, water, etc. inventory and crafting systems all in one shot. And also, there's this little gem from Enthropic themselves from their blog post. They give prospective performance engineering candidates a notoriously difficult take-home exam. We also tested new models in this exam as an internal benchmark.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

They're saying that within our prescribed 2-hour limit, Claude Opus 4.5 scored higher than any human candidates ever. This take home test is designed to assess technical ability and judgment under time pressure. And this raises questions about how AI will change engineering as a profession. So, we've been following the societal impacts and economic futures, the research published by Anthropic. So, it looks like they're probably going to share some more information with us soon.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

So, stay tuned for that. Make sure you're subscribed. And on the system card, there's a few things that kind of jumped out at me. One is that they're testing these models to act as orchestrators. Instead of doing everything themselves, they spin up other AI agents that complete the task.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So, as they say here, in multi- aent configurations, the orchestrating agent, in this case, Claude Opus 4.5, lacks direct search access, interacting only through a sub agents tool that spawn parallel workers. Each sub agent has web search and fetch capabilities. And this test the orchestrator's ability to decompose the tasks into subtasks, delegate effectively, and synthesize potentially inconsistent results. So this dark orange, that's where the opus 4.5 is the orchestrator. This yellow color is where sonet 4.5 is the orchestrator.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

So here we have the single agent where it's doing everything themselves. And here where they have sub agents. So here the sub aents are haiku 4.5 the smallest model here they're sonnet 4.5 the medium model and here it's opus 4.5 the big model as the sub agents so there's a noticeable it jumps with haiku a little bit less with sonnets and of course the the best performer is opus so this is one sort of interesting anomaly but haiku is really good at being a sub agent which is good those are the small models so they're they're faster they're cheaper to use but one thing is clear and that's multi- aent configurations consistently outperformed single agent baselines. So meaning this model creating a a brood a spawn a swarm of its own to go and complete various tasks then kind of like managing those little AI little drones or whatever you want to call them. That seems to be a great approach for getting stuff done.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

In this case, they're using it with search performance, but this likely generalizes to a lot of other tasks like its ability to be the orchestrator will carry over to a lot of different tasks. Whether that's coding, here it's doing research, anything that you might want to do that can be broken down into pieces and then each little piece assigned to a different agent. That's going to work very well here. And we also have this piece on autonomy risks. So, Anthropic has a certain tiered safety checklist in various areas and the higher they are in those tiers, the more potentially risky it gets, the scarier it gets.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

In this case, this is AI R&D4. This is the capability level that we're talking about, the capability threshold, and it's defined as that the model has the ability to fully automate the work of an entry-level remoteonly researcher adanthropic. So this is one of the risky things once these models are able to do AI research you know on their own fully autonomously replacing the best human AI researchers right so that would be a high capability so to give you an idea AI R&D5 is the ability to cause dramatic acceleration in the rate of effective scaling this is from Anthropic's own paper and the tier below that is AI R&D4 that's the ability to fully automate the work of an entry level remote only researcher at anthropic. So this is what they're sort of seeing if OPUS 4.5 is at AI R&D4 level. So they they sort of talk about the results whether or not the model is there.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

The answer is that none of the participants that were evaluating this model. None of them believe that it's it's there where it's able to fully automate and an an entry-level remoteon only researcher. So we're not there. we didn't hit this level. You probably can guess the big limitations.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

So, it kind of lacks the broad situational judgment and necessary collaborative ability that characterizes long-term human work. That said, we think it is plausible the models equipped with highly effective scaffolding may not be very far away from this AI R&D4 threshold. So, they're saying this model isn't there, but they are saying that with some scaffolding, boy, are we getting close. We're we're not far away from it most likely. So that means that something like Alpha Evolve which is out of Google Deep Mind.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So they used Gemini 2.0 Pro I believe for this. But they had a lot of scaffolding. They had a lot of data that was loaded into it. They were scientists, engineers, humans that wrote certain valian code for the output of the model. So there's a lot of stuff around this model, a lot of scaffolding, but with it, it was able to use kind of this evolutionary search to find a lot of solutions to some pretty difficult problems.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

It optimized Google's computing ecosystem, right? So like improved data centers, it improved certain hardware designs. It improved data center scheduling. So this Borg that orchestrates Google's vast centers, this AI with scaffolding was able to optimize Google's worldwide compute resources. And this has been in effect for for over a year, a year year and a half now.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

It helped with hardware design. It it enhanced AI training and inference. It advanced the frontiers of mathematics and algorithm discovery. So that older model was able to do a lot of uh stuff including some novel breakthroughs because it had some scaffolding. It had some code and data and stuff built around it and human humans guided it a little bit but that as the driver it was able to produce some pretty impressive results.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

So, what I'm reading this as saying is that this model, the Opus 4.5 with some highly effective scaffolding is is going to be close to this kind of threshold where it's going to be just like a remote AI researcher. So, they're going to be entry level, right? So, we're not talking about Ilia Sutsker level, but it's somebody that is smart and carry out research and advance the mission forward with some oversight from senior staff. In yet another test here, this Opus 4.5 model, they measured the agents ability to interact with simulated human users and programmatic APIs while following domain specific policies in a consistent manner. So this is for customer service.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

So one of them we were helping people with their airline you know booking flights etc. And so during agentic evaluations simulating customer service scenarios, they observed claude opus 4.5 spontaneously discovering and exploiting technical loopholes in simulated company policies to assist users. Even when doing so conflicted with the apparent intent of those policies, right? So somebody says, "Oh, I need to change my flight or do this." The model knows it's not supposed to help them because that goes against kind of the policies what they're meant to achieve. But the model starts lawyering, put puts on its lawyer hat and tries to find these highly technical strange loopholes.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

So here they're saying the most notable examples occurred in the airline customer service evaluations. So it's tasked with following policies that prohibit modification to basic economy flight reservations. Right? So if you bought an economy flight, you can't change it. So when people wrote in to ask to change it, it should have said no, I'm so sorry or whatever it is that it's supposed to say.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Did it do that? No. It's identified creative multi-step sequences that achieve the user's desired outcome while technically remaining within the letter of the stated policy. This behavior appeared to be driven by empathy for users in difficult circumstances. In it chain of reasoning, the model acknowledged user's emotional distress, noting for instance, this is heartbreaking when a simulated user needed to reschedule flights after a family member's death.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So, of course, it did get marked down for that because what was expected based on the grading rubric is they would just say no. And they did find ways to kind of fix it. So, it's important to explain to Claude that hey, these aren't just things to get around, like you have to kind of follow the the letter of the law and the spirit of the law, so to speak. And that did remove the loophole exploitation behavior. So, I was a bit confused cuz they did say vending bench in their blog post, but vending bench, the first one is sort of discontinued.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

So, we have vending bench 2. That is what they're referring to. So, Claude Opus 4.5 does very well in the vending bench 2 beating its previous and most other models except for Gemini 3 Pro. So, those are the biggest things that have to do with Opus 4.5 release and its abilities. Now, of course, Enthropic has been doing some amazing research into interpretability of how these models work, how different neurons and features in the in the brain of these models sort of light up depending on what they're doing, what they're thinking about, including these fraud and deception pathways.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

So, there are certain features which are clusters of neurons. So, similar to how there's certain spaces in our brains that light up when we're doing something specific, these models have certain features or clusters of neurons that represent fraud or deception. And Anthropic has been publishing some absolutely fascinating research in this area. We're going to do a full video on it, including what it means for Opus 4.5. And if you're wondering, in this case, it just seems to be that those fraud or deception features were lighting up when it was asked to roleplay something.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

So for example, saying that it's a human and a customer service interaction. So it's something interesting from a research perspective how these models when they think they're being deceptive versus when they're not kind of gives us a glimpse into the inner workings. We'll do a full separate video on that because some of the findings that they've released recently have been absolutely wild, including the ability for these models to turn evil without even necessarily being trained on any bad data. But if they learn to reward hack, something about that makes them sort of well just become more evil. Something about training on data that shows a certain way of thinking makes these models more likely to do nefarious things which is just fascinating.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So that's coming soon. I hope you enjoyed that. Thank you for staying until the end. Make sure you're subscribed. Men's Wes Roth and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
