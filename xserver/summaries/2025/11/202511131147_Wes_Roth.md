# ğŸ“º the BIG SHORT against the AI BUBBLE (Nov 25th is the day)

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: the BIG SHORT against the AI BUBBLE (Nov 25th is the day)
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=qrGpdYtwuo0](https://www.youtube.com/watch?v=qrGpdYtwuo0)
- **å‹•ç”»ID**: qrGpdYtwuo0
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ13æ—¥ 11:47
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

There's been some pretty big events happening in the world of AI. Let's cover the top AI news happening today. First and foremost, there's a race to build gigawatt scale data centers, and it looks like they're going to be built in 2 years or so. Open AAI posts a blog post saying they're fighting the New York Times invasion of user privacy. The New York Times wants to see if you've been asking Chad PT to read the New York Times articles without paying for them.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Also, a legendary investor, Michael J. Bur calls the top of the bubble, shorting Nvidia and Palanteer, calling what they're doing a common fraud of the modern era. OpenAI has some recommendations and warnings about AI progress. an important study showing that using a generative AI in various retail environments like to help consumers with chat like for example for customer support using AI to improve conversions this works and has a meaningful positive impact and there's a lot a lot more let's start at the beginning so first and foremost Epic AI has yet another report they're doing a great job putting a lot of the information about AI progress and kind of the state of of the AI industry. And here's yet another one asking, "How fast can we build a gigawatt scale data center?" Some hyperscalers plan to do it in just 1 to two years from the start of construction.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

So, we might be seeing our first gigawatt scale data centers online in 2026. So, the XAI Colossus 2, that's the one that might be the first one to get to 1 gawatt of power. We have the anthropic Amazon new Carile. I'm going to assume that's pronounced Carlilele, right? We have in the Microsoft center Meta Prometheus Open AI Stargate.

### ğŸ“ è©³ç´°èª¬æ˜

Now the Metar Prometheus took a total of 8.7 years or would once they reach the 1 gawatt of power but that whole thing might be coming online and reaching 1 gawatt of power you know right after Colossus Microsoft Meta followed by OpenAI yet another Microsoft center and another Amazon center. Keep in mind that Google recently announced the project Suncatcher. Still a very ambitious project to put data centers in space to draw solar power. Now, that's not coming as soon as the other projects, but could be a massive leap in free and abundant energy for the long term. Just a few hours ago, Anthropic announced that they're building their own AI infrastructure and they have a $15 billion investment in these projects.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

Now, of course, Google has massive infrastructure. They are masters of multi-data center training. So unlike the large AI clusters that everyone else is building, theirs are more distributed. By the way, you probably know this, but I run on coffee. It's my preferred energy source.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

This morning, I was standing in line at my local coffee shop, this place right here, when I was struck by an idea for an AI app. It was an AI mood journal. You can track how you feel and what you were doing that day. And over time, you get some actionable data about what makes you happy. Things like coffee and what makes you miserable.

### ğŸ¯ å¿œç”¨ä¾‹

Things like standing in line to get coffee. Could I build this app before I reach the end of the line? Luckily for me, there's this brand new app I have that can help me do just that. It's called, can you guess it? Vibe Code.

### ğŸ’­ è€ƒå¯Ÿ

This video is sponsored by Vibe Code because, well, coffee is getting kind of expensive, right? Anyways, Vibe Code is a mobile app that lets anyone build real mobile apps on the app store without writing a single line of code. So, I pull out my iPhone and describe my idea to Vibe Code. In seconds, I have a prototype and I haven't even had my coffee yet. By the way, they're not letting some second rate AI model take a stab at it.

### ğŸ“Œ ã¾ã¨ã‚

This is Claude code, the most powerful coding model in the world right there on your phone at your beck and call. The new pinch to build opens up a cap cut style menu right on your phone. You just pinch to create images, icons, logos, or UI assets that match your brand or style without relying on outside tools. You pinch for integrations. Add speech to text to capture your thoughts by voice.

### âœ… çµè«–

I'm feeling sanguin. Add automatic AI image generation to illustrate your mood, etc. No APIs to deal with, just pinching. Pinch to add haptics. Those are those subtle vibrations that confirm actions.

### ğŸ“š è¿½åŠ æƒ…å ±

It's the subtle little things that count. Now my app is done and I'm almost at the front of the line. Let's ship it. Getting things live on the App Store used to be a nightmare. You can now ship your app to the App Store with almost no friction.

### ğŸ”– è£œè¶³

You do need to sign in into your Apple developer account. Then you just push one button on your phone and the app will ship to the App Store. This takes a process that once took weeks of setup and turns it into a few seconds. Your progress is saved in Vibe Code Cloud. Everything is synced across devices.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Do you want to try it? Get your first three apps free by using the code Roth. So, use the code Roth at the App Store link below. Build something that solves a problem and tag me when you ship. All right, coffee break over.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Let's get back to what we were discussing before. Everyone is spending massive amounts of capital on building out their AI infrastructure. This is where Michael J. Bur comes in. He was of course played by Christian Bale in the movie The Big Short, which is a great movie.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

And he of course shorted the housing crash before anyone saw it coming or even before people thought it was possible. And now he's back shorting Nvidia and Palanteer. He's saying understating depreciation by extending useful life of assets artificially boosts earnings. One of the more common frauds of the modern era. Basically, we sort of expect all these computer chips and GPUs and data centers infrastructure to have a certain useful life.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

A GPU from 10 years ago is not going to be worth as much as a brand new one. Things slowly become obsolete and also worn out. So, his point is that these companies have been slowly kind of increasing what they're using as the useful life of these network and compute parts. So like you can see Google from three in 2020 to doubling up to six in 2025. And he's saying that this artificially boosts earnings and because of the sheer amount that they're buying, of course, they can have a big impact.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

He's saying this is exactly what the hyperscalers have done. By his estimates, they will understate depreciation by 176 billion in 2026 to 2028. So basically, if you bought a car for $20,000 and you kind of assume that it's going to be useful for 20 years and then completely break it down, you can sort of think of it as losing a,000 a year to depreciation. But if you say, oh, this car will be around for a million years, then that sort of depreciation, that loss is going to be a lot less. He's saying that this is exactly what they're doing with compute, meaning that by 2028, they will overstate earnings by 26.9%.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

This means that by 2028, Oracle will overstate earnings by almost 27%, Meta by almost 21%, etc. But it gets worse. More detail coming November 25th. Stay tuned. So, we'll see what happens November 25th, but it sounds like he's expecting things to start crumbling pretty soon.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Now, of course, there's a lot of counterpoints to it. A lot of people are saying that he was one shot by the massive reward signal of calling Eubble correctly when no one else saw it. He's been chasing that dragon ever since. Certainly, he's called a lot of other bubbles in the past that never came to be. Here's August 2022.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Here's January 2023. So, I mean, here's where he kind of said, "Sell everything, right?" So, at that point, the stock market went up quite a bit. It's up 65% since then. Now, here's Dan Max saying Michael Bur is wrong and pointing to the fact that both Microsoft and Google and Meta sort of they they said why they were increasing their depreciation or rather why they increased the server network the useful life and why that caused the depreciation to drop. All the above changes were disclosed, audited and based on new evidence.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

Now, of course, people might disagree with that and say this wasn't the correct thing to do, but I agree with Dan Mack here that maybe this is not a finance guy take. This might be more of an engineer or somebody specifically working with these chips. I might have a better opinion of whether or not their useful lives should be increased. The reason for extending the useful life or at least how we track it is because fleets actually last longer and software runs them better. Microsoft reason is explicit.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

software efficiency plus tech advances. Of course, if Michael J. Bur calls this correctly, he will have been twice right in in a very spectacular fashion, cementing his status as the ultimate short collar maybe in history. And if you're wondering why his name was Cassandra and chained here on Twitter, Cassandra was a Trojan princess gifted with prophecy, right? The gift to see the future by the god Apollo.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

but because she spurned him. Isn't that literally like every Greek tragedy? The gods just kind of get jealous and just curse everybody. Anyways, Apollo got hurt and cursed her so that her accurate predictions would never be believed. So, she would accurately predict what would happen and nobody would believe her.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

So, Michael J. Bry here decided to take that as his sort of a moniker, Cassandra. Next, we have AI progress and recommendations from OpenAI. If you recall, they said that they are likely be able to automate scientific discovery by 2028. They're saying AI is unlocking new knowledge and capabilities.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

Our responsibility is to guide that power towards a broad lasting benefit. So, the reaffirm this idea that by 2028 and beyond, we are pretty confident we'll have systems that can make more significant discoveries. They're recommending that we do a few things to make sure that everything goes well. One of those things is shared standards and insights from the Frontier Labs. They're calling for Frontier Labs to share safety research.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

This would allow us to learn about new risks, mechanisms to reduce race dynamics, and more. So, if everyone's trying to get to the finish line first, people might take shortcuts. If there was some shared framework between labs, some of that risk might be reduced. They're also talking about a public oversight and accountability that increases and is equal to the capability of these AI models and one that promotes positive impacts from AI and mitigates the negative ones. The high order bid should be accountability to public institutions.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Right? So these labs need to be accountable to the governments to the people. But how we get there might have to differ from the past. So what do they mean about these new ways? Well, it would be difficult for us to adapt in a normal way.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

the typical regulation will not be able to help much either. They're saying we will probably need to work closely with the executive branch and related agencies of multiple countries such as various safety institute to coordinate well. So definitely a lot of mentions of working and partnering with the federal government on various things like protecting against bioteterrorism, protecting people's privacy etc. and of course building an AI resilience ecosystem. So similar to how the internet infrastructure was built out, we'll need to build an AI infrastructure and this is a powerful role for national governments to play specifically in promoting industrial policies to encourage this buildout.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

The Frontier Lab should also report to the government on the impacts of AI and they're saying that predicting what's going to happen is hard, which is true, but measuring what's happening in practice is likely to be informative, right? So, we shouldn't expect these AI labs to foretell the future and know where things are going. But if they're all reporting whatever they can measure about the impact of AI, if they're reporting it to some central place, then just the fact that we have that data indeed would be very beneficial. They didn't mention user privacy in there. And speaking of user privacy, they posted this today.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Fighting the New York Times invasion of user privacy. So, as they're saying, each week 800 million people use a chat GPT. They have sensitive conversations, share various personal details about their lives, etc. You might have heard about the New York Times lawsuit. So, the New York Times is demanding that we turn over 20 million of your private Chad GPT conversations.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

They claim they might find examples of you using Chad GBT to try to get around their payw wall. This demand disregards long-standing privacy protections, breaks with common sense security practices, and would force us to turn over tens of millions of highly personal conversations from people who have no connection to the Times baseless lawsuit against OpenAI. Now, when this lawsuit just came out, we read on this channel the evidence that the New York Times brought forth to demonstrate that Chad GBT could be used to get access to copyright materials or paywalled materials. Now, I'm not a lawyer, but I have used the Chad GPT, and a lot of the evidence they presented is showing how Chad PT could be used to try to circumvent these payw walls. All those proofs that were submitted were to me, in my opinion, in a word, well, sus.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

they were all very suspicious because at the end of the outputs when you ask Chad GPT something and nowadays it's a little bit different but back then with those current models at the end it would kind of summarize what you asked for in the last paragraph of its response. So you would be able to tell if for example you uploaded a document and asked it to read that document or you asked it to go and search for something online. In each case, those little telltale signs of how those outputs were generated by CHIGPT, they were always cut off, which just seems extremely extremely suspicious. As OpenAI continues, they have tried this before. Originally, the Times wanted you to lose the ability to delete your private chats.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

We fought that and restored your right to remove them. They then demanded we turn over 1.4 billion of your private chat GBT conversations. We pushed back and we're pushing back again. Now, your private conversations are yours and they should not become collateral in a dispute over online content access. This was bizarre to me that my and every other user's conversations could be sent over to the Times.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

I've never had any agreement that the New York Times would get my conversations. I was really surprised about this. We've interviewed a lawyer, ex- litigator, law professor Christa Laser on this channel before, so she explained why this is sort of normal and within the bounds of the law. I still am just bewildered that this is the case. So, I get that.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

I guess it's okay. It's normal, but it makes no sense to me. They're saying that this demand from the New York Times does not live up to their legacy, and we're asking the court to reject it. If the Times succeeds in this demand, we'll be forced to hand over the very same data we're protecting, your data, so that's the user's data to third parties, including the Times, lawyers, and paid consultants. So, let me know what you think about this.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Does it make sense that some publication, doesn't matter who it is, whether it's the New York Times or the oatmeal.com or whatever, some random online publication, thinks that its content has been accessed without them getting paid. Should they now have access to your personal data even though you've never agreed to hand it over to them? You might not even have heard of them or had any interactions with them. But a judge somewhere might be empowered to say, "Yeah, go ahead. Hand over all their user data to to the lawyers and third parties and uh and let's see if we can settle this." And by the way, there's no guarantee that this information won't leak out there.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

I find this bizarre. If you have a counterargument, please let me know. Specifically, I'm talking about the users's data, not the New York Times versus Open the AI. They can duke it out. I don't care.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

Why is our data being shared without our permission? If you have a good argument for why that should be the case, please let me know in the comments. I'm very curious to hear it. Here's a post from Rahen Pal. He's saying, "Extremely important study.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

This shows a generative AI can raise online retail productivity by boosting conversions." Right? So, we're seeing a sales lift. We're increasing $5 per consumer annually reported. Chat bots would be able to answer product questions in many different languages. Better search queries and clear product descriptions to help shoppers find the right items faster.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

Chargeback defense won more disputes and live chat translations made customers happier. I've ran e-commerce stores for a decade plus. I wonder what portion of the money that was made was just simply from, you know, doing the chargeback disputes. This is unfortunately kind of a a plague in the online e-commerce game, especially if you're a smaller store. The industry refers to this as a friendly fraud, which is kind of a weird way to call it.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

Basically, they purchase stuff from your store, they get it shipped to their house, and once it arrives, they call their credit card company and say, "Oh, I I don't recognize this charge." At this point, the e-commerce store gets hit with a chargeback, with a dispute, which is very costly. It's bad for their merchant account. It's just very damaging. They get hit with penalties and the money that they got from the customer, well, that gets withdrawn. At this point, they have to submit tons of information proving that the customer did indeed order and receive that product.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Once they receive that information, they either side with you or the customer. Oftentimes, this process feels kind of random. If you win, you get the money back. You still are hurt in the process because every chargeback kind of has a ding against your merchant account. So, it's extremely damaging to the businesses and absolutely zero risk to the consumer.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

I think there's literally just zero chance of anything going wrong if you engage in this friendly fraud. I mean, in a perfect world, karma gets you back and hard. But I mean, the credit card companies would just let it happen since they collect fees for dealing with chargebacks. So, the more chargebacks, the better for them. I just realized I went on a tangent.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

I apologize. I have strong feelings about this, but let's continue. The point being here is that stores that utilize AI for various things like if they're an AI powered store, they have a positive economically meaningful impact. AI improves their profitability, their productivity, and it seemingly also improves the customers experience of the store as well. And as I'm recording this 1 minute ago, GPT 5.1 rolls out and I am off to check it out.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Thank you so much for joining me. Let me know what you think about the New York Times thing. Do you think that stores will become more AI powered and automated, especially online? Let me know what you thought. Thank you so much for watching and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
