# ğŸ“º ãƒ­ãƒ¼ã‚«ãƒ«AIç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãŒæã‚ã—ã„ã»ã©é«˜æ€§èƒ½ã«ï¼ˆQwen3-VLï¼‰

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Local AI Surveillance Is Getting SCARY Good (Qwen3-VL)
- **ãƒãƒ£ãƒ³ãƒãƒ«**: All About AI
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=MrhEEYvYK1A](https://www.youtube.com/watch?v=MrhEEYvYK1A)
- **å‹•ç”»ID**: MrhEEYvYK1A
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ13æ—¥ 23:30
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

Qwen3-VLã¨ã„ã†è»½é‡ãªè¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆ2Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã‚’ä½¿ã£ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã™ã‚‹AIã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹å®Ÿè·µçš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å‹•ç”»ã§ã™ã€‚ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’IPã‚«ãƒ¡ãƒ©ã¨ã—ã¦æ´»ç”¨ã—ã€2ç§’ã”ã¨ã«ç”»åƒã‚’åˆ†æã—ã¦ç‰¹å®šã®æ¡ä»¶ï¼ˆäººç‰©æ¤œå‡ºã€ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®ã‚¸ãƒ£ã‚±ãƒƒãƒˆç€ç”¨ã€ã‚«ãƒ¼ãƒ†ãƒ³ã®é–‹é–‰ãªã©ï¼‰ã§ã‚¢ãƒ©ãƒ¼ãƒ ã‚„ãƒ‰ãƒ­ãƒ¼ãƒ³ã‚’èµ·å‹•ã•ã›ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨ç•°ãªã‚Šã€LLMã‚’ä½¿ã†ã“ã¨ã§è‡ªç„¶è¨€èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã ã‘ã§æŸ”è»Ÿãªæ¤œå‡ºæ¡ä»¶ã‚’è¨­å®šã§ãã‚‹ç‚¹ãŒé©æ–°çš„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **è¶…é«˜é€Ÿãª2Bãƒ¢ãƒ‡ãƒ«**: Qwen3-VLã®2Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¯ã€RTX 4080ã§ç”»åƒåˆ†æãŒé©šç•°çš„ã«é«˜é€Ÿã€‚True/Falseåˆ¤å®šãªã‚‰ç¬æ™‚ã«å¿œç­”ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã«æœ€é©
- **è‡ªç„¶è¨€èªã§æŸ”è»Ÿãªæ¤œå‡ºæ¡ä»¶**: å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ãªè¤‡é›‘ãªè¨“ç·´ã‚„ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹è¨­å®šãŒä¸è¦ã€‚ã€Œã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®ã‚¸ãƒ£ã‚±ãƒƒãƒˆã‚’ç€ãŸäººã€ãªã©ã€ãƒ†ã‚­ã‚¹ãƒˆã§æ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã ã‘ã§ç‰¹å®šå¯¾è±¡ã‚’æ¤œå‡ºå¯èƒ½
- **å®Ÿç”¨çš„ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é€£æº**: æ¤œå‡ºæ¡ä»¶ã«å¿œã˜ã¦ãƒ‰ãƒ­ãƒ¼ãƒ³ã‚’è‡ªå‹•èµ·å‹•ã•ã›ãŸã‚Šã€ã‚¢ãƒ©ãƒ¼ãƒ ã‚’é³´ã‚‰ã—ãŸã‚Šã€ãƒ¡ãƒ¼ãƒ«/SMSé€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹ãªã©ã€ã•ã¾ã–ã¾ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç°¡å˜ã«çµ±åˆã§ãã‚‹
- **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ**: ã‚¯ãƒ©ã‚¦ãƒ‰APIã«ä¾å­˜ã›ãšã€ã™ã¹ã¦ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ä½œã™ã‚‹ãŸã‚ã€æ˜ åƒãƒ‡ãƒ¼ã‚¿ãŒå¤–éƒ¨ã«é€ä¿¡ã•ã‚Œãšãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãŒä¿è­·ã•ã‚Œã‚‹
- **ä½ã‚³ã‚¹ãƒˆãªæ§‹æˆ**: å¤ã„Androidã‚¹ãƒãƒ›ã‚’IPã‚«ãƒ¡ãƒ©ã¨ã—ã¦å†åˆ©ç”¨ã§ãã€ç‰¹åˆ¥ãªé«˜ä¾¡ãªæ©Ÿæã¯ä¸è¦ã€‚å€‹äººã§ã‚‚æ‰‹è»½ã«è©¦ã›ã‚‹AIç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

And now we're going to watch the drone here. So, it detects me and it flies upright and it tries to intimidate me by moving towards me. Okay, that's pretty scary. And it's just doing this spin move and then it's landing. Okay, so today uh I wanted to do like a small local AI security system because I've been playing around with the Quen 3VL uh vision model lately and it's so good.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

So we can use the 2 billion parameters model and still get like superb results. So as you can see this is kind of the setup I want to try out today with a few different things. So we want a mobile IP video stream. So I thought I can just use my this is just an old Android phone we can use as the camera and we can just stream to our system. We can do some snapshots.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

I thought like every 2 seconds and if you make the image small enough like the resolution the Quen 3 model is like super fast to analyze the image and if you just have like a boolean return like true or false. Let's say we ask is there a person in image and if we just return like a true or false this is super fast as you will see soon and I thought we can just have some different outputs here if it's true we can do x so one of the things we're going to do is if it's uh true then we can launch a drone right because I have this small let me see yeah I have this small drone here so we can launch this if uh ex if it's true and we can sound alarms or different stuff so this can be used for basically anything. And what is pretty cool about using Quen 3VL is that when we use an LLM instead of like a machine learning model to yeah trigger the alarm, I guess uh we can do very specific information as you will see soon. We can say only trigger the alarm if there's a person in a orange jacket or something like that. Uh but we'll get onto that.

### ğŸ“ è©³ç´°èª¬æ˜

So, I thought we can just get started and see kind of how I set this up and check everything out and then we're going to test a few different things, I think. So, I guess I said it in intro, but the model we are using today is the Quen 3 VL. So, this is the most powerful vision language models in the Quen family to date. So, what is pretty cool about this is that we have different sizes. So, I've been testing out both the 2 billion parameter model, the 4B, the 8B.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

The 8B is very good. But for this use case, I think we just need to use the 2B or maybe the 4B because it's a very simple task. We just need to uh is something there. Uh true or false. That's all we need.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

But we could maybe try some other models too. Uh but if you scroll further down here, you can see uh the way we run this. Oh, I guess it's here. It's pretty straightforward. is basically if we're going to use a llama mod, you can just do uh add an image uh with um yeah I guess like a prompt in between but uh we are actually using Python for this uh because we want to run some additional.

### ğŸ¯ å¿œç”¨ä¾‹

So here we kind of have the yeah the Python function for this. So basically you can see we are running the quen 3 VL2B model and we set up like a simple uh input here. Are there analyze if there are any people in the image? If yes, output true. Else output false.

### ğŸ’­ è€ƒå¯Ÿ

And then we just say answer only with true or false because we want fast latency, right? So we just want true or false. That's basically all we need because uh the model has set what is going to be true or false here. Right? So we are using this but I can show you kind of how the model works if you just were to run it in let's say the terminal here.

### ğŸ“Œ ã¾ã¨ã‚

So if I do like a list you can see we have the quen 32 quen 3vl2b here. So let's test that out. So like I said what we can do is just do something like this run quant 2B right so this is the 2B model okay and when we have loaded it uh loaded this model now we can just uh do the prompting here so let's say I had this image here so this is just an image of a GPU right 5090 uh and I just copy the path I just paste in the path here and I can ask a question what is this so remember this is the two billion model and you can kind of see how fast it is. So it has this reasoning model too. This is a Nvidia GeForce 5090 series.

### âœ… çµè«–

Uh yeah, so you can see how fast that was just to analyze a simple image. We can try let's say one more. Here I have an image of an LLM architecture or a transformer. So let me just copy the path of this and we can try this again. And let's just paste this in.

### ğŸ“š è¿½åŠ æƒ…å ±

Uh what is this? Okay. So you can see how fast this is going now. Showing a diagram of a neural network architecture. Okay.

### ğŸ”– è£œè¶³

And I can ask again. Let's try let's try what architecture is this. You can see this architecture shown is the transformerbased sequence model architecture designs for LLM modeling. And yeah it's so fast. I'm running this locally now on my GeForce G RTX 4080.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

So it's not the most optimized model for LLMs, but still this is a super fast 2 billion uh lang uh vision model with some reasoning capabilities as you can see here in the thinking. And I've been having so much fun with this and I think we can do a lot of cool stuff going forward by using this small uh image models. Uh but now I think we're going to plug up the camera and we're going to hook everything up and see what we can do with this. Yeah. uh local AI security system I wanted to try out.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Okay, so like I said uh I was going to use this Android phone here to yeah do the recording. And you can see this is just a standard IP webcam pro we have on this Android phone. Also here's my flipper zero. Might do a video on that soon. So I'm just going to place this phone here now right over here.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

And yeah, we kind of get this outlook. Yeah, I'm going to have to fix that. But we get this outlook over my yeah kind of living room here. And when we have kind of set that up now I can kind of go to this base URL. And here you can see here you can see the setup I have over my living room now.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So if I go like yeah in front of here. Yeah you can see me going in my living room here. Right. So that works pretty good. That's streaming the video all the way down here.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So what we can do now is that we can do snapshot of this. Right. So I can just you can see I set the reason this looks kind of bad is I set the I can't remember where I see that. Yeah, you can see it's 640 * 360 because that is enough for what we going to do today. But we could do higher quality but that that file size isn't that quick if we want to do uh analyze it with the quen 3VL model.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

So I set up like a Python code now. So we log into this and we grab snapshots. So a snapshot could look something like this. I guess I am in this camera from my testing yesterday. But you can see this is a snapshot from this camera.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Right? So basically that is what we're going to do now. And we're just going to run. We're going to run this. We're going to take snapshots and then we're going to see what happens.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So we're going to sound an alarm if we detect a person. So let's test this out now. Okay. So if we do python I guess person detect now this should start running and you can see the images we are capturing now it's going to be camera right we have to load the model first. So you can see no person detected continue monitoring.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

So this is the images we grab now right. So let's see what happens if I go over here now. How fast this is going to go off. So you can see that was instant, right? It detected me and I think we can see in the image now I just barely got into frame.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Uh yeah, up here and still it detected me, right? So that is pretty cool. But what I want to show you now is something we can do with this models now because we can specify that maybe it's only going to um capture a guy wearing a orange jacket or something. So that is what's pretty cool about this AI setup systems. This means that we can do like specialized detection.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

So let me set that up. I'm going to show you how simple that is. So now we just made some small changes. And maybe this is not the optimal way to do it, but it works. So first we're going to just run the same step as last time.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

We're just going to check is there any people in the image. So if that is false, then we're just going to keep continue monitoring. Okay. But if it's true then we have a second step that is called is anyone in the image wearing an orange jacket. And if that is true also.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So we get like true true two booleans then we're going to trigger the alarm. Okay. So let's see if that works now. So the first thing I'm going to do is I'm going to walk in front here uh without my where is it? Here orange jacket and see if the alarm goes off and then I'm going to put it on and try again.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

Okay. So, let me just uh yeah, it's probably going to be the same thing. So, I'm just going to do go here, clear this, and let's do the same. So, let's see now. So, let's grab our camera here.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

And you can see no people detected. Okay, that's good. So, let's see what happens if I go in with no orange jacket. So you can see now we have people detected but no orange jacket. So that's pretty cool.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So let me go back here now and put on my jacket. So now you can see I put my jacket on, right? And let's see what happens now. Okay, so that works, right? So now it detected that was there was a person there and it were an orange jacket.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

So that is pretty cool because now we can kind of specialize our detection system to look for like very specific things by just a line of text, right? Instead of having to do this bounding boxes training special. Yeah, I don't know machine learning models just to look for one specific thing. We can just do that with one string of text, right? So, I have another variant before we look at the drone setup.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Uh, I want to show you. So, one other thing I did mention is that this system also has like a log. So, you can see person in orange jacket detected. We have the exact time, snapshot number, and camera. And it has like a yeah, description of what happened.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So this is like a logging of everything that happened. I guess that's it just in text, right? But uh of course you can work more on this, but I just added it. But I wanted to show you is uh something similar, but this is just going to detect if my blinds or curtains, I guess it's called, are closed or open. So it's basically the same, but this time uh we can just use the 4B model just for some more accuracy.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So we are running the 4B model both times and I tried this and it was a bit more accurate. So that's why I went with this. So let's do Python blinds detect. So this is now just looking for if the curtains are open or closed. And if you look at the image it takes.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Yeah, you can see the curs curtains are open. So let's let me just go over there and close them and see if we trigger the alarm. Okay. So you can see me in the images now, right? I guess.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Yeah, I don't know if I'm on the right image. Let me fix that. So I can just close them. And let's see how fast this goes now. Like this.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

And there's the alarm. Right. So this works very good. It doesn't really take long before the image. We have a snapshot every two seconds and the image register.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Okay, the blinds are closed. Let's trigger the alarm. And this is this can trigger anything. This could send me an email. This could send me an SMS.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

This could do whatever X you want it to do. So that is what we're going to look at next. When we detect a person coming into the room, we're going to fire up our drone to scare them away. Right? That is going to be the next thing we're going to do.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

Okay. So, if we go into the drone alarm uh setup, we can see we have this same detect orange jacket here. So, this will only go off if the person is wearing an orange jacket. Okay, that's fine. So, but what is different here is that we have uh our drone set up too.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

So when the alarm is kind of armed, the drone is ready to take off the second almost a person is detected and it's just going to fly up like 50 cm or something. Uh or was it maybe 1 m. You will see when it detects a person with an orange jacket in the frame, right? And yeah, it's basically a combination of the drone uh code we had last time, but it's only going to trigger when we have the boolean set to true here on our Q uh quen 3 VLM output. Okay, so let's just fire this up and we shouldn't have any issues with that uh right uh from the bat here.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

So, let me just pick up the drone and I'm just going to reset the drone here. Okay. So, yeah, the drone is ready to go. Let's just adjust that. And let's just place the drone now.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

So, let's say the camera is there and the drone is sitting. Yeah, we can just place the drone here. Here for now. That's fine. Okay.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So, we have the drone over there. So, let's see what happens now if we run this. So that's going to be Python rollarm.py. Okay. So let's run this.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

So if we go to our camera again, you can see, yeah, that was the old image because now we have to arm the drone first. And you can see over there the drone is now armed. It's blinking yellow. Perfect. And you can see now there's no people.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

So let's see what happens if I go in without my jacket now. Okay. So, you can see it's detecting a person, but not it. The drone is not attacking, right? But let's say I put on my jacket.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

So, now I have my jacket on. Okay. So, let's go back. And now we're going to watch the drone here. So, it detects me and it flies up, right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

and it tries to intimidate me by moving towards me. Okay, that's pretty scary and it's just doing this spin move and then it's landing. That is basically all it's going to do. So, let's say you had this drone armed here ready if someone comes in the room that has like this orange jacket, it's just going to fly up and scare them away or something. So, that is one thing I tried and I thought it was pretty cool.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

So, I think this is just the beginning of things I want to do with uh these local llms. We can do API LLMs and just a bunch of other things we're going to do by trying to connect this to hardware stuff. So, I got my flipper zero, too. So, I think we're going to try to do something with that in upcoming videos. I have a bunch of other ideas with hardware.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

I might get looking into getting like a Raspberry Pi, building our own, maybe some kind of with some cameras, maybe trying to get a camera on the drone for some more stuff we can do. And I've just been having so much fun playing around with uh yeah, using AI models to also run the documentation to just get started and learn more what we can do with stuff as we did in the previous video with the drone. And it's just so much fun when you have these LLMs to assist you in making stuff like this. And kind of I feel some kind time that the opportunities are kind of endless what we can do. It's just I just got to think of it.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

And by using this Quen model here, the 2B one is just so good for the size of this. And the 81 8B one is amazing. So definitely go check this out. And I'm just running it locally on my the MacBook or I can run it on the on the desktop. And it should also work on like small local machines like the Nvidia GGX if you wanted to do the Jetet Nano or some other small maybe the Raspberry Pi 2 we're going to try out.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

So yeah, that is kind of going to be something I'm going to follow up in in the next few videos trying to do some more hardware LLM crossover stuff. It's just so much fun. So, I hope you enjoy it and I hope this gave you some inspiration what you can do. So, yeah, thank you for tuning in.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ28æ—¥

</div>
