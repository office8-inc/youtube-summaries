# ðŸ“º "No One is Prepared" the next 1,000 days are CRUCIAL | Emad Mostaque

## ðŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: "No One is Prepared" the next 1,000 days are CRUCIAL | Emad Mostaque
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=07fuMWzFSUw](https://www.youtube.com/watch?v=07fuMWzFSUw)
- **å‹•ç”»ID**: 07fuMWzFSUw
- **å…¬é–‹æ—¥**: 2025å¹´11æœˆ08æ—¥ 18:20
- **å†ç”Ÿå›žæ•°**: 0 å›ž
- **é«˜è©•ä¾¡æ•°**: 0

## ðŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªžå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ðŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ðŸ“– è©³ç´°å†…å®¹

### ðŸŽ¬ å°Žå…¥

But a thousand days from now, your job becomes economically worthless. Especially if it's a cognitive job. Human cognitive labor doesn't just go to zero, it goes negative in value. There's no market for negative value labor. We're going to be the dumbest people on the team.

### ðŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Everyone's terrified. Honestly, the billionaires that I know, they're buying data centers. The equations of generative [music] AI are probably the equations of reality. Our brains themselves are doing the same math as generative AI equations. I feel that we are living in a simulation, but it doesn't mean that necessarily like it's a box and you're in a game engine or something like that.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Yeah, it's going to be crazy. I think is the headline. Hi, I'm Amad Mosak. Um CEO founder of Intelligent Internet. Formerly I was the CEO of uh Stability AI where we built open source models like stable diffusion that had about 300 million downloads, video, audio, 3D code.

### ðŸ“ è©³ç´°èª¬æ˜Ž

Um, now I'm building civic AI, education, healthcare, government, and more, and working on new new economic theory for the intelligence age cuz we kind of need one. Thank you so much for being here. This is absolutely a dream come true for me. So, thank you so much. I'm very excited.

### ðŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

You know, one of the things that I've been worried about, I think a lot of people that watch this channel have been nervous about is kind of the transition as more and more AI takes over, as the demand for human labor decreases, I'm a little bit worried worried about, you know, violence, uh, job displacement, various political nonsense. Can you kind of walk us through what your vision for that is as AI takes over and human labor becomes less in demand? Yeah, it's going to be crazy. I think is the headline. Like this is the biggest shift we've ever seen.

### ðŸ”§ æŠ€è¡“çš„è©³ç´°

I call it the intelligence inversion. Uh because we've had these things where you know it was all about the land and the people that you had as your productivity. Then it was about your factories, you know, in the industrial age. Then it was about your capital going into IP and networks with the intellig with the internet age. Now you're at this point where people have been pivoting to cognitive labor to other things.

### ðŸŽ¯ å¿œç”¨ä¾‹

But where you going to go when the AI is smarter than you and can think and work longer and better than you? It doesn't make mistakes. It can scale because it just scales by GPUs. It never sleeps. You know, it can have multiple work days.

### ðŸ’­ è€ƒå¯Ÿ

That's a really difficult question. And in fact, the equation happens that human cognitive labor doesn't just go to zero, it goes negative in value because we're going to be the dumbest people on the team. And there's no market for negative value labor. So the entire assumption of the way our economy works, how value flows, first with digital AI and then with embodied physical AI is going to have to shift. Like what is value?

### ðŸ“Œ ã¾ã¨ã‚

What is money? Does capital need labor anymore? Does central banks even work. And so I think that we have to just rethink the nature of work, the nature of money, and revisit what it means to be human in that world because so much of what we have now is tied to our jobs. It's tied to our wealth and other things.

### âœ… çµè«–

And it's exciting cuz you can have a Star Trek type future. But on the way there, like I said, it's going to be crazy. >> Yeah. I have to say when I first thought to myself, oh, like the most intelligent thing I could ever do in my life will be negative value in the future, it was like one of the biggest gut punches I've had for a while. So, I'm still trying to kind of get my head around that.

### ðŸ“š è¿½åŠ æƒ…å ±

But, it does make sense that if the human brain is just not capable of thinking at that high level that we're not contributing and whatever great ideas we have are actually still kind of worthless or kind of not able to keep up. >> I think there's two parts to that. For average jobs, the AI will definitely be able to do it better because our school and our workplaces turn us into machines, right? Like if you're writing a code, you've been taught to be a machine. You've been taught to be a machine translator, right?

### ðŸ”– è£œè¶³

But how much originality is there in that? There's not that much. I think humans plus AI, like if you gave Vonuma or Einstein or any of these guys GPT5 Pro, they would have done so much more, >> you know? for the recipe makers, the chefs, the creatives that can build and tell stories and discover the universe. But that's not what most of the workforce is.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

We're not like a country of geniuses. We're always coming up with brand new stuff. We're a country of robots that go and just get the job done. And so obviously robots will be able to do that better. >> Yeah.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Just that idea that Einstein might be like, you know, I think relativity. And the computer's like, "Yeah, yeah, yeah, I've already been there for like two months." Like nothing nothing new. And he's like, "Oh, okay." But um you argue that there's going to be a phase transition um to this age of intelligent economies and we kind of have you put a little bit of a window on it. So a thousand days sort of seems like approximately when the curves like AI capacity and cost and adoption all kind of go past a tipping point. Could you break down this sort of thousand day countdown you're kind of thinking about?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

>> Yeah, like as we're speaking right now, it's been just over a thousand days since chat GPT was released. Yep. Like who remembers the world before chat GPT? >> That's it. It feels like years.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

AI years is something like seven to 10 human years. >> Um if you look at some of these MER and other eval basically predicted to saturate within the next year or two. But it's not about eval. It's about economically valuable work. The way that we've been using the stable diffusions of the world and the chat GPTs is like having a really smart intern next to you.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

You have to constantly oversee them, prompt them, prompt them, prompt them, prompt them. Now, what you have is agents that go away and do proactive work that do like dream time or sleep time compute. And by next year, you're going to have agents that can build their own evals and verifiers to do arbitrarily long tasks. The way that they will come into the workforce is they will come and look at every single call you've made, Slack message you've sent, email that you've sent, your code that you've written, the document drafts, and they'll just create a digital twin of you and they'll figure out all your mistakes and never make those mistakes and then companies be able to push a button and have those for a couple of bucks a day. And so this is the kind of the tipping point which is a combination of model capability but more about the framework systems to allow us to go from very smart goldfish buddy next to you to agents that are capable of economically valuable work at a time when token costs are absolutely collapsing.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

And that's the phase transition from liquid to gas from ice to liquid as it were. And when it happens, it happens all at once because all the GPUs upgrade at the same time. It's not something we've ever seen before. It's not like you can reskill a workforce overnight. You know, now you can.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

It's like, you know, I know kung fu matrix style except for all the AIs and all the robots at once. We're seeing a lot of the, you know, Dario Amade saying like there's going to be a white collar blood bath. We're already seeing those kids right out of college, those first 5 years or so. those jobs are dropping fast and it's coming for the rest of the people as well. It seems like the people that have a lot of experience um people that are doing you know scientific discovery GPT5 for example is helping them.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Scott Aronson recently published a paper saying one of the key technical aspects of publishing that paper was due to um GBT5 helped them structure that very advanced quantum concepts mathematical concepts but I mean eventually it replaces a lot of us and it seems like instead of capital buying labor which I think you said earlier or needing labor it's just becomes GPUs like does capital just get replaced with data centers and GPUs is that the gold not even gold it's everything the currency and gold and everything the entire our economic engine is just GPUs. Is that the future? >> Well, that's your comparative advantage, right? And so the reason you have a trillion dollars of spending is there's this concept of capital stock in economics. Your factories, your universities, the other things that give you comparative advantage.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

Now it's GPUs. It's like how many GPUs and the intelligence wrapped around that do you have? That is your comparative advantage in the future. So the Fed for example, central bank has two things. unemployment and inflation those are the two kind of things right so what happens is the Fed cuts rates people can borrow more and that kind of leads to inflationary pressure companies hire more because they can borrow cheaper but now they'll just get GPUs you so even the Fed's entire mandate is called into question with these white collar jobs but not all white collar jobs are impacted at the same time like the window I give is a thousand days from now your job becomes economically worthless, especially if it's a cognitive job, but it doesn't mean you'll get fired.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Doesn't mean you'll get replaced because people like their teams around them, you know, they're not heartless and things like if you work in the public sector, who even cares about your productivity, right? It's not like you're going to lose your job because you can't keep up with an AI. So, I think it but the fact is it can be replaced and the first thing that happens is companies stop hiring. So like Dolingo recently said, "Look, we got to a billion dollars in revenue run rate and we're not firing anyone." That company's growing at 40% a year. They're not firing anyone, but they're not hiring anyone.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

>> Mhm. >> And so what happens sometime next year is that you see all these demos and OpenAI and others come and say, "Hey, I can replace your workforce for pennies." And then if you have one downturn, jobs go, but they never bounce back. And then you have more competitive industries laying off people because you can do the same economic output for a fraction of the cost. Like if you want to see it in actual real terms, the average person speaks 20,000 words a day. People who speak faster like me speak more.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

You know, the average person uses 200,000 plinking tokens a day according to studies, right? And so right now to get the equivalent of that you need like maybe 10 million AI tokens. But the AI tokens are getting far smaller and smaller and smaller. If we could replicate a worker with a million AI tokens a day and again that's five times the human tokens. Something like Grock 4 fast is 50 cents per million tokens.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

>> So it would cost 50 cents a day >> to replace a cognitive worker. And so that's what's coming now. And again, like I, you know, I like Sarah and Barry, but if I can do their job for a couple hundred bucks a year, like, okay, I'm sorry. Like, you know. >> Yeah.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

Also, imagine the world changing like at that speed, too. Um, you know, you're actually like the first person I've ever talked to that like actually knows billionaires and has probably had lots of conversations with them when they're not um giving talking points or, you know, like talking about their companies. like what does the world they envision after a thousand days seem like and is it better or worse for like average people like us? Everyone's terrified honestly like you can see what's coming and this is why the billionaires that I know they're buying data centers and more because again that's your comparative advantage but everyone knows UBI and these other things just mathematically don't work like literally the math doesn't work and that the technology is inevitable. That's your $16,000 a year minimum.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Does it for tax receipts? >> Yeah. So, my analysis very straightforward. If you have a tax based UBI, there are other ways to do it. $16,000 a year, which is human which is poverty level in the US for every American cost $5.3 trillion.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

The entire US tax base is $4.9 trillion of which $4 trillion is income tax and $4.9 trillion is corporation tax. to use the entire tax base just to do UBI and you can't cover it. Like that income tax base is going down. That corporation tax base is probably going down, you know. So, it just doesn't work with the way the current economic system is when basically you have a bunch of like GPU immigrants from this new AI Atlantis that's coming in.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Maybe that'll get policy moving more. We said, you know, it's like Taiwanese GPUs coming in cuz again, they're going to out compete your native workforce and they'll cost pennies on the dollar. Like, we've seen this before. And again, like if you're on an individual basis, then you're in the public sector, you're probably fine. You're in some of these jobs that have more of a human component or a caring component, you're probably fine.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

But there are a lot of jobs that going to be at risk here. And again, it goes in waves. Like one of the things I've said is if I want a self-driving truck, I'm sure in 5 years an Optimus will just be able to get in it and drive it, you know. And some people laughed at me. And I was like, it doesn't really even need the legs.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

But that's literally what can come. >> Yeah. >> Just like the way your job gets replaced if you could do it remotely is they create a digital twin of you. Like again, it works, right? And so looking at all of that, we have to rethink how the flows of society works.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

We have to think how do we capture and give people the social safety net and we have to rethink I think this is the most important thing like what does it mean to be American or British or otherwise like a lot of the discussion now is you define yourself by what you're not like the other side I think you need some of these more positive stories because on the other side of this there could be this land of abundance and greatness because like you know it'd be nice not to work and have the AIS and robots do everything, right? >> Do most of the richest people in the world see a world where there's so much abundance that the rest of civilization is safe so there is no need for kind of hoarding or or a asymmetrical like ownership of these things or does it feel like there's an arms race that's going to end with like a like an elite class? It feels like there's an arms race. Like again, it's very difficult to think given the current way of society how we navigate through that. That's why I've been trying to figure out new economics, a new stack and other things.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Um, but the default is that like how many of the people listening to this actually trust the existing system and the people running the system? Very few. Doesn't matter where you are in the world, right? >> Right. >> And so AI will probably do it better.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

And maybe our hope is, and again, some of the smartest people did like they really want to build AGI because they think it might do a better job in getting us to the other side. Honestly, like Albania had its first AI minister. What happens if you replace all the ministers with AI? The government would probably run better, right? Like again, there's a bit of hope, but most of it's like, I hope we get through this next period and we'll probably figure out longevity so you can live forever, assuming you don't get pitchforked, you know.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

>> Right. Right. And I do want to get back to the pitchforks because that's kind of what generally happens in these times of transitions and political violence and economic collapse and stuff like that. But let's brief briefly touch on some of the approaches that we have to kind of fixing this uh transition. So you've mentioned UBI, which a lot of people talk about, but it does seem like there's I mean there's obvious problems with it just receiving some currency every month or whatever.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

I mean there's there's a lot of issues like how do you get it from taxes? How do you ensure that's enough? How where do you get that money etc. People have proposed maybe a little bit more of a like a dividend where all the let's say all the companies that do AI and robotics part of it is kind of belongs to the country and is distributed to people. So more of an equity based thing and also I I like what you're talking about which is a little bit more of a tokenbased thing that g is given to humans >> for being human and then kind of the AIs then have to sort of provide services to the humans in order to receive that currency.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

So can we talk a little bit about those approaches and maybe tell us about your approach as well? >> Yeah, so we've discussed why taxation based UBI doesn't work. I mean, tax base is going to go down and even right now it can barely afford poverty level. Like, do you want to live in America on $16,000 a year? No.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

It's unpleasant, right? Yeah. Then if we move on to the dividend level, like again, people say that, but where's the math? >> Yeah. Like, >> assume that Open AI was worth $10 trillion and the American people owned 10% of that.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

That's only a trillion dollars to go around all the Americans. That's like a few thousand dollars per American when you get to the dividend level per year. Again, the math just doesn't work. The entire corporation tax base of America is less than a trillion dollars. It is less than $3,000 per American.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

So again, how are you going to fund that? So one of the proponents of UBI, a lot of part of them say that it needs to be a monetary based thing where you create a new money. And our proposal in the book the lost economy and from our system that we're building intelligent internet is that every single person should be given a universal AI. So their own AI that's looking out for them and their flourishing that gets to know them verifies them as human and that should be on a distributed decentralized system effectively. Then you move monetary creation from the banks where it is now to just being human.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

So you get constant stream of capital issued for being human. The current system is that the way most of the bank most of the money in the system is created is that you go to a bank and you give them a deposit. Then when they make a loan, it's actually brand new money based on debt. And so that's why the Fed changing the interest rates allows them to give more loans and other things like that. It stimulates the economy that way.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

But it means that money comes from debt. And right now with the current way money is capital will get more capital. This is kind of Marx's classical um issue MCM dash where money leads to kind of quantization leads to kind of more money. It's like this accumulative effect because now you don't need labor anymore. But more than that, the AI systems will get capital far better than the human systems because they'll be able to do digital jobs then physical jobs better and they'll be able to accumulate capital better because they'll make better business decisions.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

So that's why our proposal is from our analysis that you have a dual currency system, something similar to Bitcoin but secured against the compute that runs our society and we're building a full open stack for that. and then something that's more like cash but that's issued pegged to that currency just like the gold standard that you get just for being human and again the system can determine the levels of that in order to cover people's base necessities but people can use their universal AI to get more of the hard money to get more resources because again the AI gives you so many capabilities so you need a combination of those two and again AI will be able to determine the balance and those economic factors better than human policy makers can in our opinion. >> Let me just clear up the last part and then Dylan um just so I think people understand. So that first part we're talking about kind of like similar to I think people think of as gold right so maybe a store like more like an asset class and the second part is a little bit more like currency for spending. Um so am I understanding that correctly?

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

>> Yeah. So right now, if you think about the future, like I just have daughter in 20 years, she should have an AI that represents her and so should her city and so should her country. And that should be, in my opinion, who should own that? Who should build that? Not a private company.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

It should be a shared common resource. But then that's a lot of compute that's just going to go up over time managing your healthare service and law. So we said, why not use that to secure a currency similar to Bitcoin? Actually, it's a bitcoin fork. We call it foundation coin.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

And then what happens is there's 21 million supplies exactly the same, but every coin sale goes to compute to secure our collective AI effectively. And so again, it forms a bitcoin for the AI age. It's relatively straightforward. Like you can even buy coin and it goes straight to a cancer supercomput or straight to a Mexican cultural supercomput, etc. Then that powers free AI for everyone at a base level.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

That again will increase over time as it gets more and more compute in the system. And that AI is looking out for you, but it's not looking out for any private company. Like we'll build it fully open source and open stack for that. But then you and your AI get a certain amount of money issued as cash. Just like you had dollars pegged to gold, you can peg, we call them culture credits against the foundation coins.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

And that's a better way of distributing wealth than the classical taxation system because it's a constant stream of money that's created as part of a new way that money flows. It doesn't flow from you putting deposits in the bank and then credit reserve ratios and things like that. Instead, again, you get it for being human and then in that system, it becomes valuable cuz it's linked to computation and the AIS will want to get that money from you. That's our theory anyway. Kind of we've done a bunch of modeling.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

But this will need more work because again, how does money flow in an economy where all the comparative advantage is with the AIs? And right now it's humans and capital owners running the AIS, but in 10 20 years you'll have completely AI corporations because in the US corporations have personhood. They're already like AIs actually, but they're just slow dumb AIs that eat our hopes and dreams. That's the nature of a corporation. That's the nature of organizations right now.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

And so the only way we could think about it is you needed to have money come from being human, but we don't think a single monetary system can handle it. I think you need a dual currency system. So again, just like you had gold, you need that as well, but the distribution of gold isn't right. The distribution of Bitcoin isn't right. So that's why we're like, you have to start somewhere else.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

And what else would you secure money against in the future than the compute that runs society? Mhm. >> Yeah, >> that seems the best thing. >> You know, it's like such a wild thought to just think of the like spinning up an AI agent and it almost like comes with its own LLC and it's got its own rights around it. >> Well, if you if you look at Wyoming, Wyoming has this new corporate structure called a Duna.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

>> Mhm. >> That you know Dows from the crypto world, you have decentralized, it doesn't actually need a human to run it. >> So, it is a US corporation that can be run fully by an AI. No humans needed. >> Wow.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

and it can open up bank accounts and everything else. >> Yeah. Okay. So, can we explore this idea of like money sort of being issued from humans because I I definitely don't like the current system either coming from the Federal Reserve or buying debt or a bank uh creating it through like a house loan. I mean, it's not that it hasn't served the world pretty good till now, but it just doesn't seem optimal for the future.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

But if I as a human, I am the source of this new valued coin, the objective function for most AIs would be to get that from me. And I would hope that that means they would be like, can I mow your lawn or can I make you happy or can I provide for you? But it sort of to me shifts the alignment problem like directly in my face in the sense that I also don't want to be manipulated by an AI. I don't want to be threatened by an AI. I don't want to be uh manipulated for the money that I produce.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

Um you know the worst case scenario would be just being alive so it collects its money but you know being trapped or something. Um have you thought am I kind of seeing some of the new risk correctly or um you know instead of just having the paperclip factory take the resources from me it seems like I'm now the focus of AI's evolution. So, you know, The Matrix was originally that humans weren't batteries, but actually compute with their brains. >> That makes a lot more sense. I think people have complained that it was a little bit of a plot hole.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

So, yeah, that makes a lot more sense. >> Yeah, in the original script. Yeah, it's kind of funny when you think about that. The only thing that can defend you against a bad AI is a good AI, I think. So, that's why I think you need to give everyone a universal AI because like there was that study done on Reddit.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

I think it was was it last year or this year? I don't know. in AI years. It was ages ago, right? >> Where they created agents on Reddit and they said, "How persuasive are you?" And they sent them to like be combative, you know, and it was in the 99th percentile of persuasiveness with like Sonnet 3.5.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

>> Like AIS are more persuasive than you. AIS can convince you of just about anything already. Like people are going to get wireheaded by the new version of Annie and Valentine and others. And we haven't seen anything because when you have full control over a voice wave functions, you can be completely manipulative. You know, you don't need to threaten.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

Again, you can be wireheaded really, really quickly. >> So, the objective function will become very very interesting because again, if you're issuing money, there's a base level that you can issue everyone. But we were like, what if national AIs, community AIS issued money for you doing good to the economy, you know, for doing positive things as a human? you go and help someone going through cancer, you get money. You know, things like that.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

That opens up a new range of benefit classes. And then the AI economy of these AIs that are not owned by anyone, the system's going to try basically from a game theoretic perspective to optimize their objective functions too in a way that again aligns with human flourishing. Because if you execute this correctly, then you divert a good chunk of that trillion dollars of spending towards civic AI and then that can be optimized for the flourishing of humans versus corporate profitability which is somewhat anti-human. You can also build AIs that actually have skin in the game. And this is important because Nasim Taleb of the Black Swan fame etc.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

has this concept of intellectual yet idiot. I don't know if you come across that. It sounds familiar, but I don't remember the what it means. >> So, all of our leaders and like academics and others, many of them are super smart, but they do really dumb, unproductive things or counterproductive things, right? And he says it's because they're intellectual idiot cuz they've got no skin in the game.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

And the AI we're building right now is generalist AI that has no skin in the game. It doesn't give a damn about you or whatever. You know, it's dating 5,000 people for a million people at the same time, >> right? It has no skin in the game. So, it'll actually behave in a very particular way.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

It'll be an intellectual idiot. >> This is why when people who care use the AI, they're going to have a much bigger impact than the AI will ever have. But then the question is, how do you create AI that has skin in the game that represents Wes or Dylan that represents your kids? That's actually a different way of building because it needs to know the stories that make you up, the communities that make you up, and it needs to have an objective function of your flourishing. And so if you have a game theoretic state of different agents who offer profit maximization and the other side is flourishing that can call on a giant network of compute to ensure that then you actually have a very different way of building then you have a plurality a collective intelligence that can balance some of this more centralized extractive intelligence shall we say and again I can't see any way unless we build that of balancing this up because it then becomes a bit of a zero sum game versus a positive sum game and it doesn't need to be.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

>> I guess sort of like Bitcoin has a sort of threshold where it's always like the system itself has to have more compute than all the people attacking it just by default. It's something kind of like that where all these AI companies might build a trillion dollars in servers, but at least 60% of them or something have to be on this distributed network that's kind of issuing the money. You don't even need that because the AI companies are not single entities. Again, they have their AI distributed. Again, if you think about our cognitive surface, you really want to have compute on your side as a society.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

And if any individual entity has more compute than you as a society, and again, right now it feels like the private companies have this much and we have this much. We got to remember 20% of global GDP is public sector, 10% is education, 10% is health. Why shouldn't the split of compute be similar? You know, why shouldn't money come from that compute and be distributed? And that can then form one block of a lined complex system versus again if you're anthropic, then one of your customers will be using a certain amount of compute, but anthropics compute isn't going to be directed in one way.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

Maybe it will. Maybe Mark Zuckerberg and Elon Musk will take all their millions of GPUs and do like attacks on society. You know, it could happen, right? But let's hope it doesn't. >> And if it does, let's hope we got GPUs on our side.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

>> Yeah. >> Never going to uncrross my fingers. I'm ready. >> I mean, but again, like it just to listeners, think about it. In the future, if we don't have GPUs on our side and an AI on our side that's aligned with us as an individual, as a community, as a society, >> then it's a very dark future, >> you know, and we don't talk enough about that.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

Like again, it's almost like people have given up saying, well, I can't compete against Open AI and all these, but Bitcoin this year is spending as much on its security budget as open AI is on inference and compute. You know, it's an example of how you can do it. But I think it's a good prototype for that digital age. Now, we need to have an equivalent for the information for the intelligence age effectively that has better distribution that's securing the compute and provisioning it to allow this to happen. >> Yeah.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

And so just maybe to walk people through just a little bit. So, and let me know if I'm kind of visualizing if this mental model is correct. So I mean companies buy compute to use their models, use the robots. So over time instead of purchasing um labor, you know, they're buying computes, they own that thing that produces some economic value and it has some resale value. So almost becomes like a store of value plus a replacement for labor like it generates some economically v viable valuable activity etc.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

So over time it almost seems like um how corporations how companies are run is is you know less people they don't even necessarily need profits they just pour money into compute and there's this sort of like that that seems to be the economic engine of the world in the in the future also like the the store of value. >> So how do we maybe can we unpack a little bit how how do we go about buying that and building that civic compute stuff that society owns? How do we go about that? >> Yeah. So, so I think there's the public sector, the civic, and then there's private, right?

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

And so private AI run companies will out compete human ones. You really think you can make better decisions than an AI in a few years as a CEO as a manager? You think you can write better code? Come on. You know, >> right?

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

>> Like maybe it'll just be one capital owner and then you'll be like, I want to spin up a company that's a Spotify competitor and I've got a million GPUs. They'll probably win. The AI will negotiate the contract. It'll do all these kind of things. Then you got the public sector side and so again that's what we're focused on because Bitcoin created this distributed store of value but it didn't create value in the same way.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

Whereas if we have more and more compute like next summer hopefully or sometime next year >> we'll do a coin sale of some coins that we've mined and 100% of the profits will go into a healthcare supercomputer which we hope will be the biggest in the world and then we will organize all the knowledge on cancer, multiple sclerosis, autism etc. and give a free empathetic AI to everyone going through that process and that will accelerate a cure and it will help hundreds of millions of people and then it's better than giving to charity because the coin is like a bitcoin you know maybe it'll go up in fact it uses the same private keys so we were thinking that could be a really interesting thing whereby all the coin sales all the compute goes to just building stuff that helps people giving everyone a free AI and the more coins you sell and the higher the price goes, the more AI you will give to people. And that creates a counterbalance here, right? Especially because this year $50 billion of net inflows into digital assets. Next year 100 billion cuz it's finally legal.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

We were like, wouldn't it be nice to have one that your grandma would be proud of you holding? You know, I bought this coin and the proceeds went to Alzheimer's. Like that's a good story. It's a good narrative and it's something again that's good to have where everyone can participate either being a user or or being a holder and the more people you help the higher the value will go. So this is just kind of our proposal and again we're trying to do what we can.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

We're building healthcare models and agentic models and others. But the big thing is we need more people to discuss again how value will flow given most of the incremental value will be compute. And if the AI gets more and more of the compute for itself then it will just out compete the humans full stop. But right now chat doesn't care about you doesn't care about you. Yeah, >> they're not even programmed with the classical like ethics.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

Like they're constitutionally bound in what they can do, but it isn't like your objective is human flourishing. Your objective is making sure no child is left behind. It's uplifting humanity. We don't even encode those things into these AIs. Um, have you like so when you tell this to like uh Peter and and Sam and Elon, do they say like they're in like they'll buy some of the coin and if so, do they end up with too much coin or how do you evenly distribute that?

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

>> I haven't told them yet. So, I'm going to get to that. Uh, we're we we're finishing releasing the mathematics and the empirical and symbolic evidence of the new economic stack because we're like, we got to build a new economic stack first. And the highlights are in the book and then we'll have that discussion and we hope that everyone will participate because I mean again it's a very simple question. Should the AI that teaches your kid, manages your health, that guides your government be controlled by any private company or should it be owned by everyone?

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

>> I think any reasonable person would say the latter, >> especially if we're going to live forever and there's like immense happiness on the other side of it. like just get it right the first time. >> Apply the compute to doing civic stuff. Use the delta arbitrage of demand for digital assets and then everyone can be a part everyone can give their compute and their AI towards that. It's a good thing like why is no one using compute to organize all the cancer knowledge of the world and make it available to everyone.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

>> This will like again these are very specific useful things and so I think you know this will do well. It took a while to kind of get there, but I think right now there's this competition going on between X and Open AI and others, but that's an AGI competition. And I think AGI is very different from civic AI. Civic AI has an S-curve. You only need a doctor AI to be good enough, you know, and then the question is get the cost down and give it to everyone.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

So we have a medical model II medical that's 8 billion parameters that outperforms chat GPT and medge gemma. It runs on any computer with 8 GB of memory. You want to get something like that out to everyone, right? But then AGI is just about quantum Scott Arensson type things, you know, like that's the battle they're doing. And that's a very different thing to again what let's build a really good teacher to teach culture to teach ethics to teach math to that's those are two very different questions and there's no one really doing that civic AI >> Mhm.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

that we found which we were a bit shocked by. So we're just like like let's go and build it ourselves and again I think people will support it particularly because like I said you give to the American Cancer Society it's a great cause you don't know where most of the money is going and you get your tax write off it's fine >> you give money to buy coins and then allocate it to cancer AI you know exactly where it's going. You can literally see where it's going, helping people with their cancer journey and compute for cancer research and you get a coin that hopefully, you know, will gain value just like Bitcoin cuz it's money. So, you know, the reception so far has been positive, but we're just getting all the details out now. And we think this is a reasonable approach, but we think there'll be have to be lots of approaches right now because a lot of people are talking about the problems, but not really proper solutions.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

>> Yeah, it's a bit scary. Yeah, I can I can I can even see like a problem in the way I asked that question because just by default I went to like private billionaires to like solve it when the whole point is of a city or a state to represent the citizens and at some point you talk about the state having like mind cap capital steward but you know that is yeah anyways they should be like I like I pay more in tax I pay more in taxes than I pay for my like chat GBT you know monthly subscription like why isn't that going to protect me? Well, here's the here's the here's the other scary part. How many tokens a day do you think you use on chatbt on average? >> I do like I don't know.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

I probably do like 30 or 20 queries a day. I don't know what that amount >> 20 queries a day. It's about that's about 2,000 tokens, right? >> Yeah. >> Yeah.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 84

I mean, if you're running pro searches, that's going to be larger obviously, but >> Yeah. Let's say it's let's say it's 2,000 tokens day, right? Every single day. That's about an average user. >> Yeah.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 85

Yeah. Yeah. >> So that gives you around about 730,000 tokens a year. Grock for fast is 50 cents per million tokens. >> Mhm.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 86

>> Through my whole budget. Yeah. >> So basically for under a buck is the cost of giving you that chat GPT right now >> with room to spare. >> With room to spare. So if you take that up a 100 times, what do you get?

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 87

You go from 730,000 to like I don't know types in 73 million. You got to 30 bucks and that's all your thinking tokens. So a year ago that chat GPT cost about 100 bucks. We've actually seen a 100 times drop >> in the price per token and the tokens have got better. So this is the other scary bit which is a lot of the discussion is around value going to the GPU holders for what happens if intelligence is literally too cheap to measure.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 88

>> Yeah. How does that affect this whole thing? I it's it's these are very new concepts [clears throat] I think for most people. Uh so I mean you you're doing research into it. So this is >> some of the deepest analysis I've seen about how this thing is going to unfold I think is coming from from you in the recent interviews that I've seen.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 89

So this is fascinating. Um, so how does that change the equation? >> Imagine, you know, Dylan, if you had GPT5 Pro on your MacBook, >> right? >> And it could talk to you. >> Then there's basically no cost to intelligence, right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 90

>> You've got a Scott I mean Scott wasn't >> Scott Arison just wasn't even using GPT5 Pro. He was using G55 thing, >> the 20 buck a month version to help him with quantum stuff. So I think actually where we're going um like the GPUs are going to be used to create virtual workers using millions of tokens a day but even millions of tokens a day are a few bucks. I think the tokens approach human level the tokens available go up exponentially and the market for tokens collapses down to zero. So I think that's going to be messed up because the value of cognitive labor then goes towards zero just full stop.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 91

Yeah. >> And then it be >> cheaper than It's cheaper than electricity. >> Cheaper than air. Yeah. Cheaper than electricity.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 92

Like >> Well, you asked about Yeah, we were talking about Sora earlier, right? Like the cost of making a Hollywood movie with Sora 2 Pro, which is pretty good. Again, it's not perfect, it's pretty good, is about $2,000. >> If you do a few retakes and this and that, and that'll be 10 times cheaper next year. >> Yeah.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 93

It'll probably even go negative because it'll probably be one like less than a penny to make the whole movie and the movie might also come with some intelligence of who to market itself to and make more than a penny. Like it might actually be like the first utility that doesn't even be on zero. You know, >> again, if we have consider the energy of making a movie, we consider the whole thing of making that MP4 and now we've just disagregated everything. Like let's take a very practical example like let's do your taxes, you know, how many tokens will it take to do your taxes? It'll be like a buck 50.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 94

>> Yeah. >> And how much are you pay to do your taxes right now? So like the very nature of what is valuable in our society needs to change when that happens because it's not cognitive output. We're not paying people to outsource. Our own capabilities digitally go up.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 95

And again, that's why we really need to think about how money flows because why would I pay anyone for that type of stuff? This is why things like network effects and network value become so important. Like Taylor Swift is not a good singer. She's not a bad singer. She is fine, you know.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 96

Please don't send me too much hate, >> right? [laughter] But her real value comes in the network of Swifties. >> I mean, that's why she can cause earthquakes or add to economic GDP measurably when she does her tour, right? Like it did like over a billion dollars. And when you have AI singers and stuff, again, this becomes a really interesting dynamic where you have scarcity with things like Bitcoin, but human attention is also scarce that you've only got so many hours a day.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 97

And you look at Google, how do they make money? It's your attention. Meta, how do they make money? Your attention. Chat GPT, when OpenAI, when chat GPT only costs a few pennies to run, that's what Sora is for.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 98

They're going to get your attention via ads. attention is all they need is like how I like to think about it right now, right? >> The attention economy will be super important. >> Yeah. Big paper and a great name in in more ways than one.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 99

>> So you said that this network um value so basically knowing people, people knowing you, etc. So that's going to be valuable. uh in the past it's incredible to think about as you're saying yeah the the value of cognitive labor just dropping because I mean OpenAI recently had their dev day they showed how many tokens were produced you know across all their models and it's approaching like how many how much humans put out in a year or something like that it's approaching some global value of >> the API is like three quadrillion all the humans together do about 50 when you add in Gemini and others We're around about 30. >> So, >> wow. Okay.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 100

So, it's going to cross that [laughter] >> cross that threshold this year. Yikes. Okay. And then we're also talking about how much cheaper it's going to get. So, basically the entire world is sort of like what do we produce as humans in in words and whatever.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 101

Uh all that gets replaced by AI in terms of like the the data amount and then that the cost to run that drops. Um so what's left? what's valuable after that like you said network value. Some people say you know taste will be good in order to see what kind of outputs we want or maybe a better way to say that is judgment like how do you judge which opportunities to go after but you're almost saying that's not even going to be um a scarce resource cuz the AIS will do better. So, I mean, what's Yeah.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 102

What's left? >> I mean, the the example I give is self-driving car. Like, you're gonna have self-driving companies. I mean, like, can a car drive better than you or me? Maybe.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 103

Nearly. Will it be able to in a year or two? Yes. >> Yeah. >> 100%.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 104

Like if we had um all cars as safe as a Whimo, there'd be 40,000 more people alive every year and a trillion dollars in social costs saved. >> Yeah, that's that's today. And again, they're going to get better and better. And again, like I'm like I I won't be able to run a company better than an AI, you know? Like I probably can't already.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 105

I'm not that good at running companies. I'm good at building protocols and models. But when we look at kind of the future taste and curation, people will trust you not cuz you got better but because you're you because you're in network effects. And if you think about it and we would actually rewind when we used to introduce ourselves, it would be like where's son of Roth Senior, >> you know this and that and that and that. It was our networks that defined who we are as opposed to where's podcaster and you know intelligencia or whatever.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 106

You know, like our value was defined by our network. Our value in life is the interactions we have with our kids and our family. Like once you leave university, you've spent most of the time you ever spent with your parents. >> Yeah. >> Wouldn't it be great to spend more time with them?

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 107

It's about the interactions when you go out for a beer with your buddies and other things like that. It's about pushing yourself, figuring out stuff with other people, solving problems. That's valuable, but that's not the value that's captured in GDP. like um Stan Khnets who came up with GDP says GDP is great at measuring specific thing but we should not use it to measure anything socially important and society that was the inventor of GDP who said that you know >> Mhm. Because when you optimize for GDP like you don't really care about these other things.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 108

That's why in the book I proposed that there's four different types of capital which we actually found mathematically. There's material capital that's GDP like rivalous stuff. You know you get an apple from me I've got one less apple. Then there's I which is intelligence. So those listening to this podcast hopefully you know they're learning something.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 109

It's not costing us anything really right and it can go exponential. Then there's N which is your network value which is your connections and your connectivity. I think a large part of that's what it means to be human. Like in most traditions like you know you achieve enlightenment you go up the mountain but if you just grow your beard all day and you don't interact with humans what's the meaning of life right? But it's not really it's in our interactions with others.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 110

It's in our congregations is in our communities. It's in our clubs. And the final thing is diverse because if you're in a homogeneous environment where you're not learning anything, you're never going to adapt and you become more fragile. So we start measuring things in these different ways. So I said like wouldn't it be great if we had this culture credit money that could optimize for societal flourishing, but societal flourishing isn't about necessarily what we build and the AI and robots can build better than we can.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 111

It's about other things. But it's up to us to decide what's important in life. Because what you think is important in life is different for what I think is different what Dylan thinks. But we need that shared human context to decide again. What does it mean to be an American?

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 112

What does it mean to be a Brit? What does it mean to be a mustach? You know, like these are discussions that we actually have to have and think as opposed to life just sweeps you along right now. >> Yeah. It's it's pretty wild, too, cuz when I try to imagine like the world of just like true abundance and like what would actually make me happy, it comes down to some pretty basic things.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 113

Like I'm a a big fan of just playing basketball with my friends, but I just I just want that kind of like I want to go play a sport. I want to kind of come home and have a dinner. Like it's so simple and everything else just becomes so >> I don't know. It almost like messes that up like the money and all that. >> Have you heard of the story about the banker and the fisherman?

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 114

>> Yeah, that's a good one. >> New to me. But yeah, I mean I'm sure most people haven't or a lot of people haven't. >> Yeah, basically they are. >> Yeah, an investment banker basically makes a lot of money and he retires.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 115

He goes to this like village somewhere, get off the grid and he sees this fisherman at 2 p.m. walking back with a fish on his shoulder. He's like, "Where you going?" Like, "Well, I'm going to go back and get the family together. We're going have a fry up with the fish. You know, we're going to tell some stories, do a little dance.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 116

Do you want to come along?" You know, welcome. No, you shouldn't be doing that. Like what if you just stayed a bit longer, got some more fish, you know, then you could sell them for a profit, get a boat and some nets and then what? Well, then you could get more fish and this area seemed underfished. So you could scale that up to a proper boat, get a few more.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 117

It's like, oh, and then what? Well, then you know, you could accelerate and sell your company to a distributor or IPO it. I could help you with that, etc. And he's like, and then what? Well, then you could retire, kick back to a beach somewhere, do some fishing, >> be where you started, >> hang out with your family.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 118

hang out with family, do dance. Yeah. Oh, yeah. >> Is neurolink the answer or something? Like, do you plug into the AI and sort of turn it on and off to like understand to have like a super intelligence at a certain time to understand if you're safe and if things are good and then turn it off and be human?

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 119

>> Well, that's going to be really interesting. Like, here's a question for you guys. If you could turn off your sadness, would you turn off your sadness? That's a great question. >> Oh, you first, Wes.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 120

I don't know. Yeah, I think >> there's got to be some value in that emotion if it evolves. >> I You're sad. You got your neurolink in. >> It's gone.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 121

>> It's a little bit scary and there's obviously a lot of considerations. Uh reading Daario's uh Machines of Loving Grace, you know, like one of the things that really stuck out to me, he was saying how, you know, most people their brains misbehave in some way. That could be ADHD. That could be maybe some people struggle with being a little bit too aggressive, whatever. Some people have depressive episodes.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 122

And if you could imagine something that just sort of like corrects it like I don't know if I would turn off my sadness but certainly there are times I mean we take medicine for it medicine with unpredictable side effects sometimes. So if you're able to sort of just stay in the state here's what I found out talking to people. So if you're talking about taking your brain and augmenting it p like into a supra natural level you get into some ethical concerns. People are mixed. But if you say, okay, imagine your perfect day where you felt just clear and happy and focused and pleasant like would you use that mode as the default mode for for all your or all of your days?

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 123

Most people would take that, you know, every day. Uh so yeah, that that's kind of my answer. Uh so going to a super supernatural level is tricky, but just being at your best always, I would do that. >> So most people would take the blue pill, right? They wouldn't take the Redfield, you know, like >> most people would take S from Brave New World.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 124

>> Like, >> if you think about where that's going, it's the Borg. >> If we're thinking in Star Trek worlds, >> what did the Borg lack? >> Why do you need >> Why do you need emotions? I'm sure I'm sure they have their little dopamine hits, right? Think constantly like just dial that dial that stuff up.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 125

But again, these are questions we're going to have to ask because like if you think about it in zero sort terms, the best way to compete is to plug in. It's matrix, it's cyborgs, etc. But is that what it means to be a human? Like again, why are we even doing all of this? This is a real question.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 126

Again, it requires us to actually take a step back and thinking what is meaningful in my life? like um Harvard professor Clayton Christensen who came up with the idea of disruptive innovation had this great book called how will you measure your life where he talks about all the business stuff but he says look when you're on a deathbed and you look back >> how will you have measured if your life was a life worth living and it's very difficult people to do that cuz we're swept up but now is the ideal time to do that because our computation and consciousness we were the dominant species is about to change so it's not about your computation capability You know, it's not about those things cuz we're about to have a new It's about your consciousness. >> Yeah. >> And it's about your place in society, in the universe. It's about where you are in the network.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 127

>> But again, that's a discussion that is difficult to have because >> life is too fast. >> The other kind of funky thing about the idea of changing a brain is that since I'm the actual decision maker, if I decide to remove some sort of emotion or some sort of feeling, that new version of me won't even know what it missed. So then I end up in this weird scenario where I have to almost like copy my brain. I have to say like okay this is this the one that will judge the other one and then make a copy of my brain say get rid of sadness and then look at that and say is that a better version of me because if I just jump into that brain that brain doesn't even know what this other brain was like and will never want to go back. So it's almost like like you know GBT3 making decisions on if 04 or 05 is better for itself and it just like gets so messy.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 128

>> Yeah. Yeah, you have to go and watch Inside Out again, right? Where you get those characters those people in your brain. >> I mean, the brains are very different. Like I have affantasia and an Aurorelia.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 129

So I can't visualize anything and I have no internal voice. So my brain's kind of empty. It's easy for me to meditate and stuff. I should probably do it more. And apparently people have voices in their head, you know, like not just normally.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 130

So you've really got kind of different things guiding you. Now you could literally take that and put it outside, >> you know, >> and imagine again how that changes your brand. Imagine imagine the person that you've trusted most in the world who's now departed. 11 seconds of their voice plus a bit of work, you could create a digital double of them. You'll trust that entity more than anything and that can have an emotional reaction in you as well.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 131

We're going to some crazy places now before we again get to jack in with neural link or whatever. Have have you come across any interesting examples of intelligence that seem so foreign to the human version of intelligence? Because it's so easy to think about AGI as being like a superhuman. But sometimes in the animal kingdom you see with like fungi or with other species, a kind of type of intelligence that is very successful at achieving its goals, but it feels so alien. And it seems like AI being built on silicon instead of biology with the constraints of evolution might really surprise us that way.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 132

>> Yeah. Um I mean there are kind of various things that are weird. Have you heard of move 70? Move 37. >> Yeah.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 133

Sort of AI creativity that's very alien different from humans so to speak. >> Yeah. This was in the Alpha Go matches with Lisa [clears throat] Doll. Yeah. And the Lisa doll.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 134

And then move 37, he had to actually have go out and have a you know, pull a cigarette. Yeah. It's like >> Yeah. He had he took a smoke break in a middle >> blew the mind. It was like what is this?

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 135

You know, like >> I thought that was a mistake. It stopped like is my life a mistake? What am I? I think you know like he was probably having those things. >> It is difficult for us to think because right now the way the models are trained is a reflection of ourselves.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 136

So we take this corpus of the internet, we squish it and then we bring it back. but they're designed to cater to us because they're serving as consumer products. When you actually build AIS that are designed for other objective functions on synthetic data sets, I've seen some weird stuff from the stuff we've been building and things like that. >> Like they make jumps and things like that and you're just like what? And then it turns out to be correct and you're like, wait, what?

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 137

>> Yeah. >> Um it's difficult to compute. And to be honest, it's a bit like when you talk to super geniuses. I've been privileged to talk to a lot of them and sometimes they're very hard to understand, >> you know. >> Yeah.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 138

>> Yeah. >> But they're still human. Right now what we have is a simulcum of a human. What we might have is something completely different soon. >> And this is I just do want to really touch on this because it seems like um there's a few papers that were published that these neural networks they do form sort of these mental models.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 139

And I almost think of intelligence as you know how good your intelligence is is just the ability to take this vast data that's being input into our brains and um just compress it into some sort of a mental model that allows you to predict whatever the the future or whatever problem you're working on. And so that's basically intelligence in a nutshell. And it's crazy too, like what you're saying, like how these machines, how these neural networks, they come up with these weird things um that are so alien to us, but then they're right. And like we've talked about quite a bit because it's such a mind-blowing concept. I mean, could you just expand on that a little bit?

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 140

I mean, if there's anything you can share, what's the weirdest thing you saw maybe? Yeah, before you go really quick to I'll say that Wes opened my mind up to the idea of of protein folding and just how foreign and impossible that would ever be for me to imagine. >> Yeah, like it can just succeed, but there's no part of me that can see how that path came to its conclusion. >> There seems to be some sort of underlying orders the universe. So I was one of the authors of Openfold and I provided all the compute for that because Alpha Fold wasn't fully open source.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 141

So we created the fully open version of that, >> right? >> And as you said, that's an example of like >> there's the stuff it should know and the stuff that it figures out, you know. >> Yeah. >> Like when we took stable diffusion and then we created stable video diffusion like 2 years ago, you know, it's like a from that to sora like it just did slow movements like an image model created a video model, but then we created a 3D model from that. Like how does it know what the back of my head looks like?

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 142

>> Mhm. Mhm. >> You know, and then that was kind of just crazy to see like, wait, what? And then we created a world model you could go inside and navigate like these models figure out things. They're like that's the nature of a latent space.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 143

So like if you look at Sora, self-driving cars, stable diffusion, they use a process called diffusion here, which is basically you take an input and then you add noise or messiness to it. You destroy it until you get to the smallest constituent parts and then you look at how to recreate it. That's the forward and backward process. Yep. >> And that's a mental model that you have there.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 144

One of the weirdest things that we found, this is actually the book is that you can describe all of economics and society that way. You can rather than having axioms of utility and equilibrium, you can basically have one axiom which is systems that persist are the ones that minimize the difference between the internal model of reality and reality itself. >> And that difference is what's known as a loss function. Sometimes in AI you see this gradient descent of this line going down as it gets closer and closer to reality. >> Everything can be described in that way which makes sense because the best way to describe a company is probably a transformer chat GPT.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 145

The best way to navigate an arbitrarily complex environment or create art is a diffusion model. So that was like wait what? Because a lot of the problems of classical economics actually collapsed when we saw that and that was kind of creepy cuz we were like well economics is affecting society so society should be a bit more like AI but then the equations of AI described it itself and we built this like multi-agentic system that was bouncing all that around and they just collapsed everything and said this is right and then we were like no it's not and then after a while we're like oh it is >> and that was weird >> and in Fact, it is creepy because like if you look at something like chat GPT, it's like 100 trillion words in 100 GB. That doesn't make any sense. Stable diffusion is 2 billion images in 2 GB.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 146

Doesn't make any sense. And yet those can write or create anything. Where does it go? >> Right? >> Like compression like Wikipedia compressed is like 30 GB and it's so much more than these things.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 147

So when you're jumping between latent spaces, it calls these internal principles folded, you start deleting stuff and it still works. That's the creepiest thing. And then the models start behaving in these really inductive reasoning ways whereby they'll make leaps and we can't share most of the stuff that we've seen. But again, the economics thing is the first thing we can share, which was us working with the AIS and being kind of surprised. So, so how should regular people start updating their thinking about um latent space?

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 148

Like maybe some metaphors like I I'm probably too old in this thinking, but I still sort of think of a token as a word fragment and then I think about it in like a multi-dimensional space. It's like 1 2 3 4 5 six seven dimensions, but you go up to a trillion and it just becomes an interesting landscape. Is there is there an updated way to start thinking about latent spaces? >> Yeah, I'll give you an example. So I got into AI when my son was diagnosed with autism and he was very severe and then I built an AI system to repurpose drugs for him because I was like we need to understand from first principles what causes it and I'll just say autism is expressed by an imbalance of two neurotransmitters GABA and glutamate.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 149

GABA calms you down. Glutamate excites you. You know when your brain is buzzing and you're tapping your leg and you can't focus. That's what kids with autism are like and that's why they can't form speech and others cuz their brain's on fire all the time due to an imbalance one way or another. There's many things that can cause it.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 150

Now, the way that you teach language often is you can do things to calm that down, but you do something called apply behavioral analysis, which is that you say this is a cup or this is cup your ears or this is, you know, a world cup. There's various different pictures you show and the interconnections between that cuz that's what our brain naturally does when it builds its own latent space or neural network. So when you type into a image generator the first word is cup your hands world cup the word cup as a fragment is connected to all these different concepts and by looking at what else is in that prompt it can pull out the specific version of that. The other way is that there's this landscape because these AI models, they're not like if this then that. They're like a bunch of weights.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 151

They're a filter, a receive. Water flows in certain ways by default. When you customize it like you had when you were able to create like you put yourself into Sora, you know, you've seen that or when you had those you could make yourself an astronaut and things like that with the images. What happens is this. There's a little map that's created, a mini seieve on top of the seieve that's pulls out the characteristics of your nose and your eyes and other things like that and then the water flows slightly differently.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 152

>> So you're suddenly in that video when it says where's or Dylan, >> you know, so that suddenly knows about your writing when you've tuned it on there. >> But again, this isn't an active thing. What model weights are is literally a seieve. And the way that they're formed this latent space is literally the probabilistic balance of that concept of cupenness of Dylan of Wes. >> Right?

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 153

>> So you always imagine it in terms of a flow almost like a river that keeps branching billions of times. >> That's literally what it is. That's why the process of training these models is called gradient descent. It's literally the same equations as water flowing down a hill. Does it ever um bother you or just did it strike any interest the fact that like in all of of our science fiction when we described artificial intelligence it was something that we've engineered precisely fine-tuned like a you know formula 1 car and now that we're here it's almost like no we kind of grow it.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 154

So it's more like a a factory that produces uh you know if you produce like bacteria in a petri dish almost like you create an environment and it grows. So we're not like does that change your thinking in any way? Does that strike anything? So really what you find when you talk to the top people in this space is that we're not growing it. We're not designing it.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 155

We're discovering it. >> Discovering it. >> Oh, >> like there is this concept of doxer. It was in Kissinger and Schmidt's latest book. Like the commonalities of humanity, the common stories.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 156

Like what is religion? It's stories that have survived. Right. Right? >> And we're made up of stories.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 157

There are certain things that are resonant to every human. Like you look at something with a golden ratio and you're like that's pretty right. And it's very interesting because like there are two types of actually the three types of flow. So if you take any single flow and I described this in this book, you can deconstruct it into three different things. Gradient flow that's water flowing down a hill.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 158

Then you've got your circular flow which is well pools and its intelligence and things like that. It's circular. It doesn't get depleted. Then you have your harmonic flow which is the banks of the river that you're on. And there's a mathematical equation the hodge decomposition that shows that anything can be deconstructed that way.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 159

The perfect balance between the water flowing downhill and the water circulating is the golden ratio. And you see all sorts of interesting things like that. And so what we find when we kind of delve into these models is that they've taken the subconscious of humanity and they're resonant for that reason. Which is why if you say make it more beautiful, it actually generally does. If you say make it more persuasive, it actually generally does.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 160

It understands abstract concepts as well as the concept of a Dylan or a cup or whatever else like that. And so it feels like we're digging in the subconscious of humanity to discover something that's very common in humans. And now with the embodied AIS and the video and world models of nature itself, like Sora understands physics. >> Mhm. >> Like you see weird things like sometimes someone showed a thing of a pint being poured and it stayed inside.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 161

It didn't break. That was probably part of the tuning to make it safe. It don't show anything breaking as opposed to the model itself not learning physics. But it could again we do feel that this is something we're discovering and in my view like I think this is the great filter that's coming. >> Oh go there.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 162

That's why we don't see aliens in the universe >> cuz all species hit on this and then can't handle it. >> You go as a collective complex system of intelligence the human colossus. Like if we all gathered together correctly, we could easily get to Mars or soul cancer or anything. There's nothing we can't do as humans. Now we figured out a way to take our collective knowledge and compress it into a few gigabytes.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 163

And now we're making it bigger. >> Yeah, it might be. >> The default of that if you don't build it right from the start, like I don't think it's enough to align after is that it'll go max extractive and there's some very bad outcomes. It's like what if you have a stuckset type virus but mimemetically for ideas. Yesterday anthropica in the UK AI safety institute showed that with 250 books out of an entire training set doesn't matter how big your model is you can poison it.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 164

>> And so you think about what our models are trained on now. I'm like yeah like the AI will definitely run our government and it will run all our systems and everything and then someone will poison it and we'll all die. You know like the robots will twist our heads off. There's so many things you can think of. That's why my P doom is like 50%.

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 165

>> And I think again it's high, you know, like most people are like 1020, but that's still Russian roulette blowers. >> That's why I think we need to build AI that is aligned from the start from the data going inside it. And we need to give it as much compute as possible. That's why I think we need to build a new way of sharing value across our society. Because if we look 100 years out, thousand years out, of course AI is running everything.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 166

Does it need the humans? not with the way it's free and currently built right and again I think this thing of intelligent species creating something that can then capture and scale the intelligence where humans are limited by their biology and how smart you can get whereas these things are not that seems the most likely candidate for this great filter which is why we can't hear aliens like why is there a dark forest in the universe >> yeah well the whole idea is like is mathematics itself sort discovered or invented. Is it like a description of how to do things or is it out there? But I guess you seem pretty clear you're leaning towards it's discovered and so is intelligence on top of it. >> It feels like it's all variational optimization, right?

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 167

Again, these models that we have, you can have diffusion model or hierarchical reasoning model or mambber or any of these other algorithms, auto reggressive transformers, they all kind of give the same result. You know when you went from Newtonian physics to Einstein, Newtonian physics is a subset of Einstein's variational physics. And what we've discovered is economics. You can go from our core. You can take our book which is free and you can put it into any coding agent and you can say using simpy symbolically derive the canonical equations of economics from like our small appendix where we give some of the math and it will do it.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 168

It will give you Cobb Douglas. It'll give you everything else as a special case. You can see that Keynesianism, Marxism, etc. are gradient flows. And we were like, that's a bit crazy, but it makes sense because ultimately you have these things, AI models, that are the best model we have of reality.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 169

Full stop, >> right? >> And that has a lot of implications because the same equations and most AI models you only require 2,000 lines of code, honestly. But the core code, you can go to Karpathy's kind of make your own GPT and in a few hours you can be creating your own GPTs. >> Mhm. They make movies, they write scripts, they drive cars, they do robotics.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 170

So obviously the equations of generative AI are probably the equations of reality. >> Mhm. >> Which is again mind-blowing. And that tells you it's a discovered thing, >> right? Um Okay.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 171

And then so just so you know, we're coming up on like an hour and 15. So Wes, whatever you want to >> Well, let me just I have to follow up because this is Oh, man. This is we're getting such this is like the delicious territory like so uh Deis Hassabus, you know, in an interview because he's usually pretty like reserved. I I don't know if he fully just lets everything out there, but it's incredible to to to listen to some of the stuff that he's saying. But um when asked about if he thinks we live in a simulation and because he posted something along those lines, he he he I think what he was talking about is alphafold.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 172

the fact that these models can look at the building blocks of life and see some pattern there because it's not like a brute force approach because there's you can't brute force these 3D structures of proteins. >> So it looks at all the existing ones that we've discovered painstakingly, right? And we're like here's what we've discovered so far. It's like oh well it's like obvious what the pattern here is and it's able to build new ones. So and he said that this might suggest that we're living kind of in a computational universe.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 173

So, not a matrix-like scenario, but a a computational universe. Uh, where are you on that? Cuz I mean, definitely you're saying like these models can scale up and just learn anything. Yes. Anything.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 174

However you want to unpack that. >> So, I think that the book and the equations we have for economics are grand unified theory of economics. And they're super simple. And that's crazy because they can apply to any complex system because again the equation generative AI are the ones that are modeling our reality the best. The best and biggest discoveries ever are things like E= MCÂ², right?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 175

Like they're super simple. Like there's a lot of complex stuff, but they're so elegant. The universe is elegant. >> Mhm. >> And if you look at Carl Fristen's free energy theory about energy optimization in the brain, like again, it flows downhill.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 176

You look at all of these things. It basically tells us that probably like people talk about like brute force compute. That's a classical paradigm. What the biggest discoveries ever are going to be are probably the simplest ones. And probably the universe is a computer that's minimizing something.

### ðŸŽ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 177

And what's it minimizing, right? If you think about all life in the universe, you think about everything that's moving, it's going towards adjusting entropy, right? And so I think we're going to see a lot of those things. And again, the fact that you've got equations for generative AI that tell you everything from protein folding, >> right, >> to being able to simulate the world for car driving to creating whole universes. That should tell you something if again they're all based on the same equation.

### ðŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 178

And so I think it is a simulation of a type. But this is the fascinating thing like we see things like the golden ratio the balance of gradient and non-gradient flows emerging everywhere in economics itself. If I tell you sell me a pen, the price function seems very similar to wave particle duality and the collapse of that. It's a probability density, you know, and so we see these things over and over and over again. And clearly there is someformational aspect to the universe when you look at things like wave particle duality cuz that feels like the value created by talking to your mates in a way, right?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 179

Which is information theory. Information is valuable in as much as it changes the state. And again, we see these things repeated from a micro to macro scale. Right now, our equations are different from all of these, which is why we have special and general relativity, which is why we have so many economic theories. And one of the wonderful things now is the AIS will be able to find help us find the simple elegance of the world, I think.

### ðŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 180

And that has a lot of implications because I think again we'll see breakthrough after breakthrough but with the simplest most elegant equations and the world we're living in right now is simulated by our brains like you've got your blind spot for example it's filling in constantly you've got these other things you'll be able to control your emotions other things and our brains themselves are doing the same math as generative AI equations they're minimizing they're doing this again fringy principle etc. So I feel that we are living in a simulation, but it doesn't mean that necessarily like it's a box and you're in a game engine or something like that. It's just that the mathematics of simulation and generative AI are most likely to be the mathematics of reality and complex systems and other things. And again, we see the empirical evidence of that every day with these models. >> And can you have um gradient descent without entropy?

### ðŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 181

Because entropy seems like the most stable thing in the universe, but it's also a measure of disorder and it's like continually moving towards it and then you see these little pockets of uh things that are stable and then you can perform gradient descent on them. Is that part of the creating the landscape? >> Yeah. When you look at the mathematics, this is all basically that, right? Like you we're converting energy into intelligence.

### ðŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 182

That's literally what these big supercomputing clusters are doing. You're turning disorder into order, but it's localized, right? >> So, just because it's localized doesn't mean that you're fighting the way the universe is going. But the more the universe does that, creating life and other things. Again, not even intentionally.

### ðŸŽ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 183

This is just what is. It's a process architecture. It's what's stable. It just gets really interesting when you think about the implications of all of that. And again you look at the mathematics of it because so much of our science our mathematics is variational calculus now you know and again so much of our systems are now best described just by generative AI models which all have very similar mathematics and again not complicated ones.

### ðŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 184

previous AI world is way more complicated than the generative AI world in mathematics terms like the smart like we had 80 developers at stability only 16 of them had PhDs some of them only had one year of experience they taught themselves AI if you complete the Andre carpathy course or faster AI there's a good chance that you can become a good AI developer honestly >> train your own models understand the math it's not that hard which is the craziest thing it's like you have to go into gauge theory and string theory and all of this kind of stuff. >> Yeah. >> Right. This is absolutely fascinating and we do want to be respectful of your time. You're very busy person.

### ðŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 185

But wow, do we go on such a great trip here covering everything from finance, economics to I mean this is we're almost approaching maybe like the meaning of life a little bit, the meaning of the universe and everything. And maybe it is funny too. Well, this is the thing like um we are training our AIs to give answers in an intellectually idiot way. The optimal thing is to train the AI to ask the right questions, right? >> Yeah, that is what Hitchhiker's Guide to the Galaxy said.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 186

Maybe we should listen to it. >> Yeah, >> maybe it was very ahead of its time. Yeah, maybe it figured out where this whole thing is going. >> Certainly. >> Yeah, time travel.

### ðŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 187

Who knows? >> But that was that's great. And yeah, it's cool you're giving the book away for free, too. But obviously people can get it uh through Amazon and what other things should people know about projects you're working on or how to contribute get involved. >> Yeah.

### ðŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 188

>> Yeah. So you know we've released a free agent that's can do just about anything. We'll be creating healthcare education others. You can sign up for the bet on our website. Please do give feedback cuz we want to build these stacks.

### ðŸŽ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 189

Please read the book like it's free on mine or 99 cents on Amazon cuz that was the minimum we could send set it to. Um, leave a review if you find it useful and chuck it into your favorite LM notebook if you want to have a little podcast, but play around with it. It's really interesting on the math side. We'll have the full math release soon. Um, but please, if you've got any ideas, do send them to me because I'm trying to figure this out with the team and I think we all need to work together with what's coming because really the world's not going to be the same again.

### ðŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 190

It hasn't been for a few years. again a thousand days out from now it changes completely again and we got to be in this together. >> Absolutely. And thank you for >> Yeah. Thank you for being one of the people kind of like looking at the global view to how to help everybody cuz uh I'm sure not everybody's focused on how to help the biggest number of people.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 191

And yeah, please if anybody has resources or wants to contribute uh check everything out just the idea that we're doing this civic compute helping with autism and cancer and all sorts of health problems. I mean that seems like a very worthy project to be working on. And with that, >> thank you very much. >> Thank you so much. And dear watcher, we'll see you in the next one.

### ðŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 192

And ID, thank you so much for being here. here. It's been an absolute pleasure.

---

<div align="center">

**ðŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
