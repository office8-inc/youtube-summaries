# ğŸ“º OpenAI is "Is Hiding the Truth"

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: OpenAI is "Is Hiding the Truth"
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=NhMq52kqjC4](https://www.youtube.com/watch?v=NhMq52kqjC4)
- **å‹•ç”»ID**: NhMq52kqjC4
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ17æ—¥ 19:13
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

So, OpenAI had a number of researchers quit. They're saying that the company is hiding the truth about what its internal research is showing. Now, this is original reporting by Wired. They have multiple sources, but here's kind of the scoop. Open has long published research on the potential safety and economic impact of its own technology.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

We've certainly heard from various OpenAI members talking about the potential job losses, maybe replacement or at least augmentation of certain jobs through AI. If you saw my recent video on GPT 5.2, I specifically highlighted one benchmark there that is a little bit massive, important, troubling depending on how you look at it and that is GDP val. GDP val is basically testing if these models are capable of doing entire projects that otherwise would have been done by human not experts in the field but but specialists people who have at least a few years experience working in that field. Up until the last few weeks and the release of GBT 5.2 to no AI model reached parody with an industry expert. GPT 5.2 leaped above that parody with the industry expert align and now is preferred to the human counterparts.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

So this is from the blog post from a few months ago from OpenAI. They're saying as AI becomes more capable, it will likely cause changes in the job market. So if you're following along, here's the story so far. In September this year, 2025, OpenAI did not have a model that was close to being as good as an industry expert at doing entire projects. Anthropic did, we'll come back to that in a second, but OpenI did not have anything close.

### ğŸ“ è©³ç´°èª¬æ˜

The best model they had GPT5 high, the win rate was 35%. So only 35% of the time the, you know, people 12 years experience with management experience in those fields, kind of like the the bosses, the managers, right? the upper management, whatever you want to call them, only onethird of the time they preferred the output of an LM to an industry expert, a human industry expert. Then December 11th, a few days ago, a little bit under a week ago, you know, the new GPT 5.2 comes out and GDP Val changes. They have they've updated that benchmark and it takes quite a leap.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So here's that 35% win rate by the previous best model. And if we're counting wins and ties, the combined rate was 38.8%. 8%. So that jumps to 74.1% of it either winning or or tying even if we're looking just the win rate 60%. It it clear is a clear winner 60% of the time over a human being.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

So this wired article got published December 9th 2 days before this model comes out before the new benchmark comes out saying that there's AI researchers that are worried that OpenAI isn't revealing everything it knows about the potentially negative impact that these models might have. So Wired reports that Sam Alman led companies becoming more guarded about publishing research that paints an inconvenient truth that AI could be bad for the economy. At least Topa employees quit the economic research team and quit the company entirely. One of these employees was economic researcher Tom Cunningham. In his final parting message that was shared internally saying that the research team at OpenAI was veering away from doing real actual research and acting more like a propaganda arm of the company.

### ğŸ¯ å¿œç”¨ä¾‹

So the employee that left this is Tom Cunningham. I believe this is the right person. So he's ex OpenAI and now working for meter right so economics and AI meters of course you know you've seen those charts of how fast the AI agents are getting better. We've covered a number of research papers by them. Now Cunningham declined wired request for comet.

### ğŸ’­ è€ƒå¯Ÿ

Hopefully in the future we'll hear a little bit more from him. Maybe he'll kind of give us a glimpse into what he's thinking, what his thoughts are. Also, just a day or so ago, the OpenAI's chief communication officer, Hannah Wong, did decide to leave. Shinio is leaving. Wong joined OpenAI in 2021 and is leaving now, which is very interesting and a little bit bizarre to think about.

### ğŸ“Œ ã¾ã¨ã‚

OpenI is expected to IPO, right, to go public on the stock market probably a year or so from now. As some people here on Reddit are saying, leaving less than a year before a trillion dollar IPO is wild. Now while open AI at least some people are claiming is not publishing the research anthropic has been very vocal about it Dario Amade went on multiple interviews and several news sources saying that a white collar blood bath is coming. So we've talked about some of those headlines. So Dario Amade saying that that AI could spark a blood bath for white collar jobs.

### âœ… çµè«–

Specifically there's a certain segment that is especially at risk. We covered in the past the Stanford paper that used the anthropics economic index, the the data that they provide about their research about how AI is affecting jobs and they published their results and they're not looking great. Most team chats are where work is talked about, not where it actually happens. This portion of the video is sponsored by Glue and they're trying to fix exactly that. If your day looks like mine, you live in chat, but nothing actually gets shipped there.

### ğŸ“š è¿½åŠ æƒ…å ±

No work actually gets done in chat. Log this, deploy that, grab the latest metrics, respond to this customer, make it so. And suddenly you're bouncing into GitHub, dashboards, notion, calendars, G drive. The point is context switching kills focus and it slows teams down. This is where Glue comes in.

### ğŸ”– è£œè¶³

Glue is a focused team chat app with an embedded AI agent that can actually take action. This is a first in a team collaboration. Here's the key idea. Glue is the first multiplayer MCP client. MCP is model context protocol, a standard for connecting AI to real tools.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

So instead of switching windows, you just do it inside the thread. Glue's AAI calls linear creates the issue and post the results right there. It can update a tasks, pull a notion doc, zapier, zoom, canva, hugging face, PayPal, strike, you get it. Every tool call is visible so you see who triggered what and glue is threads first. AI docs and actions all in one place.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Developers can extend MCP integrations to hit internal APIs or custom workflows. Glue is the go-to team chat for dev teams and startups focused on working efficiently and cutting out busy work. Chat as the place where work gets done. Start a free 30-day trial at glue.ai AI and turn your team chat into a command center. Work gets done where you talk with glue.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

And now back to whatever we were talking about before. We covered it in the past the Stanford paper that used the anthropics economic index the data that they provide about their research about how AI is affecting jobs and they published their results and they're not looking great. Specifically, we're seeing a huge drop off for the very early career. So ages 22 to 25. So people coming out of college and are just beginning to enter the workforce.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Those are the people that seem to be the most affected. And this very much coincides with the time that these chatbots started coming out. So as as this paper put it, no, we can't blame this on on 2020 and what was happening back then. We can't blame it on some other things. This seems to be definitely tied to the fact that these chatbots often times can perform a lot of duties that normally we would maybe entrust to a a new incoming worker that is just beginning in their career, still learning how to do stuff.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

You give them some uh grunt work to do. That's kind of what it used to happen. Now that seems to be going away. Notice when you get into kind of like the developing career, 31 to 34 mid-career. So basically 31 plus you're fine.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

And there does not seem to be a drop off. It's very much concentrated in that early career. Here's another kind of chart showing the same thing. So this is for software developers. A lot of this is also reflected for computer jobs in general.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

But Anthropic Research also is looking at other AI exposed jobs. They're looking for which jobs could these AI chatbots potentially replace some of the work and be used to automate a portion or all of the job performed. And so again, that's anthropic, their published research. Stanford used some of their data to come up with with their paper and and their research. But coming back to OpenAI, here's what they did publish about their GBT 5.2 model.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Again, that was the one that had the big leap from before to now. So here's how well it performs at various spreadsheets. So here it's task to create a workforce planning model. Headcount, hiring plan, attrition, and budget impact include engineering, marketing, legal, and sales departments. Now, of course, at a glance, it's obvious that this GPT 5.2 thinking, I mean, just looks much better.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

It looks like a lot more thought and and detail went into it. So, visually, obviously, there's a big difference. But, I mean, is it accurate? Did they just make a whole bunch of stuff up here and uh just colored it with pretty colors? Is that what happened?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Well, not quite. Here's what one of the judges of GPT Val commented on the work. So, these are people that are having managers at various big corporations, well-known corporations. We've read some of the names on there. you've you've heard of most of them.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

They have banks and tech firms and large food firms and airplane builder like just all the big names that you're familiar with. They have people from across different industries, 44 different occupations, top nine industry contributing to US GDP and I believe they said that these judges on average have something like 12 years experience. They have management experience. But these are the people that at these real Fortune 500 companies are making decisions about, you know, who to hire and who to give work to, which projects how they should be completed, which one's better than the other. So when these people pick the LM outputs over human outputs, that seems like it's a very meaningful statistic.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

It's a very meaningful signal because these are the people who actually choose who gets to work in the real world at these massive massive corporations. So on one of the outputs, one of these judges said, "It's an exciting and noticeable leap in output quality. It appears to have been done by a professional company with staff and has a surprisingly well-designed layout and advice for both deliverables, though if one, we still have some minor errors to correct. Additionally, our internal benchmark of junior investment banking analyst spreadsheet modeling tasks such as putting together a three-statement model for a Fortune 500 company with proper formatting and citations or buying a leveraged buyout model for take private. This new model we're talking about, GPT 5.2 into thinking its average score per task is 9.3% higher than GPT 5.1s.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

And so these are the results. Here's another example of a cap table. The previous one, everything in red means it was wrong somehow. And this new model got everything right. It's also very auditable.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

So you can go back and double check that everything's right. So it's like following certain instructions how to correctly fill stuff out. It's also can do its own audits or you can have a a different model doing the audit. So you can have one model write it and a different one doing the auditing. So as I say here 5.2 complete all calculations correctly and in an auditable way and there's more examples that they give.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So just to kind of sum things up, Dario Amade was probably one of the first people to start ringing the alarm or at least more recently he was the one that came out with the strongest language that was just absolutely unmistakable. And I mean when you say something's going to be a bloodbath, you know what I mean? You're not really mincing your words. the video that I did about GBT 5.2, I titled it GBT 5.2 is the first human labor replacement, right? Get ready for layoffs.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So again, I think that the people that are paying attention and that know how to like read between the lines and are reading the various papers that are published about this, you know, notice our complete lack of shock on our faces. Were not surprised by this. This wave is coming. If you've been watching this channel, I've been talking about for for quite a bit. I didn't realize this at the time, although in retrospect, it's kind of obvious that the first people that are going to be very harmed by this are the most vulnerable to job losses.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

It's kind of those younger kids that are just beginning to enter the workforce, right? They're straight out of college. They haven't had too much time to develop those skills yet. I always kind of my head thought that the people that are skillful and good at their job, right? They'll be sort of augmented by the AI, they will be become more efficient and able to do more stuff.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

and maybe people that don't provide as much value, maybe some of those jobs would be automated. Maybe I wanted to think that because it just seemed more fair. But I mean, looking at this chart, if this is to be believed that this is what we're going to see over the next 5, 10, 15 years, I mean, that's pretty sad. When you're just entering the workforce, it's it's hard to find a job that pays enough so you can pay rent. I remember being in my early 20s running out of money and getting hit with overdraft fees.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

like you're basically getting charged a fee for not having enough money, right? Those early career years are are kind of brutal. But then you get to 30 or thereabouts or well into your 30s, it gets easier. It gets easier because you were able to build up the skills, you know, rise up the corporate hierarchy, whatever. You've improved your resume, you've improved your life skills.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

kind of get out of jobs here in this early career. That's like the most vulnerable people that need to have jobs to learn, to grow, to buy houses, to have families. So, this definitely, for lack of a better word, sucks. Now, if you're asking, well, isn't this just software development? Isn't it just limited to that one sector or industry?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Here is Anthropics, their economic index, kind of showing which jobs and and industries are affected. So if I kind of zoom in here. So green, the green squares, they're mostly automated tasks. So this is where the job could basically disappear. If enough of your job tasks are are green, meaning that that job can be automated.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Whereas if you know most of them are purple, that's an augmented task, meaning that maybe they might need less people to do it because one person will be more effective or efficient at doing it, but you can't fully replace a person. AI augments it. It doesn't replace it. and then this what gray color I guess that's where they don't have uh data for it. One other thing to note is that they're using this on net classification which is a way to just basically kind of break down every job into what skills you need to do the job.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

And here they basically break down each skill by you know kind of like an RPG kind of like a video game you might have you know a skill go from one to 100 you know apprentice journeyman master whatever. So something as basic as a reading comprehension for example is is broken down by these skill levels. So 85 means you can read a scientific article describing surgical procedures. So something that's very high level. 57 is understand an email for management describing a new personnel policies.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

So a little bit more mid-level. And 28 read step-by-step instructions for completing a form. So this is something fairly basic, something you would need just to to go to like the DMV for example. Interestingly you don't need that level of reading comprehension to work at the DMV. you can get away far less based on what what I've seen.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

But I'm only joking, of course. DMV employees are great people. Solid of the earth, I believe, is the expression. But notice like if you want to be an editor, right, you need level 73, lawyer, level 70, etc. And that goes all the way down to more manual type of work where you need to read some basic instructions, but the job doesn't really depend on it.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

The reason I kind of bring that up is this breakdown. The onet classification I feel like isn't going to be as as accurate as useful as what OpenI is doing with GDP val. If I if I sometimes say GPT val, I apologize. A GDP like a gross domestic product, right? GDP value uses actual projects that you would complete if you're working in that field, right?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

So financial investment analyst might be asked to create a competitor landscape for last mile delivery. A manufacturing engineer might design a 3D model of cable reel stand for assembly line right with all of the list of components with the sketches 3D drawings whatever auto CAD schematics whatever you're using for that. So this to me is a lot more like handson than just you know knowing that you need 45 out of 100 points on the reading comprehension scale to qualify for a job. That's a little bit more vague. This is kind of like real life economically valuable work.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

But the point being is that here with anthropic, so they're they're showing how much of the job is able to be automated or augmented by AI. And yes, software developers are at the top 5.2%. So if I'm reading this correctly, they've identified 5.2% of the various, you know, onet classifications of those skills can be automated. And these they don't have data on. So for example, could a large language model train users to use a new or modified equipment?

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

Having used the JAGBT anthropic and Gemini to walk me through a lot of technical stuff, I I would say yes. I'm sure there's limitations, but it could certainly do some of that. Specify power supply requirements and configuration maybe. But the point is like these are estimates. This is just what we know exists, right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

We know it's at least this. So notice data warehousing specialists are also very very high in the list. computer programmers, web developers, various other computer tasks, bioinformatics technicians. We also have tutors, educational instruction, and a library. I think this number is likely a lot higher.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

You can learn a lot with just access to a good chatbot with a a good model behind it. Then we have copy writers. I feel this has to be a lot higher. So for example, one of the things they don't have data on is very language tone of messages based on product and medium. I mean this is kind of what large language models were made for.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

review advertising trends, consumer surveys, etc. or present drafts and ideas to clients again from that GDP val that we looked at. I mean, it's doing presentations, it's putting together various reports. Like a lot of this it could automate and for a lot of these other jobs, it it seems like eventually a lot of these skills can be replaced by large language models greatly automated or augmented. I mean, notice here financial analysts, they're saying.14%.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

But as we've seen with GPT 5.2, I mean, there's a big leap from what it used to be able to do to what it does now. Meaning that if we took all the latest data that OpenAI has with these benchmarks and we updated all these jobs and how they're going to be affected and could they be automated with AI, maybe that would look pretty bleak because keep in mind the earlier version of GDP val that was September 2025 anthropics economic index that we're looking at now is September 2025 and Dario was ringing the alarm in May of 2025. Right? So when they were seeing these effects, the potential effects in the future, they were already saying, "Hey, this could be a bloodbath for white collar employment, this 20% drop off in headcount for the people in their early career for for software developers, you know, we saw that by July 2025. Back then we did not have a large language model that was released to the public that was better than humans at completing those projects, right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

So, you know, whatever, 3 4 months ago, if you wanted to use an LLM, you would get inferior results. The projects that were completed would not be quite as good as if you just let a human being handle them. Now, as as soon as it gets to human expert level parody, right? So, where it's like you could either give it to the humor or the LM. It doesn't matter in terms of the quality of the output.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

I mean, that's kind of the point at which a lot of people, a lot of employers might consider switching to the LLM. It's probably cheaper, faster, less less liability. I mean, we would have a unemployment nightmare if it just reached parody 50/50 and then just stopped there. So, if it got to be as good as the average human level expert, that alone could have probably replaced all of those jobs or or projects they were doing. It would have been done by LMS, but it didn't match 50/50, right?

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

It went above and beyond, so to speak, right? So, almost let's let's call it 74% 74% tie or win rate. combined, you know, versus a human level expert. So, could there be some potentially negative research that OpenAI has access to kind of showing like what what the next step is in this direction after what Anthropic has published and and Stanford in collaboration with Anthropic have published however long ago 3 4 months ago. Right now, we're seeing the next generation of models that are that are even better, right?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

So, they they were slightly under humans, then they exceeded humans, they're better than humans. So what is the economic impact if we have a glimpse into that certainly that would be eyeopening and certainly if you're trying to IPO and uh you have something like that right publishing it could paint a a target on you so that could be plausible again take it with a grain of salt we don't know what's happening behind the scenes certainly these things can be greatly overblown for example you know if we scroll down here after this article describes the situ situation that's happening. They they add this little paragraph. Uh take a listen. The reported censorship or at least hostility towards pursuing a work that paints AI in an unflattering light is emblematic of OpenAI's shift from a nonprofit and ostensibly altruist roots as it transforms instead into a global economic juggernaut.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

Wow, that's very very poetic. So I decided to paste that into Gemini and and ask if this is in fact a biasfree statement. Gemini did not have to think that hard about it's like no this is not a a bias free statement even bolded than not. While the statement may be based on reported events the language it used to describe them is highly subjective interpretive and emotionally charged. It reads kind of like an opinion piece and it explains why right the charged terminology hostility juggernaut censorship points out all the weasel words that were used like ostensibly altruist emblematic of etc.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

Again, the point being here is take everything with a grain of salt. Unfortunately, a lot of reporters can't even pretend to be unbiased when it comes to certain subjects. And as AI is getting better at researching and citing its sources and factchecking everything, I'm already finding myself using it to find real information about news, about events, and and what's happening. I'm using it a lot more and I'm a lot happier with the results because nobody on the other side of the article is trying to get me convinced of whatever politics they happen to believe in or just trying to get me to be a little bit more outraged to get me to click on some ads or whatever. So, I I'm not sure if blood baths have a silver lining, but um you know what?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

I I'll leave it right there. Point being is soon we will likely hear something either from the people that were let go or or perhaps through some other channels or some researchers going to get released if not OpenAI than somebody else. So make sure you're subscribed. Please enable notifications if you can. And just keep this in mind kind of everything is unfolding according to plan.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

This this shouldn't come as a surprise. We knew this was coming. We believe that on the other side of this is potentially a a better future, maybe a post labor future, maybe where we all have a little bit more time to enjoy life, where we don't have to work as hard. That's that's possible. And how we handle the short-term, the medium-term transition is going to depend whether it's going to be a a dream or a nightmare.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

So, rule number one, whatever else you do, don't panic. These things take a while to percolate through society. It's not going too crazy fast, although definitely more fast than is comfortable. There are some very smart people thinking about how to approach these subjects. This isn't happening in a vacuum.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

And the kind of good news is that it's going to affect everybody. This isn't one of those situations where some small portion of the population gets affected and everybody else is like, "Yeah, whatever. It's fine. Doesn't bother me." No, this is this is everybody. So, we're going to figure this out.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

We just need to manage that transition intelligently. Anyways, hopefully that helped. If you stayed this far, thank you so much for watching.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
