# ğŸ“º Google just killed OpenAI...

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Google just killed OpenAI...
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=PshNZ1zztgo](https://www.youtube.com/watch?v=PshNZ1zztgo)
- **å‹•ç”»ID**: PshNZ1zztgo
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ03æ—¥ 13:21
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

They will definitely want to come out and show that they can dance and I want people to know that we made them dance and I think that'll be a great day. >> Openai and Microsoft wanted to make Google dance and dance did. Now OpenAI CEO declares code red to combat threats to ChadBt delays ads effort. So let's talk about this. What happened?

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

3 weeks ago on November 10th, I did a video saying no one sees it coming except Google where I outlined why Google is about to start dominating. This is before the stealth roll out of Gemini 3.0 and certainly before the actual rollout of 3.0, before the new Nana Banana dropped. This is before Warren Buffett bought a whole bunch of Google stock or at least before everybody else knew about it. That's when it was revealed. This is before Simeonasus posted their excellent write up about Nvidia and Google and their approach to building these AI chips and their excellent cartoon explainer of what's happening for people that don't want to read the entire blog post that they published.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Here's the thing. Everybody is sort of looking at different parts of the Google's business and saying that they're going to kill it. In my original video, I mainly highlighted the research that they're putting out that is getting kind of buried amidst the big headlines, right? It's sort of falling off to the side, even though it has huge implications. It's research into continuous learning.

### ğŸ“ è©³ç´°èª¬æ˜

It's research into alternative ways of powering these AI data centers, drug discovery, as well as their AI chips. The idea being that they're playing the long game. They're planning to win in the long run. There are people that are making a bullcase for Gemini just based on the performance of Gemini 3. There are some people that are completely all in on the TPUs that they're producing and the massive massive business that that could be in the future, whether they're selling it through the cloud or even better if they start competing with Nvidia by actually selling those chips to people that are building out the AI data centers similar to how Nvidia does it.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

Warren Buffett probably has his own reasoning for why he's buying the stock. The point here being is Google seems to be compounding on all fronts. It seems to be winning on all fronts. It had a late start, but slowly it's beginning to accelerate a little bit faster. And over time, you begin to realize that between their models, the infrastructure, the massive capital that they have, the massive talent pool, their access to massive amounts of data, all those things kind of point to the fact that if they're going full steam, they will become an absolute juggernaut in this AI space.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

We're not even mentioning Project Genesis. So, it's their partnership with the White House. They're going to be getting a lot of I'm assuming classified data along with other frontier labs but Google is one of them and along with the White House they'll be building some sort of a scientific AI researcher. We covered in the previous video details are still a little bit fuzzy but obviously seems like a big deal. Now at the same time some people have reported seeing ads begin to appear in Chad GPT.

### ğŸ¯ å¿œç”¨ä¾‹

Some people are saying that references to some sort of an ad serving abilities appearing in kind of a behind-the-scenes code that runs at Chad GBT. I haven't verified those claims, but it seems like OpenAI was getting ready to start using ads for the free accounts in ChadBt. Well, that's on hold for the time being and Sam Alman is declaring code red to now try to battle Google. Gemini users are rapidly increasing. Anthropic has of course a lot of enterprise customers.

### ğŸ’­ è€ƒå¯Ÿ

So there's pressure on OpenAI from the other frontier labs that are out competing them in their own sort of areas. And some of the internal memos that we've been seeing coming out of OpenAI are kind of showing us that the people inside OpenAI are are not blind to this. They're very very aware of what's happening and they're worried and they're realizing that maybe they need to start dancing as well as Sait Nadella put it. By the way, if you're not aware of that reference, so that's the Microsoft CEO Saitinadella. He was saying back in the days where it seemed like Open AI and everyone else had a lead and Google maybe was struggling a little bit.

### ğŸ“Œ ã¾ã¨ã‚

It was falling behind. He was saying how with their innovation, they're going to put pressure on Google and, you know, make them dance. So, tons of respect to Satin Nadella, to Sam Alman. They're very competitive. They're in it to win it.

### âœ… çµè«–

They called out Google and Google responded and they responded in a very big way. It was a delayed result, but now they've sort of woken up the sleeping giant. And it's now, as they say, Google's race to lose. They're in the lead, and unless they make some pretty big errors, they're going to stay in the lead. Hey, quick aside.

### ğŸ“š è¿½åŠ æƒ…å ±

If you're asking ChadBt to help you with stuff, that's a great start. But the future is automations. It's AI agents working tirelessly on your behalf and humming along like happy little digital bees. In this section, I'll show you how to build your very own N8N automations. that can power your business or whatever else is taking up your time.

### ğŸ”– è£œè¶³

N8N is an open-source self-hostable automation tool and it's not the sponsor of today's video. To make launching our Nan automations easy and to be sure they're working entirely 24/7 online, we are going to use Hostinger which has a true one-click deployment of Nan automations as well as a built-in Q mode for high volume automations and a library of 100 plus ready-made workflow templates. So, the setup time is basically zero. Hostinger is the sponsor of this video. For this automation project, the recommended option is this KVM2 VPS plan.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Includes two vCPUs, 8 gigs of RAM, 100 gigs of fast NVME disc storage, and 8 terabytes of bandwidth. It's hosting's most pick tier for automation workflows because it's powerful enough to run continuous 24/7 execution without overspending. The biggest advantage is cost efficiency. N is fully free when you self-host it. That means the only thing you're paying for is the VPS, which typically ends up being three to four times cheaper than the equivalent usage on the NAN cloud.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

You get unlimited workflows, unlimited concurrent executions, and complete control over scaling. From here, adding the plan to the cart is straightforward. We're going to select KVM2, proceed to checkout, and apply the code west at hostinger.com/westroth to lock in the discount. After completing the purchase, the onboarding wizard walks you through the install process automatically. Once inside the dashboard, you can deploy NAN instantly using Hostinger's one-click installation template.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

The system provisions everything, runtime, dependencies, and environment variables without manual configuration. When the workspace is ready, you can take the workflow built in this video and deploy directly into the VPS to run continuously. Here's my issue. I need a way to keep up with AI news in real time. This used to be a task a simple mortal like myself could do on my own.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Now, I have to have a veritable AI agent swarm to have a chance. So, let's begin. The first thing we need is to decide what triggers it to start. This is the trigger and can be a Slack message or email or a time of day or an account posting something on X or whatever else you want. You can have it run on a set schedule, even every minute if you so choose.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Then we take the data from that event and run it through a gauntlet of steps that can include third party apps, various AI models, as well as logic checks and various flowchart style decision trees. All of this with no code. So, let me quickly show you how I would start building my AI news aggregator. First, let's script the news from X/ Twitter, some of our favorite YouTube channels, Hacker News, Reddit, etc. So, for example, if we wanted to get Hacker News, there's an app for that.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

There's an actual node for that. We want to get an article. So, this nodes goes on Hacker News. It gets the top 100 articles and it returns them here. We can use it in a JSON format.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

And this could be running every 1 minute, 5 minutes, 15 minutes, whatever. Or what I'd like to do is just to have my favorite AI chat assistant write me some JavaScript code that does whatever it is that I like. I add the code in JavaScript node. Paste that code in and here for example it returns the last 10 stories on hacker news. Format it in JSON format.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Easy. We can do the same thing for YouTube either with the YouTube API or just with a HTTP request. We use get URL is that that basically looks at the feed for any given channel on YouTube. By the way, if you don't know these URLs, just ask your favorite AI chatbot. Most of them will have this data for you.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

As we're getting the various headlines, we need to make sure we merge it into a single list to make sure that we have all the data that we're going to need for later. Google Sheets work really well here. Just append a row with the new headline. So, we got our stories here. Next, let's merge it all into a single list so we have all the data we need for later.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

I like to use Google Sheets. So, we're going to append a row in a sheet for every new story. You are going to need to connect your Google account in the credentials. I have my title, date, and URL columns in Google Sheets. And the values that I want to send is the title, the date, and time.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

and of course the URL. And here it is. It populates everything just like it's supposed to. Next, we apply the importance rubric and a branch. Here we're going to ask Google Gemini to rate how important this news story is.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

So, we're going to ask Gemini to take a look at this story, the latest news story that came in and rate 1 to 10 on the important scale according to the following criteria. And then we have our criteria for how important it is, which is probably going to be a work in process. Keep tweaking it and updating it until the model is able to match your importance criteria perfectly. So here we have the Gemini's output with its reasoning. Really, we just can use the reasoning to see if it makes sense or not, but we just want the score.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

Gemini can also be used to analyze YouTube videos without needing to download them. Just give it the URL and it'll describe whatever is happening in the video, answer any and all questions about it, etc. So now we have our agents scouring the web and pulling all information into a Google sheet and then ranking them based on importance. By the way, I often separate everything into their own workflows just to keep everything manageable. If you have a workflow like this for example, each separate one can be a workflow or you can create a massive workflow that encapsulates everything.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

I love looking at this. I prefer working with this. Okay, so now we have everything in our Google sheet. Now we use a simple logic node to separate what we're going to do with the story based on certain criteria. We add a node flow.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

If the importance of our story is above a certain threshold, then we want to do one thing. Otherwise, we do something else. If it's for example greater than importance than eight, we want to do one thing. And if it's not, then we want to do something else. And now we get to the output side.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

Let's say it's an important story when we're posted it to our blog, or maybe just in our Slack channel. If it's important, we'll create a WordPress post. And if it's not as important, well, we still want to hear about it, send it to my Slack channel. I can have it create a Reddit post, a tweet post, whatever you want. Obviously, make sure you're following the toos and don't spam.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Now, of course, you need to add your credentials for each one of those things. Comment down below if you want a full deep dive and walkthrough of how to build these, including detailed step-by-step directions. Once your automation is live, Hostinger takes care of all the tech and heavy lifting. The great thing with Hostinger is that you're not capped. Unlimited workflows, unlimited concurrent executions, community nodes, and a Hostinger API, N8 node to automate your VPS and domains from inside N8N.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Need more power? Just upgrade the plan with zero reinstall. Automate smarter. Go to hostinger.com/wwestroth and use the code westroth for an additional discount on yearly plans. Build today, scale tomorrow.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

And now, let's get back to the show. So, Openai is planning to release a new model that's going to be competitive with Gemini 3. The code name Garlic has been floating around. I can't help but feel these internal names are shots across the bow from both companies. Google will name when they're testing their new models, they'll name it something that has some meaning that kind of takes a stab at Open EI and vice versa.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

Is it just me? Am I missing that? Let me know if you agree. I'm not crazy, right? Cuz there was that whole video of Sam Alman cooking his kitchen, chopping up tons of garlic.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

This is from that shot, right? That's the green bottle of whatever olive oil they're using. Then at the Google IO, they had the VO3, I think, was introduced with this like frying stuff up and the whole thing was they had sound. And now we have OpenAI with their garlic model. I don't know, maybe I'm connecting dots that are not there.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Let me know what you think. Recently, an internal memo from OpenAI had some was saying that he expects rough vibes for a bit because of you know big part due to Google. So the situation might be looking rough for OpenAI. In a call with investors, their CFO mentioned that growth is slowing. Meanwhile, for Google, they had 450 million users for the Gemini platform in July.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

So, 450 million active users in July and in October, 650 million active users. So, the user game is going great for Google and Gemini. But that might not even be the most important metric in terms of who's going to win, you know, in the long haul. Gemini 3 was trained on Google's own tensor processing units TPUs. This training was done exclusively on Google's customuilt hardware.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

So currently the best model available Gemini 3 was completely trained without relying on Nvidia's GPUs. So this is from a semi analysis that kind of shows you why that's so meaningful. So a lot of our attention right now focuses on hardware for inference and post-training. Yet, it's the pre-training of the frontier model that remains the hardest and most resource inensive challenge right now. So, Google trained everything themselves on their own hardware and produced a state-of-the-art model.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

By contrast, Opening Ei's leading researchers have not completed a successful full-scale pre-training run that was broadly deployed for a new Frontier model since GPT40 in May 2024, highlighting the significant technical hurdle that Google's TPU fleet has managed to overcome. This little sentence here is like a third of the way into the article. It's kind of buried in there, but wow, is it huge. Like, think about the massive difference between those two statements. Google trains a state-of-the-art model on their own hardware.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

Hardware they don't sell. They they they are beginning to lease it through their cloud services. So, Enthropic is able to use it through Google's cloud. But if you wanted to build your own data centers with, you know, metal racks and put your own TPUs in there, you you can't do that. You can do that with Nvidia technology, but not Google.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

Meanwhile, OpenAI, who relies on outside funding and who relies on Nvidia's technology, hasn't had a successful full-scale pre-training run since GPT40 in May 2024. Also, if you recall, there's that acquisition of Windsurf. There's actually a few acquisitions of Windsurf. Different people sort of got different parts of the company. But Google did the aqua hire of former Windsurf CEO Verun Moan and his team and out of that was born anti-gravity.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

Anti-gravity is of course Google's answer to OpenAI codeex. You could say also to cursor all the other similar coding AI platforms that are out there. And it officially enters Gemini into the vibe coding token guzzling wars. So super fast, let me sketch something out here so you kind of have an understanding of the different layers. One layer is sort of the chips, the hardware, the people that make, design and sell hardware, GPUs, TPUs, etc.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

Then you have the data centers. So this is where you buy the chips, you put them on metal racks, you connect them together, you make sure you have your your cooling, your power, etc., etc., etc. There's companies that just buy those chips, create those data centers, and then just sell that capacity to the the labs, the frontier labs, right? So we can say labs, right? So these are the people that make the actual models.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

OpenAI, Anthropic, Google, XAI, etc. And then kind of at the top there is the application layer, right? We'll just call it apps. So that's the outputs of those models, right? Like there's a million different ways you can use AI applications to make something useful, whether it's for coding or research or writing emails or making picture, whatever the video generation platforms, anything.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

And there's some companies that are really good at this layer, some companies that are uh good at this layer, some companies that are good at this layer, etc., etc., etc. But guess where Google is now? Google now is is here. Let me let me get a thicker marker here. Google is here.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

It's the alpha and omega. It's everything. It's across all the layers, right? Does it have chips? Yes, it has TPUs, its own hardware.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Does it have its own data center? Yes, Google Cloud. It's expanding massively. Are they an AI lab? Absolutely.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

They have every type of model. They have a video model. They have an LLM, bestin-class LLM right now. Not a banana VO. They have their own music thing.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

They have the imaging. They have like a million different models. Even if you don't count all the alpha models like alpha fold, alpha code, alpha cubit, like there's more models than we can probably count. So yes, they're an AI lab. Do they have applications?

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

Yes, of course. They just released anti-gravity, but that's not the only one. They have jewels. They have Firebase. I mean, they have a lot of different ones maybe targeted at different people.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

And that's just kind of in the coding sector. I mean, the Gemini model is coming to Google Maps. Apparently, it's coming to Google Home. It's coming to just everywhere where you can shove a large language model. Google will shove Gemini there.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

And obviously some people are scared. The application layer like cursor, they're probably not super duper happy about this. Google has tons of users, tons of smart people developing software. So they're in direct competition with Google. And every other app that's in direct competition is probably kind of scared.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

Are the other labs scared? I mean, yeah. again. So, OpenAI is declaring code red. Anthropic signed some insane deal with Google as well so that they're able to use the Google cloud.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

So, Enthropic is also in some way having to rely on a competing Frontier Lab. Should the data centers be worried? Probably. I mean, if you're buying stuff from Nvidia and you're building out data centers and there's the TPUs, which some people say are better for specifically machine learning tasks. As Google ramps up and gets up to speed and provides cloud solutions, number one, you can't replicate it by buying TPUs.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

You have to rely on Google. And of course, Google can exert a lot of pressure through price, you know, strategies on these data centers and in fact on Nvidia and the other chip manufacturers. Now, if you're familiar with the semi analysis team, the writers in that team, I mean, a lot of people know Dylan Patel, but the point is those articles aren't just made by him. He has a host of very talented writers who are experts in their area. For example, Jeremy.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

So Jeremy is the head of data center and energy infrastructure research at semi analysis and to say that he knows his stuff is a little bit of an understatement. He really knows his stuff. We were very fortunate to be able to get him for an interview just a couple days ago. This was before this recent semi analysis post that we just looked at. So this is before some of the stuff we looked at here.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

I believe we interviewed them the Friday before Thanksgiving. But here's a clip of our conversation where we specifically talked about what is Google up to. My ability to formulate coherent questions that morning was absolutely gone for some reason. But let's take a look. So Nvidia really people can build their own like racks and stuff with TPUs with Google software.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

They're not allowing that. It looks like they have Enthropic, maybe a few other ones, but so far they're not doing any sort of external sales mostly. What do you think is going to happen with with TPUs over the next several years? Do you expect Google to become a bigger player? >> Yes, for sure.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

So, I I guess the the high level view here is that the reason Nvidia has such a high margin is so dominant is because they're the best by far, at least the best at providing a merchant solution that anyone can use. But so, Google is interesting because if you think about who has the actual best system for AI training and AI inference, it's a close match. uh they have their advantages and disadvantages but TPU is generally considered call it maybe slightly behind Nvidia or maybe as good as Nvidia exactly depends on on on on the exact portals and such but so it's like actually the most competitive solution with Nvidia and then if you think about it it's interesting because Google is what like a three trillion dollar company and Nvidia is what like $4 to5 trillion so the is more valuable than Google which does howler but also search and all that stuff so it is pretty uh pretty incredible >> yeah Yeah, the reason I would say Google has generally not been competitive with Nvidia obviously is business model that always sold through the cloud. So it's their deployment. You cannot buy TPUs as a rack and put your own data set up.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

So you you're dependent on one cloud provider which is Google and dependent on their capacity plans and all of that. You cannot go sort of vertical and be like I want to buy a million GPUs this year and 2 million next year. That didn't exist previously. You were really depend on whatever Google wanted to do. Uh so that was an issue.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

And the other one is from a I guess software perspective like it's well known that Nvidia has the kua mode on so many developers using the Nvidia platform. A lot of software packages and things like that that make the life easier for any anyone who programs on Nvidia. Google is more of a Google world. People are not that familiar with the Google stack besides people inside Google. But this is actually where it gets interesting because people inside Google have actually been changing companies a lot, right?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

like you've seen a lot of hiring of ex Google engineers at OpenAI at Anthropic at others and so you have people who are actually familiar with that programming stack that are going to other uh other companies right and this is why it makes sense for Google because there's such a big organization that okay they do everything internal they have this weird software stack that no one else knows how to use but because they're so big it makes sense for them and may actually be paying off as we saw they landed a massive deal with Anthropic and so like that's really the first time they're going to sell externally uh GPU systems as a direct competitor to Nvidia. So, it is actually a pretty big change in the industry. Definitely something worth tracking. Yeah. I mean, maybe we can pause here and I'm sure you have a whole bunch of other questions.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

Yeah, this is this is so interesting because it just I'm so curious to see how Google plays this and yeah, like like you said, so they don't really let you take, you know, whatever, take it home, tinker it or build your own data center. It's all through Google Cloud. It's notoriously kind of difficult. >> Yes. I was just going to say like if we go back to our earlier framework of like breaking things down by layer, >> right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

uh the end user layer again like it's essentially five companies that are really huge and there's there's a bunch of other startups like thinking machines or SSI or a few others this draw it's not a lot of end users and the reason it's not a lot of end users also because the talent pool is pretty limited there aren't that many ML researchers that actually know how to use that type of hardware and Google is actually huge one in in in that sort of talent pool right like so many people have went through Google so like you could actually see a world where because Google has such a dominant AI talent Many many of the young talents are actually getting used to their their custom stack and so the disadvantage that they used to have versus Nvidia doesn't really apply in this world which is so niche because they have such a high presence and again like you're seeing that the some exglers having hired OpenAI an entropic meta and so on and so forth. So you have people with TPU experience going to every other big lab and right if they know how to use it and the system is actually good or even better than Nvidia then yes you definitely have finally at some extent a real like very sort of existential competitor to Nvidia with a system that is equally as good and like also I just want to emphasize I I I I say system a lot because it's crucial in this world to think about systems and the reason Google has been so successful is because they actually were the first to think uh on system level meaning that If you look at the typical Nvidia server race box with a GPUs to metal box with a GPUs and what Jensen and other Nvidians love talking about in 255 is the GB 200 NV72 which is this vertically integrated rack which can connect to 72 GPU with NVI amazing we've done some benchmarking on infus max or open source benchmark it is uh for some work was a real breakthrough we can do a 10x including the performance but Google has actually been thinking about system level uh architectures for many years for nearly a decade now so they actually have experience and have been doing system level integrations prior to to Nvidia doing that. So they they understand very well the workloads. Their system is very competitive. The gross margin the Google layer is actually lower than Nvidia.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

They don't charge 75%. They charge a lot. Uh it's not 75. So yeah, it's a real competitor. And if they manage to sort of democratize that, which I think they plan to do, uh it's going to be interesting to see how that evolves.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

>> And they're going to be on every layer basically at that point, right? Because they're a chip manufacturer or you you know they have their own chips. They're going to have their own cloud. you know, they are going to be using the the chips to run whatever it is that they're running to build models, to run inference, and they also have their applications. They just announced anti-gravity, which seems like a competitor to like cursor or whatever.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

What happens if Google comes out at some point and basically effectively builds a price ceiling for tokens per dollar or whatever, right? >> So, obviously more competition could uh make Nvidia lower their prices. We actually have seen that already for a while. About a year ago, AMD was getting closer. They had few delays, but in terms of like where we thought they were going to be, they appeared to be getting closer and they actually led Jensen to lower pricing a bit and slightly lower gross margin.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

Uh it's it's interesting because if you analyze sort of the gross margin or the the markup that Nvidia charges on top of their bill of materials, there's been a trend where like it's been like this. It's slightly slightly down and now it's up again because he feels very good about GB2 300 and and the road map right now. Um so anyways all of this to say yes competition will have an impact for sure if it's big enough. Now the question is going to be like is the solution competitive on a whatever it is the metric like is it price per uh price per tokens per per dollar a fluffy like it's all of it just just imagine a blended metric of like performance per dollar >> that is going to be the real definer like if Google can actually outpace the current Nvidia yes it's going to lead to most likely prices going down now it is interesting because in the history of semiconductors those are very high value added layers. We have very rarely seen an industry where gross margins are cut to an extent that people don't make a good living if that makes sense.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

Generally what you see in this industry is the number one makes very good profits the number two doesn't make as good profits but if you look at the gross margin still is still like whatever depends on the metal market like 50% 60%. So it would be very surprising from historical context stuff like the global margin were to go down to an extent that they're not making good enough profits and obviously making good profits matters because like the reason videos was 4 trillion or 5 trillion is not just sales it's also gross margin right and sales are actually a function of the market they have on on on bill materials actually sales are direct so yeah the other issue that Google has is that building their system is incredibly complicated and they're not doing that alone so there's a semicolon another company out there called Broadcom, which is not maybe a household name, but probably should be because they're worth a trillion dollars now. So, actually a pretty swish company and Broadcom has some crucial IP that Google absolutely needs to build CPUs. Without this IP, they're not competitive. And Broadcom obviously understands that and so they're charging a lot of money for IP.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

>> It's not like Google operates on a fully verticalized model. uh as we've seen in the past for example like in in the past you've seen some CPUs like pay some margin to ARM ARN but the margin stock wasn't nearly as high so it was easy to build a custom CPU that could output that could beat Intel on sort of price per performance in this era Nvidia charges 75% but Broadcom charges well above 60% as well on the whole system so like Google does have its own constraints

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
