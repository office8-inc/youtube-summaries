# ğŸ“º Google DeepMind: "The arrival of AGI"

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Google DeepMind: "The arrival of AGI"
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=hUabJaV0h8w](https://www.youtube.com/watch?v=hUabJaV0h8w)
- **å‹•ç”»ID**: hUabJaV0h8w
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ14æ—¥ 00:44
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

So things are heating up in the world of AI and the conversation about AI is beginning to change. This chart presents what's happening I think in a very good way and not for the reasons for which they created it but just for the reason that it exists. This is the Federal Reserve Bank of Dallas. This is not a joke. This is a bunch of bankers sitting around kind of putting things together and discussing it with very serious faces.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

And it shows that somewhere here, so before 2035 and sometime after, you know, the current moment, there are two big potential changes to how things were for a long time. And in one of them, things are incredibly good and in one of them, things are incredibly bad. Even a few years ago, this chart would have been unthinkable. It would not be a, you know, serious chart. And today, as you'll see, it's part of the conversation.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

10 years ago, almost to the day, OpenAI started up. I think they announced it December 11th and this is a few weeks later, January 4th, the first kind of official day everybody gathered. And alongside this, Sam Alman just posted his blog post about what the next 10 years might look like. And some of those predictions are wild or would have been absolutely insane even a few years ago. But here's the thing.

### ğŸ“ è©³ç´°èª¬æ˜

Shane Alleg, the co-founder of DeepMind, he went on the Google DeepMind podcast with Hannah Fry. So they did a an interview together. They titled it the arrival of AGI and they're kind of beginning to say the quiet part out loud. The gloves are coming off. They're they're saying what's going to happen.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

They're beginning to talk about like what happens kind of here around this point. No one's saying that it's a business as usual. Business as usual status quo that's that's been thrown out the window. So, OpenAI is saying it. Google Deep Mind at least one of the co-founders of of Deep Mind is is talking about it.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

There's another podcast that we'll look at that has a lot of highly highly influential people who not only know a lot about this but also have a lot of real tangible power in the space and they're beginning to talk about in very real terms. Again, discussing how this happens, how this happens. By the way, if you're audio only, what we're looking at is a chart of how kind of the economy has shaped over the last 100 plus years. And it's kind of showing that very soon, well before 2035, things might go completely off the rails. never before seen kind of a changes in the inflection of that curve.

### ğŸ¯ å¿œç”¨ä¾‹

And there's two of those events, two of those curves kind of splitting off. One is singularity, the benign scenario, and one is a singularity kind of extinction, the extinction event. And we're kind of approaching this insane injunction where the next 10 years or even the next few years will be unlike anything we've ever seen before. And we're seeing very smart, very serious people start having actual serious discussions about this. like it's no longer flowery language and hypotheticals.

### ğŸ’­ è€ƒå¯Ÿ

It's more like what do we actually do? But first, let's take a look at a very wonderful and very long running AI agent experiment called AI digest and their project AI village where the best language models in the world go and try to complete some tasks while having access to the computer, internet, Google Drive, like a whole bunch of stuff. And they're working together to achieve certain things. The stuff that they've been able to achieve might come as a surprise to you if you haven't seen this project before. All this is very, very real.

### ğŸ“Œ ã¾ã¨ã‚

Their actions are recorded. And today is kind of a big day because GPT 5.2 joined the village. As you'll see, it does seem like we're hitting a certain inflection point. We also have a very interesting announcement by AWS. So, make sure you're subscribed.

### âœ… çµè«–

Make sure you have your notifications on. Things are heating up. So, let's dive in. This might be kind of hard to imagine, but it's been 10 years to the day as of December 11th since OpenAI was founded. Here's an older tweet from Sam Alman.

### ğŸ“š è¿½åŠ æƒ…å ±

So this is this picture is the first day of OpenAI. I think that's Ilia Sutskcover over there. That's Greg. That was a long long time ago. So they announced the effort 10 years ago, December 11th.

### ğŸ”– è£œè¶³

And that picture on the first day, that was early January 2016. There are a lot of very interesting descriptions of how they started, how they built a culture of discovery, how many wins and losses they have. This is before Google's attention on a unique paper, the transformer architecture. They were doing a lot of stuff with reinforcement learning and without large language models. It was a very different time back then.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

In 2017, they had several foundational results. the Dota 1 versus one results where we pushed the reinforcement learning to new levels of scale, the unsupervised sentiment neuron, where we saw a language model undeniably learned semantics rather than just syntax. It's interesting to think that not that long ago, you know, these were kind of big discoveries. Quick aside, just in case you haven't heard me mention this before, we are leaving the era of the AI chatbot and we are entering the era of the AI agent. We are moving from an AI that just chats to an AI that actually does work.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Well, AWS reinvent 2025 just wrapped up and looking at the announcements, the timeline's just accelerated. The agentic era isn't coming, it's here right now. AWS is sponsoring this segment and I want to break down the three updates from the keynotes that proves that they are building the operating system for this new reality. First, and this is the headline, frontier agents. AWS introduced a new class of AI agent that doesn't just assist with tasks.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

They deliver complete outcomes. The big one here is Kirao. This is an autonomous agent that runs alongside your developers. It doesn't just autocomplete code. It takes items from your backlog, figures out how to deliver the feature, triages bugs, and improves code coverage independently.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

It maintains context, learns your team's standards, and works in the background. They also launched the AWS security agent and AWS DevOps agent. These integrate with your observability tools to catch vulnerabilities and stop incidents before they happen. This is the definition of proactive AI. Second, for the builders who want to create their own agents, the toolkit just got a massive upgrade on Amazon Bedrock.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

They launched the Amazon Nova 2 model family. You've got Nova 2 Sonic for real time voice agents and Nova 2 Omni for multimedia reasoning. But the sleeper hit here is Amazon Nova Act. This is a model specifically optimized for UI automation. It can browse the web and execute workflows with a level of reliability that we haven't seen before.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

And with Bedrock Agent Core, they've solved the biggest problem with agents, trust. Now you have policy controls and evaluations. So you can actually monitor these agents and put them into production without them going off the rails. And finally, we have to talk about the metal. You can't have infinite agents without the compute to back it up.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

AWS announced Tranium 3 ultra servers. It's their most advanced custom silicon yet. It's designed specifically to drive down the cost of inference and training. They also revealed project Rainineer, which is where they're training these frontier models using massive clusters of training chips. Whether you are using Nova Forge to build custom models or running agents 247, AWS has built the infrastructure to make this economically viable.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Look, the takeaway from reinvent 2025 is clear. It's about agents that deliver complete outcomes, not just assistance. Whether you want to use Kro to write code or use Bedrock to build your own custom agents, the stack is ready. I've linked the full breakdown of the announcements and the keynotes in the description below. Go check out the Kero demo.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

It's wild. Huge thanks to AWS for sponsoring this video. Now, let's get back to it. Let's travel back in time. This is April 6th, 2017.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Really not that long ago if you think about it. And I think a lot of the people that say that these large language models, they're just fancy autocompletes. They don't actually understand anything. This at the core of it is I think what those people don't understand. This model was taught to predict the next character in the text of Amazon reviews.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

It was unsupervised learning. We weren't telling it what's good, what's bad. We weren't doing anything like that. We're just like what's the next letter, what's the next word, etc. And so here they discover something huge, something surprising.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

And these are researchers that have been studying, you know, machine learning. So when they say they found something surprising, that means something. It means that they found something new, something that we didn't know about, something we maybe didn't expect. They said, "We were very surprised that our model learned an interpretable feature that simply predicting the next character in Amazon reviews resulted in discovering the concept of sentiment." So they were training this model to predict the next token. And it's it used surprisingly few of the learned units.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So it was like just more efficient. So they were wondering like what's happening here? how to get that efficient at predicting the next token. And when they dug in, they realized that there actually existed a single sentiment neuron that's highly predictive of the sentiment value. So there's a certain neuron or cluster of of neurons.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

And when the machine is writing a negative review versus a positive review, when it's trying to predict tokens for one of the other, it's obvious that different parts of its brain light up. Like if you see those MRI scans or whatever, it's like this person is doing math, right? And like one part of the brain lights up. This person is reliving happy fond memories. Some other part of the brain lights up here.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Different parts of the neural network that is this little language model. Different parts of it lit up depending on whether it was writing a negative review or a positive review. And this is kind of like the really important thing to understand about these models, especially for people that say, "Oh, they're just predicting the next token." Yes. Yes, they are. But how?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

What needs to happen in that brain in that digital brain for it to be able to predict the next token? Well, what happens is it has some representations of reality, some mental models or whatever you want to call it that get formed for it to better be able to predict how the next token should go. So, no one told that there are negative reviews or or positive reviews like none of that is within anything that this model learned about. So, it kind of came up with that on its own. And obviously, it's not thinking of it as negative or positive.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

just different parts of their brain got separated to be able to write positive reviews and negative reviews. Now, that's what we kind of labeled that. But it it doesn't matter what we label it. The point is it sort of found a way to model those concepts that it has never been taught. And if they kind of bumped it to more of the positive neuron, it would write positive, you know, reviews.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

And if they would bump it to be a little bit negative, it would write negative reviews. But the point is that these models learn implicitly, not just explicitly. So explicitly is when we just spell it out. We tell it what to do. Implicitly is more kind of picking it up on its own.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

Kind of like kids, right? So parents explicitly tell him what they should be doing. Like don't be bad, Timmy. Don't lie. And Timmy hears that, but Timmy's also like taking in tons of data from the environment, from other people, and even from your own actions.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So while you might have told Timmy explicitly, don't lie, Timmy's learning implicitly from a million different sources and forming their own opinion. Timmy might form completely different of beings from you and maybe even eventually understand the world better. And OpenAI in 2017 was kind of discovering that something similar happens with these neural nets. So they pressed on and made the technology better and launched Chad GBT 3 years ago. Can you believe that?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

3 years ago the world took notice and then much more when we launched GPT4. All of a sudden AGI was no longer a crazy thing to consider. So from the sentiment neuron to the original CHBT. So that's about four years. Then from CHBT to GBT4, that transition for me was where I like really came online.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

I was like, whoa, something's really happening here. Keep in mind that when OpenI started, they were talking about building EGI. People would laugh at them. People would say that they're crazy. People would completely dismiss those ideas.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

In fact, most of Sam Alman's blog posts from like a year or two years ago, they seemed like they were kind of crazy at that time. Now, if we were to read them, we like, "Well, yeah, sure. Of course, that's how progress will happen." The reason I say that is because this blog post is is going to start getting a little bit spicier. And it's important to understand that this entire time people like Sam Alman and others, they would say things that sounded crazy. then a year would go by or a few years would go by and would be like, "Okay, well that thing that he said is not so crazy." So when you hear him say the next crazy thing, right, kind of keep that in mind.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

By the way, I recommend you do read this blog post because there's a lot in there that I'm kind of skipping over that's important, but you know, one of the points is they developed a strategy of iterative deployment. So we've talked about this. So their idea was let's release it to the world and let's keep releasing it. This is as opposed to a more cautious approach of like, oh, it's so dangerous, we can't release it, right? kind of keeping it behind closed walls.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

They chose to just keep shipping each new version, putting it out there so that society can adapt little by little. This was quite controversial at the time, but I think it's been one of our best decisions, so their best decisions ever, and become the industry standard. I I agree with this. I think that we're seeing the world adapt with things like deep fakes. I think a lot of older people still have a hard time picking up on what's real and what's not.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

But I do feel like a a fairly large part of society is kind of developing a a resistance to it and and kind of knowing, okay, that's probably fake or if they're not sure, they try to verify it somehow. We're developing these new sort of muscles to just accept whatever we see as truth. I was actually explaining this to Brad and Leo the other day, my my friends. We were shooting the new Power Rangers movie and yeah, I mean, they get it. They they agree.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

And here's another image of me kind of explaining how this whole AI thing works to to other people in the space that that have a platform that can talk about it. But on a serious note, notice that we have this technology and nothing's really breaking. Things like Nano Banana didn't break elections, didn't you know cause a market meltdown, didn't cause various scandals in part because most people are aware that everybody has access to this and you shouldn't believe everything you see. If this was behind closed doors, then it might have a big impact if some people could put stuff out like this and and really shape public opinion or create scandals or or whatever. But because everybody's just releasing stuff out there in the wild, we society, everybody, we're forced to adapt.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

So getting back to the blog post, they're saying 10 years into OpenAI, we have an AI that can do better than most of our smartest people at our most difficult intellectual competitions, right? So the mathematical Olympiads and certain coding competitions have been dominated by these models. And here's kind of where this blog post is is getting kind of interesting and uh and out there. So he's saying, "I have never felt more optimistic about our research and product road maps and overall line of sight towards our mission. In 10 more years, I believe we are almost certain to build super intelligence." So he's saying, "I expect the future to feel weird." In some sense, daily life and the things we care most about will change very little.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

It's true. That was one of the interesting things with like Chad GBT and stuff when it started coming out. People were like, "Oh, lives are completely going to change within the next few years." Not really. They they really didn't. I mean, most of us go about our daily lives like normal, even though there's been a lot of changes in technological advancement.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So, somehow saying, "And I'm sure we'll continue to be much more focused on what other people do than we will be on what machines do. But in some other sense, the people of 2035 will be capable of doing things that I just don't think we can easily imagine. Right now, I've been able to use GBT 5.2 to create playable games, 3D playable games with HTML and 3JS that have sound effects and little explosions and various other graphics and particles and whatnot. One shot. I just explain what I want and it creates it.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

Some are expecting that by next year, by 2026, you'd be able to create like full production games with AI, like a a game that you would previously buy on a Steam or whatever, PlayStation, Xbox, whatever. You know, in 2026, you would be able to just create it by prompting a large language model, some AI model. What will you be able to prompt into existence by 2035 is is kind of wild to think about. But the kind of big point that I want to illustrate here, it really comes down to this sentence. In 10 more years we are almost certain to build super intelligence.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

Do you believe that statement? Do you like fully sort of understand that statement? I fully believe that most of us can't fully grasp what that means and how the world will change. So you might sort of logically understand the arguments for it, but just on a kind of a deeper level. We're not we're not groing it, if you will.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Which brings me to my next point. Here's a recent YouTube video by Google DeepMind and Hannah Fry. So this is Shane Le, co-founder of DeepMind. It's called The Arrival of AGI. And again, so this is Google DeepMind, they tend to be pretty conservative with how they title things.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

All right? So when they say the arrival of AGI, it's not there to to get clicks. They really mean something's coming. So if you don't have enough time to watch that video, the part that I'm talking about starts about 40 minutes in. So here they talk about how AI will change the world.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

how not enough people are really thinking about what's going to happen and so I'm just having Gemini kind of condense it so we can talk about it. So what things do they think will will will change? Well well AI will bring the following things. The current system where people contribute mental and physical labor for access to resources may no longer work the same way. And I remember him actually talking about that.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

This is almost a quote or a direct quote. I forget exactly how he phrased it, but it was something very very similar. So think about for what that means. The current system where people contribute mental and physical labor for access to resources. So like what does that mean?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

What is that idea that we're talking about? Some people online will say like oh well that's capitalism and so capitalism will end. I really feel like that's missing the point. This idea of contributing mental and physical labor for access to resources isn't it just one like economic structure. It's just a big big part of life and has been for hundreds and thousands of years.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

You can go back to medieval times. People still worked contributed and got access to resources. you go back to like the hunter and gatherer tribes. It's still working like doing something so that you can have access to resources whether that's hunting or weaving baskets or taking care of kids or just tracking gathering fruits and berries like whatever it is like that's what we did so that we can eat. But it's not like if you gathered a berry you got to eat that berry and nothing else.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

There was always that cooperation and like everybody contributed like it was always a little bit abstracted. if you're part of the tribe, you you kind of contributed and you kind of got something out of it. So, it's not really just about money or capitalism or or jobs. It just kind of how we've existed forever. It's also kind of like how a lot of wild animals tend to live as well.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

Like wolves hunt in a pack, share resources, whatever. Like if you have to think about what is it look like to to be in a system where you just get access to resources, you don't have to contribute anything because something that's like better and smarter and just with access to more knowledge and resources just completely takes care of you like forever. are not just kids while they're growing up, but just for for your whole life. I mean, like house cats, that's the only thing that I can think of uh from the top of my head. The point is that most of the people in the world, we're used to being able to work, right?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

Contribute mental and physical labor to get access to resources, aka money. We don't have an example of a world where that doesn't happen. We have no idea how to make that world work. As I say here, there will be a need for a different method of wealth distribution in a post ai economy and society. So, we don't really have like a workable model for for what that looks like.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

Again, the only thing I can think of is cats. Like cats live their entire life. They just get fed. Nothing is expected with dogs. Even then, there's usually some expectations.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

They do tricks. They guard the house, right? They they wait to poop until you take them on a walk. There's some expectations of some sort of a performance. They contribute something, right?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

Cats contribute nothing. and just have access to resources. They sleep 18 hours a day. So, this is Peter Gustv. He does AI capability at LM Arena.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

He posted that the reason why cats haven't invented the transformer is because they sleep 18 hours a day. I actually don't think this is true. I I disagree with this and I I wasn't afraid to say it here. I said, I don't think this is correct. A community note might be needed.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

Truth is that they refuse to work in Python. They only code in Scratch. Sorry, I got distracted there. On a serious note, think about how embedded this system of working and resources is. The entire process of shaping kids minds and teaching them skills and everything is is in one way or another based on their ability to go and do work.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

From a very young age, we start teaching kids skills that we think will be economically valuable in the future. We also use that system to decide where people live, what they get to have versus what they don't get to have. It organizes what projects we pursue, right? Right? If somebody has some hairbrain scheme like building the largest sand castle ever and they try to recruit a thousand people to work on it, no one's going to go and help that person because again at the end somewhere money has to come in like the people have to get paid in order for the business to make money back.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

Somebody has to pay for the tickets to that business has to buy some product. Like a lot of our lives are somehow tied directly to to money and being able to do work and then allocate resources. Here's the co-founder of Google DeepMind saying that might come to an end and soon and no one's thinking about it, which is true if you think about it. We really don't have workable solutions. We have some ideas.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

We've covered some of those on the show, but we don't have anything that's really fleshed out that's ready to go. Any number of people on X were talking about the recent All-In podcast with they had Tucker Carlson on there and obviously there's going to be political stuff in there that some people will agree, disagree with, tons of controversy, whatever. But as again some people on X have pointed out about twothirds of the way in they talk about the anti-AI sentiment and they point out some interesting ideas. Again this is regardless of politics but one of the things that they were pointing out that China is beginning to think ahead to what's going to happen as automation takes over. For example, they have these ideas about giving licenses to people that will have self-driving cars for them to be able to rent those cars out as taxis.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

or maybe it's licenses for self-driving vehicles in general. The point is they're able to control how many of those hit the road. And the reason for that is because if they just are able to just pull it out there with no restriction and the people that are for example doing deliveries or being taxi drivers, that job market is going to rapidly collapse by having licenses. They're able to kind of control how quickly that spreads. This is kind of very very different from how we think about it in the States.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

I think here in the states we kind of see the two solutions as either hey don't worry about it as in no regulation or ban it as in try to stop it try to prevent it from happening right we either want to meddle with it or like lazy fair don't touch it the China approach as I understand it seems to be like it's coming we can't do anything about it let's just make sure that it happens at a gradual enough rate to where we can adapt and make sure it doesn't just crash everything overnight so whether or not you watch this podcast or not again Right. 49 minutes in. The first 5 minutes you can even skip, but somewhere in there it gets very informative. And I would encourage people to maybe watch at least a little bit of it. Definitely that segment because they they really go past the the silly headlines that we're all seeing and into like the real stuff.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

Can governments use this to control the population? How do we prevent bad actors to to try to kind of like just build their own bias into it? They talk about the potential for tyrannical governments to use AI to basically control the population. They talk about how to approach the whole job loss perspective. How to get the best of AI kind of like those promised things like living a longer automation meaning cheaper prices for goods and services, for healthcare, for housing, for everything without the kind of horrible potential worse outcomes.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

That that kind of chunk of it was a a great discussion around real subjects. And so was this again like this portion here, the societal and economic transition. I assume listen to that part. And what they're saying here is that every faculty and department in universities studying areas where human intelligence is crucial needs to seriously consider the implication of cheap, abundant and capable machine intelligence. If you look at all the education universities around the world and all the systems and ideas that they're built on, what percentage of that is based on the assumption that one young kids, young adults need to learn to work to go and then produce valuable work and make money and that humans are the only thing that can do that.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

being able to produce some sort of a mental labor in order to improve the world or or do something of value. It seems like a big part of education is kind of resting on that assumption. If that assumption is no longer true, how does education change? We don't really have a good answer to that. So Epic AI the meter time horizon.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

So basically they you've seen these charts to kind of predict where models are going, where the capabilities are going based on previous capabilities that they're tracking. So we're we're kind of seeing those abilities to continue to evolve. It's not changing. we it doesn't seem like we're hitting some limit. So here's kind of that capabilities index.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

So so notice and starting in April 2023 to right now basically this is January 2026 right? So this is just less than a month in the future there's a pretty clear trend and pattern and that pattern is holding and if you haven't seen this chart I just wanted to remind you so this is the Federal Reserve Bank of Dallas kind of looking at the GDP gross domestic product so per capita. So again, this is kind of has been the line since 1870 and you could probably kind of project it back even further. So communities, societies, nations, whatever produce some amount of goods and services, etc. And this is how life has been for as long as we know it.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

And somewhere right before 2035, so again as Sam Alman has said, you know, by 2035 having super intelligence is is an almost certainty, right? So let's say that's kind of like right around that point. And notice these two new lines never before seen. One is a red going, you know, kind of almost straight up. One is purple going to zero again and never before seen.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

The purple line is a singularity. So kind of the emergence of super intelligence, you can say, and we go to extinction, right? So that's the the end of the human race at which point, yeah, GDP goes to zero, right? Or the red line singularity, right? But it's a benign scenario.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

So super intelligence kind of takes off and GDP goes through the roof. Both the Google DeepMind podcast and the All-In podcast with Tucker Carlson. Both of those have very good segments about what's about to happen. Depending on your interest, political preferences, whatever, one of those might be more appealing to you than the other. If you have strong preferences, just watch one of them.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

If you think this is bigger than politics, more important than politics, then watch both of them. at least definitely those segments that I pointed out because we're like here and by this point we should have some idea of what we're going to do. Anyways, if you made it this far, thank you so much for watching. I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
