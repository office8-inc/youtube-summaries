# ğŸ“º Claude Codeã®é–‹ç™ºè€…ãŒæ˜ã‹ã™çœŸå®Ÿ - ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æœªæ¥

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: the creator of Claude Code just revealed the truth
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=fOKeVX8ZdDU](https://www.youtube.com/watch?v=fOKeVX8ZdDU)
- **å‹•ç”»ID**: fOKeVX8ZdDU
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ30æ—¥ 11:13
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

AIæ¥­ç•Œã®æ¿€å‹•ã‚’ä¼ãˆã‚‹æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ç‰¹é›†ã€‚NvidiaãŒGroqã‚’å®Ÿè³ªçš„ã«è²·åã—ã€TPUé–‹ç™ºè€…ã‚’ç²å¾—ã—ãŸæˆ¦ç•¥çš„ãªå‹•ãã€ãƒ¢ãƒ«ã‚¬ãƒ³ãƒ»ã‚¹ã‚¿ãƒ³ãƒ¬ãƒ¼ã«ã‚ˆã‚‹ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å¸‚å ´ãŒ2050å¹´ã¾ã§ã«25å…†ãƒ‰ãƒ«ã«æˆé•·ã™ã‚‹ã¨ã„ã†äºˆæ¸¬ã€ãã—ã¦Claude Codeã®é–‹ç™ºè€…ãŒéå»30æ—¥é–“ã®ã‚³ãƒ¼ãƒ‰è²¢çŒ®ãŒ100% AIã«ã‚ˆã‚‹ã‚‚ã®ã ã£ãŸã¨ã„ã†è¡æ’ƒçš„ãªå‘Šç™½ã‚’å–ã‚Šä¸Šã’ã¦ã„ã¾ã™ã€‚Andre Karphyã¯ã€Œãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰9ã®åœ°éœ‡ãŒã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¥²ã£ã¦ã„ã‚‹ã€ã¨è­¦å‘Šã—ã€AIã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é©å‘½ã®åˆ°æ¥ã‚’ç¤ºå”†ã€‚AIé–‹ç™ºè€…ã€æŠ•è³‡å®¶ã€ãã—ã¦ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®æœªæ¥ã«é–¢å¿ƒãŒã‚ã‚‹å…¨ã¦ã®æ–¹ã«å‘ã‘ãŸå¿…è¦‹ã®å†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **Nvidia-Groqè²·åã®è£å´**: NvidiaãŒGroqã®CEOï¼ˆTPUé–‹ç™ºè€…ï¼‰ã¨90%ã®å¾“æ¥­å“¡ã‚’ç²å¾—ã™ã‚‹ã€Œé€†ã‚¢ã‚¯ãƒã‚¤ã‚¢ã€ã‚’å®Ÿæ–½ã€‚200å„„ãƒ‰ãƒ«è¦æ¨¡ã®å–å¼•ã§ã€FTCã®å¯©æŸ»ã‚’å›é¿ã—ãªãŒã‚‰å®Ÿè³ªçš„ã«Groqã®æŠ€è¡“ã¨äººæã‚’ç²å¾—

- **ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å¸‚å ´ã®çˆ†ç™ºçš„æˆé•·**: ãƒ¢ãƒ«ã‚¬ãƒ³ãƒ»ã‚¹ã‚¿ãƒ³ãƒ¬ãƒ¼ã®äºˆæ¸¬ã§ã¯ã€ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å¸‚å ´ã¯ç¾åœ¨ã®910å„„ãƒ‰ãƒ«ã‹ã‚‰2050å¹´ã¾ã§ã«25å…†ãƒ‰ãƒ«ï¼ˆ250å€ï¼‰ã«æˆé•·ã€‚Amazonã¯æ—¢ã«300ä»¥ä¸Šã®æ–½è¨­ã§100ä¸‡å°ä»¥ä¸Šã®ãƒ­ãƒœãƒƒãƒˆã‚’é‹ç”¨ä¸­

- **Claude Codeã®è¡æ’ƒçš„äº‹å®Ÿ**: é–‹ç™ºè€…Boris ChurneyãŒã€éå»30æ—¥é–“ã®259ä»¶ã®PRã€497ã‚³ãƒŸãƒƒãƒˆã€4ä¸‡è¡Œã®ã‚³ãƒ¼ãƒ‰è¿½åŠ ãŒ100% Claude Codeï¼ˆAIï¼‰ã«ã‚ˆã‚‹ã‚‚ã®ã ã£ãŸã¨å‘Šç™½ã€‚AIãŒè‡ªåˆ†è‡ªèº«ã‚’æ”¹å–„ã™ã‚‹ã€Œè‡ªå·±æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã€ãŒå®Ÿç¾

- **ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åœ°æ®»å¤‰å‹•**: Andre KarphyãŒã€Œãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰9ã®åœ°éœ‡ãŒè·æ¥­ã‚’æºã‚‹ãŒã—ã¦ã„ã‚‹ã€ã¨è­¦å‘Šã€‚é©åˆ‡ã«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã„ã“ãªã›ã°10å€ã®ç”Ÿç”£æ€§å‘ä¸ŠãŒå¯èƒ½ã ãŒã€ãã‚Œã‚’å®Ÿç¾ã§ãã¦ã„ãªã„ã®ã¯ã€Œã‚¹ã‚­ãƒ«ä¸è¶³ã€ã¨è‡ªå·±åˆ†æ

- **ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®æ–°ãŸãªè„…å¨**: OpenAIãŒã€Œpreparednessè²¬ä»»è€…ã€ã‚’å‹Ÿé›†ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒƒã‚­ãƒ³ã‚°ã®å°‚é–€å®¶ãŒè¶…äººçš„ãªAIã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’æ‚ªç”¨ã™ã‚Œã°ã€ä¸–ç•Œæœ€é«˜ã®ãƒãƒƒã‚«ãƒ¼ã«ãªã‚Šã†ã‚‹ãƒªã‚¹ã‚¯ã«è­¦é˜

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Tons of stuff happening in the world of AI. Let's get into it. Andre Karpathy is feeling really, really behind. He's saying that a category 9 earthquake is coming. It's coming for software engineers.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Meanwhile, Nvidia acquired a secret weapon in their battle against Google and the TPUs. Dr. Jim Fan from Nvidia has some anxiety about how quickly robotics is progressing or at least that there's some issues with how it's progressing. Meanwhile, Morgan Stanley is like, "We're going to the moon, baby." And tons more. Let's cover it all cuz these are kind of big news.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

I've taken some time off to just kind of kick back for the holidays, but I am back. I'm still traveling around, so pardon the setup and the various audio and video quality. I don't know. I feel like it's it's pretty good, but I am sort of making do with what I have. I hope you love it.

### ğŸ“ è©³ç´°èª¬æ˜

Make sure you're subscribed and let's get going. All right, so first and foremost, Grock got acquired. So this is GRQ, not the large language model from XAI, Elon Musk's company. This is completely separate. This is the language processing unit.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So, its big claim to fame is the fact they can run inference on these LLMs very, very fast. Instead of focusing on training or just general use, it just spits out words really quickly. Jonathan Ross is the CEO founder of Grock, or at least he was up until very recently. He's also the creator of the TPU, Google's big machine learning chip. And today, he posts this that Grock entered into a non-exclusive license agreement with Nvidia.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

a lot of confusion about what this whole thing means. Basically, if large companies like Nvidia just gobble up all of the competitors, the FTC, kind of the governing bodies, they get a little bit upset and they want to get out their microscope and take a closer look at what is happening. But it seems like big tech companies found a way to kind of get around this whole thing. And they do this with these reverse aqua hires. Basically, instead of buying the company outright, they're basically trying to just get the best talent to join here.

### ğŸ¯ å¿œç”¨ä¾‹

Axio does a great job of kind of explaining what's happening. Basically, Nvidia is getting Gro CEO Jonathan Ross and President Sunonny Madra to join Nvidia. So, they're getting that top tier talent to join Nvidia and work for Nvidia. Obviously, a a big big win. Again, this is one of the people that invented the language processing unit and the tensor processing unit, the TPU, the thing that's Google beginning to kind of roll out that's making quite an impact in in the market.

### ğŸ’­ è€ƒå¯Ÿ

Now, meanwhile, Grock, the original Grock, is going to continue to operate as a standalone company as a new CEO, Simon Edwards, who has been the chief financial officer. Now, some people complain about this, saying that this is basically becoming kind of a zombie company. And of course, it remains to be seen what happens to Grock once the top tier talent gets moved over to Nvidia. Notice that about 90% of Grock employees are said to be joining Nvidia. Now, the valuation is at 20 billion.

### ğŸ“Œ ã¾ã¨ã‚

There's a lot of chatter online about well somebody might get sort of screwed out of their investment if this is getting paid for you know specifically the the talent the hires instead of the investors. That does not seem to be true. It seems that everyone's taking care of everybody's getting paid and probably quite a bit. So basically most Grock shareholders will receive a per share distribution tied to the $20 billion valuation according to sources. So people are going to get paid.

### âœ… çµè«–

Meanwhile, the best and brightest talent, but 90% of the talent in this case is going over to Nvidia. So, Nvidia basically got the company. They got the company, they got the tech, but they didn't officially acquire the company. So, that merger doesn't actually happen. And so, the FTC and other regulatory agencies can't come in and and analyze the deal and potentially block it.

### ğŸ“š è¿½åŠ æƒ…å ±

So, thanks to Dan Primac for posting this. He's saying that, you know, he's hearing a lot of chatter about Grock and in short, everybody's getting paid very, very well, even if they're not fully vested. Jordan Tibido, who we had on the channel for a podcast a number of times, I believe he's saying, "Thank you. I thought this was the case." Was hearing the whamance on this platform and it was becoming insufferable. He's saying, "I suspect the reason that companies don't advertise this is because they don't want to rub it in the FTC's face." the fact that they figured out some ways around the politics of large tech acquisitions.

### ğŸ”– è£œè¶³

So meaning if they acquire then there could be trouble but if they do this they largely I mean it's a fairly effective workaround to get what they want without the regulatory scrutiny. And so keep in mind that Google is showing some strength that they're potentially a big competitor to Nvidia with their TPUs. As Lynn's saying here, acquiring Grock is is strategic to have the TPU early member join the battle against TPU. So, one of the creators of the TPU is now working for Nvidia and helped them in the battle against, you know, the TPU and Google. So, the game of chips is heating up.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

All right. Next, we have two things about robots that's kind of interesting. One, and this is posted by Roan Paul. This is Morgan Stanley Research. She's summarizing the latest research out of Morgan Stanley about the massive insane growth of robotics.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

And also we have Dr. Jim Fan from Nvidia sharing his anxiety on the wild west of robotics. All right, let's start with the Morgan Stanley. Here's the big headline. Robotics could explode from 91 billion today to 25 trillion by 2050.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

Worldwide robot installations are growing. 13% compounded annual growth rate since 2015. Logistics automation is up 20 plus% per year and warehouses that are using robots report a 25 to 30% higher productivity. The scale is already massive. Amazon confirmed across 1 million robots in June 2025 across 300 plus facilities.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So, expect this thing to blow up. Again, according to the Morgan Stanley Research, up to 25 trillion by 2050. That's going to be enabled by AI, sensors, and automation. We're going to be seeing professional service robots, autonomous vehicles, humanoids. It's a 250x market surge.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So, it's wild to think about, but I mean, if you think of them as replacing physical labor, like the kind of the mathematics behind it gets kind of wonky. I mean, every nation, every company, their economic power is in big part kind of their population, the the skills of that population andor employees. If buying or leasing a robot in the future gives you a positive ROI to basically where it makes more money, let's say per month than you have to pay for it per month, the demand is going to be absolutely off the charts. We've seen what happened to Nvidia and GPUs when you have massive demand for something in a bottleneck for how quickly it can get produced. So, if you're betting on these robots being valuable, certainly kind of like that wave that is coming, uh, you should expect it to be massive.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

But before you bet it all on robots. So again, Dr. Jim Fan has some anxieties about the wild west of robotics. And here are three lessons that he learned in 2025. He's saying hardware is ahead of software, but hardware reliability severely limits software iteration speed.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

We're seeing exquisite engineering in Optimus, Eat atlas, Figure, Neo G1, etc., etc., etc., But our best AI isn't fully squeezing all the juice out of the frontier hardware that we have. The body is more capable than what the brain can command. And babysitting these robots demand an entire operations team. Unlike humans, robots don't heal from bruises, overheating, broken motors, bizarre firmware issues haunt us daily. Mistakes are irreversible and unforgiving.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

As he says here, my patience was the only thing that scaled. Benchmarking is still an epic disaster in robotics, right? So, everybody has their own kind of benchmark, right? So, if you have your own benchmark for everything, every single thing is just state-of-the-art. So, basically, everyone cherrypicks the nicest looking demo out of 100 tries.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

And he's saying we got to do better as a field in 2026 and stop treating reproducibility and scientific discipline as secondclass citizens. and three VLM based VLA feels wrong. This I thought was quite interesting. So we've seen a few of these VAS VLMs announced, right? So VA stands for vision and language action.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So similar how we have LM's large language model, we can also have VLM's vision language model and VA's vision language action model. All right, so you take a pre-trained VLM checkpoint and graft an action model on top. Google has been rolling out a few of these. They they look impressive so far as far as I can tell. But if you think about it, VLMs are hyper optimized to hill climb benchmarks like visual question answering.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

This implies two problems. One, most parameters in VLMs are for language and knowledge, not for physics. And two, visual encoders are actively tuned to discard low-level details because question answers only require highlevel understanding. But minute details matter a lot for dexterity. So, he's saying that there's no reason for VA's performance to scale as VLM parameters scale.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

Pre-training is misaligned. Video world models seem to be a much better pre-training objective for robot policy. And he's saying, I'm betting big on it. And we've seen similar things with Google as well. So, they they have a lot of video world models.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

Some of them look like video games. Some generate actual worlds to run around in. A lot of that's going to be used to train robots in these simulations instead of having, you know, some human manually collect the data by, you know, picking up glasses and whatnot. They just throw these robots into those model worlds and have them train in there. But as you can see, it sounds like he's saying, well, we're not quite there where we just solve all the problems.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

There's still quite a ways to go. Software needs to catch up to hardware. We need better benchmarks or at least more standardized benchmarks. And these VALAs might be a dead end or at least suboptimal, but Dr. Jim Fan has probably some of the best robotic labs and researchers working in this stuff.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So, if he's pointing out issues, I would feel like everybody else is struggling with these things as well. So, I'm certainly hoping for a rapid takeoff, but we'll see if it happens. And this was kind of a fun post. This is Boris Churnney. He's saying, "When I created Cloud Code as a side project back in September 2024, I had no idea it would grow to be what it is today.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

Kind of mind-blowing that it started as a side project. It's humbling to see how Cloud Code has become a core dev tool for so many engineers and certainly the reception has been amazing." He's saying here, "Increasingly, code is no longer the bottleneck." And here's kind of the thing to pay attention to to kind understand what's happening right now. saying a year ago, Claude struggled to generate bash commands without escaping issues. It worked for seconds or minutes at a time. We saw early signs that it may become broadly useful for coding one day.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Fast forward to today. In the last 30 days, he this this person that basically created dreamed up cloud code, he landed 259 PRs, 497 commits, 40,000 lines added, 30,000 lines removed. Every single line was written by cloud code plus opus 4.5. Cloud consistently runs for minutes, hours, and days at a time using stop hooks. Software engineering is changing and we are entering a new period in coding history and we're still just getting started.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

So here's the part that's kind of jumping out at me as someone is sort of confirming. You didn't write a line of code for cloud code in the last 30 days. And the creator of cloud code goes correct in the last 30 days. 100% of my contributions to claude code were written by claude code. So to put it a a different way, I would say that claude code is vibe coding itself.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

Is that fair? We were sort of the organic bootloadader that kind of started this whole thing up and now it just takes off and goes from here. Here's McKay Wriggley. So he does a lot of great vibe coding tutorials. as you see him build stuff live on his live streams.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

He's saying the more I code with Opus 4.5, the more I think we're 6 to 12 months away from solving software. The model is pretty much there. I'll build like three versions of an app in a few hours just to explore options that each would have taken me one to two weeks less than a year ago. It's getting weird. As AGI gets closer, I expect things to start feeling increasingly weird and the weirdness is definitely starting to accelerate.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

And finally, he's saying people underrate how massive the network effects of claude skills alone will be in driving performance over the next few months. Anthropic gave a great talk at AIE about how skills are kind of like a form of continual learning. And I agree. He's not alone. Andre Karpathy wrote a huge post here.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

got almost 15 million views, meaning I've never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between or sparse and in between. I feel like there's a word missing there, but the point is that we're contributing less. He's saying he has a sense that he could be 10x more powerful if he just properly string together what has become available over the last year or so. and his failure to claim that boost to to go up 10x feels decidedly like skill issue.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

He's not learning how to claim that boost and become 10x better. He spells out exactly what he means. I'll link this down below if you want to read it. I do encourage people to read it. You think clearly some powerful alien tool was handed around except it comes with no manual and everyone has to figure out how to hold it and operate it while the resulting magnitude 9 earthquake is rocking the profession.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Roll up your sleeves to not fall behind. I personally wouldn't be surprised if almost like a new skill set emerged. Not even necessarily from the software engineers that were great at their jobs before. I mean maybe but not necessarily. It could be potentially brand new people that figure out just to how to harness this ability, how to stay at the cutting edge already.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Some people are suggesting that you shouldn't be looking at the code just because the AI produces sloppy code. That's fine. Don't even look at it. Let it handle everything for you. And obviously that still might cause some issues today or a lot of issues today.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

But as this thing continues, is it possible that that will be the most uh effective approach? You know, just let it rock and roll on on full auto and and see where it takes you. Certainly simple projects that don't have a lot of complexity that don't don't have a lot of failure cases where it could catastrophically blow up in your face. You know, these things can build them fast and effectively. For example, Sam Alman at Open EI, they're hiring a head of preparedness.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

models are improving quickly and are capable of many great things. We've seen them, for example, find vulnerabilities in various cyber security setups. They're they're getting good at fighting those exploits so that they can be patched. But of course, as you can imagine, if they can sort of red team it for the good of all, bad guys can use it to bring something down. And as Sam Alman is saying here, if you want to help the world figure out how to enable cyber security defenders with cutting edge capabilities while ensuring attackers can't use them for harm and also saying and even gain confidence in the safety of running systems that can self-improve, please consider applying.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

This will be a stressful job and you'll jump into the deep end pretty much immediately. I love that sort of job description because saying that this is going to be super stressful. is going to throw you in the deep end and you're going to have to solve everything. That doesn't work for most jobs and that doesn't work for most people. Here, the person that you want running this is probably salivating when he's hearing that.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

He's like, I want to solve those huge stressful problems and he or she, they're just willing to go for it. So, interesting times ahead. I think I'll leave us with this ply the prompter quote. So back in October 2024, he said, "I wonder how long before y'all realize that as AI approaches, superhuman coding abilities, the best prompt hackers in the world become the best additional hackers in the world." Right? So if you're able to break these models and get them to do what you want them to do, right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

If you're a prompt hacker and you're good at it, you are now have become the greatest traditional hacker, right? you're able to get around various cyber security setups, etc. Right? If a AI model has superhuman skills, but doesn't want to do naughty things, but you're able to pro it in such a way to get it to do those things, then you basically have superhuman skills that can be used for evil. And yesterday, he uh just sort of quote tweeted and said, "Oh, cool." So, the answer is 14ish, you know, for around 14 months.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

Thanks. This is in response to Sam's post, of course. So wild wild times ahead. Let me know what you think. Are we going to have you know coding and software development solved soon?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

Are people capable of breaking these models kind of by prompt hacking them? Will they have highly highly dangerous abilities at their fingertips? Do you think in this sort of fairly rapid expansion of the robotics industry and the robotics revolution? Let me know what you think. I am uh back from my kind of time off that I took for various holidays.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

I am rejuiced and ready to dive back in. And it sounds like that's happening just in time cuz things are about to take off. If you made this far, thank you so much for watching. My name is Wes Roth and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
