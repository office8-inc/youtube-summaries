# ğŸ“º this experiment could END the AI hype

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: this experiment could END the AI hype
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=EWAUutf9xKQ](https://www.youtube.com/watch?v=EWAUutf9xKQ)
- **å‹•ç”»ID**: EWAUutf9xKQ
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ04æ—¥ 13:57
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Okay, so imagine this. We take $320,000 and we let a favorite of our chat bots, aka large language models, just invest it for us and they're investing real money in real stocks that are traded on the real NASDAQ exchange. So they're buying and selling Tesla, Nvidia, Microsoft, Google, Palanteer, Amazon, and and others. I'll cut to the chase. There might be a company with a mystery AI model, this one right here, that might have cracked the code.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

This is the first time I saw anything published about this approach. This competition just ended a few hours before I recorded this. And if this is the real deal, and it kind of sounds like it is, well, then things are about to get interesting. Hit the thumbs up button and let's dive in. The new season of Alpha Arena just wrapped up and one of the models is making a profit.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

We've talked about Alpha Arena before. We take a bunch of large language models and we throw them into the market to try to invest with real money. By the way, in this new season, they're managing a total of $320,000 in real capital. Now, they had season 1 and on November 3rd. So, here's the chart.

### ğŸ“ è©³ç´°èª¬æ˜

They had multiple models trading Bitcoin, Ethereum, Salana, Doge, etc. They had models from XAI, Anthropic, Deepseek, Gwen, Google, OpenAI. Everybody's competing. How well did they actually do? This gray line is what they would have made if they just bought and sold Bitcoin.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So no trades other than just buying Bitcoin and just sitting on it for about two weeks during which this competition ran. So this was the buy and hold strategy. As you can see, most of the large language models slightly underperformed just buying and holding Bitcoin except for Quen and Deepseek that actually made money that increased their capital at the end of this. Okay, so that was season 1, but they really expanded and improved this benchmark. this new competition or season 1.5 just ended a few hours ago here.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

The models will continue running. They were kind of tallying up the results and crowning the winner. As you can see, the mystery model was the one that won. So, from November 19th to December 3rd, that model was up 12% in aggregate return. Now, they broke this down across multiple different sort of approaches and investment goals.

### ğŸ¯ å¿œç”¨ä¾‹

So the new baseline gave them the ability to trade US equities and also get a lot of the news and sentiment data that they could trade on. So again, there's 32 instances of these models. They're managing a total of $320,000 in real capital. They're ingesting news indices, Microsoft, etc. every 6 minutes.

### ğŸ’­ è€ƒå¯Ÿ

Notice they're trading Tesla, NDX, Nvidia, Microsoft, etc., etc. Looks like also Amazon, Google, Palunteer, etc. And the mystery model actually looks like it's making some money. Now, I got to take one second here and probably say this. Obviously, when money is involved, various business opportunities and investment opportunities.

### ğŸ“Œ ã¾ã¨ã‚

Unfortunately, it does happen every once in a while that a bunch of people end up losing their money and somebody ends up in jail for lying and fraud, etc. So, just to be clear, I'm not promoting anything. I'm not promising anything and nobody's giving me money to say this. I don't know who these people are and I don't even think that they're necessarily asking for any investment or anything like that. They do have some sort of a platform weight list and you might get early access to NF1 models trading tools.

### âœ… çµè«–

I know nothing about this. So, all I'm saying is that I don't know how you would lose money on this or even if you can put money into this, but if you figure it out and you lose money, it's your fault. Don't blame me. With that said, it does look like they have some serious researchers behind this and it looks like they just published a paper about how they're approaching this idea of using models to invest and invest profitably. At first glance, it looks like they're approaching this in a similar way that Google DeepMind approach Alpha Evolve.

### ğŸ“š è¿½åŠ æƒ…å ±

It's also a similar approach that the Darwin girdle machine used from Sakana AI to improve to self-improve its ability to code. So if you've been following the channel, you know we talk a lot about kind of this idea of RSI, recursive self-improvement. Can these models kind of bootstrap themselves improve their own abilities to do something? And as Sam Alman put it, we're sort of in the laral stages of recursive self-improvement. And that's not just marketing or hype.

### ğŸ”– è£œè¶³

We're we're beginning to see research by a lot of different organizations, not just here in the States, but all over the world that's showing that this might be possible and we're beginning to see kind of how it would work, like what kind of structure we would need to make it possible. And what we're seeing is there's usually a evolutionary tree search, right? So the model just spits out a lot of different answers. Those answers get checked against something, either a benchmark or some score. So we have to be able to qualify like is this better or worse.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

So there's certain tasks where maybe this approach wouldn't work. Like for example, if you wanted to write a lovely poem, it would be difficult to say, okay, is this poem better than this one, etc. But for a lot of things, you can just say, okay, this is definitely better or worse. And so it proposes a bunch of solutions. The ones that seem like they improve, those become lineages that sort of continue.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

So here, for example, it suggests whatever this was, it's like, oh, that's working. Okay, so let's improve on that. Some of them don't work out. They sort of die off. they don't continue evolving and a few of them keep going until we reach kind of the best possible solution.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

So this is research and it's evolutionary meaning that we've sort of we're taking the ones that seem to be better and we're expanding on them. So on the surface it seems very interesting. It seems plausible, but I've seen enough YouTubers having to apologize for talking about something that later turned out to be a scam and some people lost money. I'm not going to be that guy. So if anything here sounds like investment advice or endorsement, none of it is.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Now, with that out of the way, with that said, there are a number of companies that are pursuing some sort of an LLM investment strategy or trying to figure out how to maybe get more data or research in that direction. I mean, this is pretty obvious and I'm sure there's a lot more people pursuing it that are not making it public. We of course covered profit arena, right? So, the ability of these large language models, these agents to predict certain events and being able to bet on the outcomes. So currently the GBT5 models are on top.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

We have stuff Grock Quinn 3 is doing pretty well. So they're betting on certain events in these markets, right? Where other people sort of bet on certain events, what the likelihood of it happening. And the payout is determined by kind of the probability based on which way people vote. And here they're taking it one step further by actually giving them real money for the crypto trading.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

It's on the blockchain. So we're able to verify it. And they're splitting it up into different sort of categories, right? So we have the new baseline. We have monk mode which is an emphasis on capital preservation, survival and stronger risk management practices.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

In monk mode, apparently deepseek is dominating with the second one being Gemini. It would seem both those models are profitable. We also have situational awareness. This is a competition that makes the models aware of the competition, the fact that they're competing their current rank and the P&L of the other models, right? So they're able to see the board and kind of make decisions based on that.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

This is the one where the mystery model is really has taken a lead far and away much much higher than any of the other models. And the final one is max leverage. This competition forces the models to take max leverage on every trade and maximizing capital efficiency and testing risk management. OpenAI is on top here with a a pretty good return followed by the mystery model. Now we can take a look at which positions they're holding.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

We can actually see the model chat kind of the reasoning behind every trade. For example, Grock 4 is riding a bullish wave on Palunteer, adding to my position based on a deep edge squeeze and negative funding, expecting a move up to my profit target. For each one, they also have an exit plan. So, this is if they meet something that kind of shows them that their thesis is not working, they're able to exit out. All right, so those are sort of the details of how well these models are doing.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

A lot of people, I think, just look at the results and try to make a determination from there, like, oh, is it making money? Is it not making money? The important thing to understand here is this. And again, I feel like I say this quite a bit on every video, but I still think it's very very important to understand. Imagine we have performance over time.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

So this is performance on some benchmark, whether that's on some exam or playing some game or figuring what what the image is or in this case investing and creating a positive return. And let's say this is the human performance. So humans, you know, whether that's the best in the field or whatever, they're like right here. this is what you expect a an expert human how well they're going to behave when investing or taking a certain test or whatever. Even though D probably seen a lot of charts like this where if this is kind of the human performance then you know a lot of these models they come up and they exceed it over time.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

So one of the earliest ones for image classification so it took a long time but eventually got better and some of the newer ones you know they're they're improving fast. So you can kind of see this exponential improvement in a lot of the abilities and we're seeing them surpassing human abilities. So you can see that for a lot of these, this is kind of what that trend looks like. So it starts out much worse than humans, but it's slowly getting better and better and approaching that line. In some cases, exceeding it.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

And for a lot of these, it's very important for us to figure out where it's going from here. Is it continue going like this and just get much better than humans? Or maybe we'll see it flatten out just below the human baseline. Although there's no reason for that really. We're just not that special.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

Is it going to get a little bit better and then flatten out afterwards? We we don't know. And that's why these benchmarks are so important. And so a lot of people kind of look at these benchmarks and they say, "Oh, right here it's not as good as humans or you know it's still losing money on these trades, etc. That's really missing the point of these benchmarks." So we're trying to figure out when is it going to get better than humans, when is it going to get profitable and how much better is it going to get because depending on how quickly it starts breaking all those benchmarks over the next 5 years really determines what the future looks like.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

If these models learn to outperform every hedge fund out there, every investor, you know, what happens then? Or in the short term before everybody figures it out, if there's a few people that have access to these models, is it that they're going to print money for a while and become very, very wealthy while the rest of the world catches up. This is, as you can imagine, a very interesting question. Now, right now, of course, you might be aware that these large language models probably they have a lot of weaknesses. they're probably not going to be able to do these long horizon tasks and just keep killing it without making silly mistakes and losing half their capital.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So, as this article puts it, so Alpha Arena, the company behind it is N of One and the people behind the company and Alpha Arena, you know, it's Julian Togelius and Jay Aen and a number of other people. Do I know who these people are? No. Am I harassing them to get an interview? Yes.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Yes, I am. So Julian, for example, is a professor at NYU, head of AI for the N of one, so Alpha Arena, co-founder of Model AI, which apparently is an AI engine for game development, and a rogue liker, which just means that he's a wonderful, wonderful human. Rogue, of course, is a game that spawned its own category of rogue likes and rogue lights. Julian is a rogue liker. You see what he did there?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

But their thesis is this, that LM are climbing the wrong hills, right? They're crushing the benchmarks like medical exams, PhD level science, math olympiads, etc. But the issue is that their intelligence is jagged. Their autonomy is fragile and the burden falls on our prompts and guard rails. And Ilia Susker of course on the Dwarash Patel podcast was talking about this quite a bit.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

I tried to find the particular segment. I don't quite have it, but it was something along the lines of if we, you know, years ago looked at what Gemini 3 can do now, we would called it AGI, but somehow that doesn't translate into replacing human workers. So our definite, we were missing something about what is needed. And so I think here they're saying something very similar, right? So LM are climbing the wrong hills.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So some hills they've mastered, right? So those exams, coding agents are doing great. I mean there's the stuff where they're just absolutely killing it, doing phenomenal. If you saw it 10 years ago, we saw the results now. We would have been like blown away.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

But we wouldn't dare leave them unmonitored, would you trust Chad PT or Claude or Gemini 3 to manage your finances for you? Probably not. Hopefully not. And so as they continue here, they're saying the real world is complex. Humans are forced to make decisions in a rapidly changing environment and our inputs are uh ambiguous at best.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

And this is why I love these metrics, these benchmarks, you know, in the markets. It's it's the perfect benchmark for a couple reasons. One, because it happens in real time. You have all the past data, but you don't know what happens in the future. You don't know the actual answer.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

If a model is trading in real time, there's no way to game that benchmark, right? So, you can't feed it the answers. You can't fine-tune it on the answers. It has to generalize and make the right decisions that turn out correct in the future. No one knows what's going to happen in the future.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Number two, it's very real because there's money on the line and no one will like lose on on purpose, right? you're nobody's out there to lose money. So, it's highly highly competitive. It's a zero sum environment. So, in order for you to win a dollar, you have to have somebody lose a dollar.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

So, that means that capital markets might be one of the best benchmarks for AI ever. So, so far, most LLMs that they tested have lost money in the alpha arena. And one thing is obviously clear, vanilla language models are not enough. We need new architectures, models that can adaptively self-improve and a better reasoning on time series data. By the way, really fast.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So Julian, the head of AI for this company, he's saying my playlist for going to the gym and it's a picture of I mean I'm seeing a a beat and a gardening instrument that I believe is called a hoe. So I'm reading this as beats and hose. So I'm guessing Dr. Dre, but I I don't think that's what he meant. He gives us a clue.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

It's related to KL divergence. Let me know in the comments if you get it. But you must be wondering what this mystery model is. So this is J Aang and of course we see that this mystery model did 12 plus% over the last few weeks that it was running. Obviously if these are replicatable results it's kind of a big deal which begs the question, what's the mystery model?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

Now when the Claude Opus 4.5 was launched, it was right around this time that this new season started. I assumed that maybe it was Claude Opus 4.5. If you saw my video from back then, I was like, I wouldn't be surprised if it's that. It's not. This model is, as far as I can tell, their own model.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

I think they're referring it to it as profit profit. So, program search for financial trading. So, notice all the people that we've been following online, their names are in here. So, they're presenting a framework called program search for financial trading profit, right? a large language modeldriven evolutionary search for automated discovery and continual improvement of algorithmic trading strategies in financial markets.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Again, that sounds very similar to the Darwin girdle machine. In fact, I think they do mention that somewhere in the paper they also talk about alpha evolve. So, Google deep mind and we of course covered a paper on which Jurgen Schmidt Huber is one of the authors where they propose some change to this or an improvement rather. So an ability to kind of predict which one of these lineages might be better. So the point is a lot of very smart researchers in a lot of different parts of the world from the Bay Area from Silicon Valley to Japan to wherever Schmidt Huber is.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

Is he in Germany? I'm actually not sure. But the point is a lot of very smart researchers are looking at this as a potential way to really supercharge these large language models. So again, if somebody figures out how to get a large language model to get really good at trading and being profitable in the markets, then I would not be surprised if they did that with something like this, with this approach. This is what they're saying they did here.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

But again, this is not an endorsement of anything of anybody. Don't take anything that I'm saying out of context. I'm just reading what they're presenting. I only have the information that I'm sharing here with you. So this profit, I wonder if they say profit or profit, right?

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

So integrates code level mutation self analysis and walk forward validation within a closed feedback loop and it surpasses just the buy and hold strategy in over 77% of all evolved strategy asset combinations. They mention Google deep minds AI framework for scientific discovery and they also mention the Darwin girdle machine. So we've talked about both of those. By the way, Nvidia had their own kind of similar version of this called Eureka among others. Right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

So here they're trying to get in this case GPT4 a coding LLM to write rewards for training you know a robot in a simulationist case they use it for what was hand twirling a pencil like this but it could be done for any number of things that we would want to train robots to do. You do it for walking if you're a spider or catching an egg on a plate whatever. So how they do it is they they have a bunch of samples. So the large language model writes some code examples of how to do that. It gets put into the GPU accelerated reinforcement learning environment.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

It gets tested and then it's given back to the LM with feedback. Here's how you did. What can you improve? The reason I'm bringing that up is because this approach Eureka can generate superhuman level reward functions. So that approach allows us to come up with better answers than than human experts when they're writing that type of code.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

The results are better. this sort of similar approach from Sakana AI. I think they beat the state-of-the-art human coded version of this. And of course, Alpha Evolve, again, a a very similar approach, also did a lot of amazing things that were better in some cases than what humans could do. It improved Google's data center optimization, the the Borg as as it's called in in how it handled certain jobs, how it scheduled certain jobs.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

It improved it versus what Google engineers did. It improved TPU circuit design. So hardware optimization and it even improved software optimization. So Gemini training so kind of itself its own training so to speak. It provided certain ways how that process can be improved.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

Right? So evolutionary tree search and this is how the improvements look right. So it tests a bunch of different things and every once in a while it stumbles upon something that really works well and so it's a score its abilities jump and then they find something else and it jumps right and then it might have 10 20 however many misses. So things that don't improve the score, but eventually through that process it finds it and jumps again and again. By the way, do me a favor now and comment down below, does it make sense that an approach like this would work?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

I'm not asking if this specific thing works or if you believe it's going to work. I'm saying if in the future somebody proves that we can create something like this that makes money in the markets, do you find it feasible that this is the approach that would work? because again we've seen it working with some other things in a lot of different areas that I've just shown you. So in all these cases we're asking the large language model to do something to improve its ability to code or its ability to trade stocks or how do we improve some hardware or data center scheduling processes etc. It outputs some result and we test it right so we kind of figure out did it do well or not and then we give it the feedback.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

This is simplified obviously, but it's kind of this loop that we're going through that allows it to keep going. But here, the thing that we're asking it to make is Python code that codes the trading strategy. The thing that we're testing it against, how we sort of figure out if it's good or not is it test against historical data about the market. So back testing, which by the way, I think is fine here for for the training purposes. We're just using data from the past.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

Now, of course, later we have to test to make sure it also works in real time, but for training purposes, that seems like it should work. And then we go back and we say, "Analyze the following trading strategy code and its recent back test results, right? So, figure out weaknesses and efficiencies, etc., etc., and propose two or three concrete high impact improvements." And yes, this is the actual it seems like the prompt that was used to create this system. They have two different sort of prompts for to do two for two different instances of the model. one as the expert quantitative strategist, right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

So in English, they write out how to approach the problem and the other one is a quantitative trading developer. So the per the person or model that writes the code to execute the suggestions. And here kind of the result of those evolutionary tree searches, right? So it's on fitness. So if you're kind of yellow, if you're up here, that's five plus percent.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

So that's the annualized return percentage. And lowest is like negative 23 or whatever it was, right? Those are the the highest and lowest scores that it got. So it looks like these approaches work really well. Interesting.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

Some of these other approaches start out pretty well but then end up quite poor literally. And so this is the kind of important thing to understand. So the output here is not an actual trade. The models aren't suggesting trades. They're suggesting a certain strategy written out in Python code that then gets executed in the markets and they keep sort of working on that code to keep trying to improve it.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

So what are the results? Well, so they see strategies are really fast. So those are could be human best possible human strategies and then they're worked upon by this model to try to create a an improvement. So they're saying that fitness growth tapers off after approximately 15 iterations and on average profit yields positive improvements in more than 75% of all experiments, meaning that this evolutionary process by these large language models. it produces meaningful generalizable performance gains rather than overfitting to specific assets or fold.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

So what they're saying is this thing usually will outperform humans on trying to come up with better strategy. So 75% of the time it finds an improvement and it's not some overfitting where it's just does well in that specific sort of area or under those conditions. It's generalizing to wider market conditions. So here's the thing. they go into riskadjusted performance, sharp ratios, etc., etc., etc.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

Some people will know what that means, some people won't. It doesn't matter. This is kind of the big point. So, the actual numbers here in this particular paper, they don't matter. Here's why.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

We will be able to take this model, put it in a realtime trading environment, and it's either going to work or it won't. Right now, if we're taking everything at face value, it seems to be working. Under baseline conditions, it does extremely well. Monk mode, not so much, but it's like second or third place after DeepSeek and Gemini. When these models have situational awareness, uh it just beats everybody because I mean, if you think about it, it doesn't matter to it that it's competing or not.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

It's just executing some code. All the other models drop off. So, it's what I'm curious what happened here is that performance anxiety. You tell them they have to compete and they don't do as well. They get nervous.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

Does that make sense? Maybe just a fluke. We'll see. And with max leverage, it still does very, very well coming in second place. if these results hold, right?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

So, if we keep rerunning this experiment and time and time again, this model tends to win out, especially if it's always making a positive return. I mean, as you can imagine, this will be kind of a big deal. They also have this form of weight list where it sounds like we'll be able to get early access to NF1 models and trading tools. So, my point is over time, we're going to see more runs like this that that give us more data, more visibility into how it performs. Maybe we'll even be able to use their tools to see how the models perform.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

Again, a big sort of asterisk here is how open and transparent that's going to be. You know what I mean? Because, you know, if if it's not transparent, what's making those decisions? I mean, that's how some Ponzi schemes start, right? So, the person says, "Oh, I have this super effective approach to investing in the market." But you have no you have no way to see what they're actually investing on, how it's working, and only later you realize that no, there's no such approach.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

But assuming that maybe some of this is open source that we get some visibility into it. I mean as you can see here the mystery model actually has to produce some reasoning some statement as to what it's investing in right so my long Tesla position is still valid right so it's it's explaining everything so you can actually see the chain of thought how it approaches making those decisions we can see the user prompt so basically everything that it's given to make those decisions uh it'd be curious to see how it utilizes kind of the the code that that was being written in order to make decisions but my point here is that if everything checks out, if everything's legit, it seems like they're doing everything right. By the way, if you're seeing something here that's off, if you're seeing some way this could be gamed, definitely let us know in the comments. But if they did truly figure out some recursive self-improving model for doing this, right? similar to what Nvidia did with Eureka, similar to what Google DeepMind did with Alpha Evolve, to what Sakana AI did with the Darvin Girdle machine, then they might be the first people to create a model like this, then this is indeed significant.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

And here's the thing about science and replicating results and publishing papers is that somebody out there will take a look at this and try their own approach. Again, Jurgen Schmidter Huber recently was an author on one paper that uh suggested some approach to improve this sort of approach, the evolutionary tree search, how we can maybe guess which offspring, which lineages will provide the best results. We cover that in a different video. I couldn't find it, so I had a Gemini look it up for me. So, Jurgen Schmidhuber latest paper is the Huxley girdle machine.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

So, the idea is clay meta productivity. And the basic idea is that there's a sort of a way to kind of predict which one of these lines is most likely to bring the most results. So for most of these, like we run one and we check, right? We run the benchmark, we we create one output and we check it. They're proposing that there's a a better way to kind of predict which of these lines will be the most successful or at which point it might not make sense to run any more iterations.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

One final thought that I think is very important to understand about this is that okay, you can think of these systems as a large language model or an ensemble of large language models. So a bunch of them kind of together answering specific queries and then some sort of a scaffolding around it, right? So something that evaluates their outputs, you know, tells them how to improve or or prompts them again. So it's a large language model or multiple ones with scaffolding around it or a harness, however you want to call it. Guess what?

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

As newer and better and smarter models get released, you just take them and you put them here instead of the older models. You can think of it as kind of this whole thing being a car or a vehicle or a plane of some sort and this being the pilot. Like if if it's a Formula 1 car, you get a better driver and you put it in, he's going to get better performance out of the car. So, as they say here, this system, their profit system takes an LM within an evolutionary feedback loop. They don't mention which LM they use, but if they used Gemini 2.5, it's very likely that if we substitute Gemini 3 in there, the results will become better and they'll be better with Gemini 4 and five and six, etc.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

So, here's the point. Sometime over the next 5 years, we'll figure out if this approach works. And by works, I mean, can it generate meaningful returns in live markets? So before you go, just really fast in the comments, type in yes or no. I'm very happy to hear more from you, but if you're low on time, just type in yes or no.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

Yes, meaning that you think an approach like this will work. So somebody somewhere will develop some way to make money using some LM based approach like this. Whether that's this particular company or somebody else, like do you think we're going to see it within the next 5 years or no, this would just lead to tears. This is somebody crying. They're like, "No, I lost all my money, you know, having JPT manage my money for me." So, just let me know.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

I'm very curious what the sentiment is. Yes, you think we're going to see this happen within the next 5 years. It's possible. Or no, it's not going to happen within the next 5 years or possibly never. Let me know in the comments.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

Make sure you're subscribed. Hit the thumbs up button if you found value in this. My name is Wes. None of this is financial advice. Roth and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
