# ğŸ“º Shipmas Day 1: Autonomous AI Social Media Video Converter App

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Shipmas Day 1: Autonomous AI Social Media Video Converter App
- **ãƒãƒ£ãƒ³ãƒãƒ«**: All About AI
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=oRgnXdQyMHc](https://www.youtube.com/watch?v=oRgnXdQyMHc)
- **å‹•ç”»ID**: oRgnXdQyMHc
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ06æ—¥ 01:01
- **å†ç”Ÿå›æ•°**: 1,157 å›
- **é«˜è©•ä¾¡æ•°**: 33

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

So today uh I wanted to bring you along doing like a full application from start to beginning and I just want to explain my ID here. So basically what we want to do today is we want to create a flow from source input. Then we're going to use the yolo you only look once uh uh machine learning uh library to actually detect the faces and find the coordinates. Okay. And when we have the coordinates, of course, we're going to store them.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

And we're going to use AI to write commands in FFmpeg to keep track of the coordinates from the landscape video. And we're going to select some clips and stuff with a workflow we have. And then we're going to get a final vertical video. Right? So basically this application is going to be a landscape to vertical video converter with some uh I would say reasoning and context awareness and doing like a great selection of clips uh based on a user input.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

So I just wanted to do like a full video where we use cloud code to do this uh from beginning to end because there's been a while since we did that and yeah let me just walk you through this and see what we get at the end here. So for this uh like I said we're going to use cloud code and like I said before I am on the max subscription at the moment but um doesn't really matter too much in this case I think. So what I want to start off with what I always start off with for this project I don't even think we need context. So I don't really need to gather any documentation. So I just want to jump straight into plan mode and I'm going to read out my ID here.

### ğŸ“ è©³ç´°èª¬æ˜

So for this I like to use speech to text just save me a bunch of time. So let me just do that. Today's project is going to be a landscape to vertical video converter. And for that uh let's say I have uploaded a source video uh in 169 format. And what we want to do first is use the yolo library.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

you only look once to find the coordinates of the faces in the video. So we can keep track of where um people are in the video. Maybe if possible we can also track who is speaking or like moving their mouth if that is possible. And what we want to do with those coordinates further along is to actually use ffmpeg to actually turn this into a 916 vertical video. So the idea is when we have the coordinates for the the faces, we can all those always keep those in [music] uh a nice centered crop in the converted to vertical video format.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

Right? And that is just I think what we're going to start with. We're just going to start by trying to convert a uh 69 clip into a vertical video. And for that of course you need to write the ffmpeg scripts in between. But for now um we're just going to try to do the conversion and we're going to build on that further.

### ğŸ¯ å¿œç”¨ä¾‹

Okay. So that is kind of my input because I want to do kind of this in two operations. First I just want to see if the technology works because I haven't tried it. And if that works we're going to do some more work to get the better clips. So let's just start with this in plan mode in Opus 4.5.

### ğŸ’­ è€ƒå¯Ÿ

So now what's going to happen is that yeah, Opus is going to create a plan for this and we're just going to try to execute this and see what happens. So yeah, you can see we're using some exploring agents here. I'm just going to accept this and I will take you back when we have our plan here. So that was done. So now we have our plan here.

### ğŸ“Œ ã¾ã¨ã‚

So you can see the core features is the YOLO face detection. Uh we got to try speaking detection. So for that we're going to use something called media pipe, smart target, smooth cropping uh and ffmpeg conversion. Okay. And yeah, we have some files to create here and ready to proceed.

### âœ… çµè«–

Yes, that's fine. Uh I'm just going to do a quick upload because I did grab um a source video. Uh it's just uh Lionus tech tips talking with the Lionus tools and that is going to be our source clip. So I'm just going to say something here. The source video uh will be in uh slash source indeed.

### ğŸ“š è¿½åŠ æƒ…å ±

Okay. [snorts] So we can just upd up update our plan and then I just think we're going to execute and try to iterate. Okay. So that was it. So now I'm just going to do yes.

### ğŸ”– è£œè¶³

And now you can see we switched off from plan mode. And now we're going to actually start the project to implement this. This means probably that we have to grab the yolo uh model, maybe the media pipe model and stuff like that. So I think I'm not going to include this. Uh I'm just going to yeah let's just speed this up uh this part and I'll stop if there's an interesting point here.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Okay. So you can see all modules are implemented. Let's verify the structure before we can yeah try it out I guess. So like I said this is not like a huge code base. Uh but it's going to be interesting to see how well it works.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

So would you like me to test this with a video? Yes. Please test. So you can see we have some flags here. Um but for now I think we're just going to run it so Claude code can upgrade this.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

I just we're just going to take it from here. We're going to iterate basically. I think I'm just going to take you back uh when we get the first results back here now. Okay. So we seems like we had some issues here.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Maybe we need to do some iteration. So there's an off uh by one error in the smoothing function. Okay. So I guess we need to uh fix that. And what is pretty cool here is that now that we have kind of clawed opus 4.5 uh that reads all the outputs uh from our code now it can just kind of iterate on the fly and this just saves you so much time, right?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So yeah, we're going to try to run the converter again. I'll take you back. Was completed successfully. Let's verify the output. Pretty interesting.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

Yeah, we can probe that. So now we're just probing with ffmpeg into this. The conversion worked. Here's the summary. Input liners m4 linus vertical.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

1,900 frames. Speaking face detected. Face fallbacks. And now let's see how it looks. Okay, that's a good start, right?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So let me see if I have the sound on. Okay, let's play it. how much people have [music] profited from Linux. Do you have any idea? >> No, but I I have said that I feel very good about the fact that I now have two different projects that I started that both created billion-dollar companies.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

>> I think billion is an understatement. Yes, but I mean clearly they people built billiondollar companies on top of both. Okay, so you can see there was a lot of flickering back and forward. Let's try to eliminate that. Okay, but other than that, I think it did a pretty good job here.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So, I'm I'm uh I'm happy, but let's try to get rid of the flickering. I would say that was a great start. Uh we have a few issues. Uh one of them is the flickering. So, uh, what we do now is we flicker back and forward between the faces.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

Sometimes we kind of end up in the middle. Uh, we just need the model to make a decision. So, if it thinks uh a face is talking, let's just keep the the crop on that face. And if it uh the probability is high that the other face is speaking just shift to that and stay there because uh if not we're just going to get this flickering back and forward. So please make this adjustments uh that just pick the frame or the camera that is the highest confidence.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

Okay. So we we did make a lot of adjustments in the code based on my prompt. So, what we're going to do now is just going to run the the conversion again and let's see if we see any difference this time if we can kind of get rid of the flickering and be more confident who is actually doing the speaking. Okay, so that was converted again. Uh now let's check out uh if we can see any difference.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So basically let's go back here and let's hopefully now we will get less of this flickering. how much people have profited from Linux. Do you have any idea? >> No. But I I have said that I feel very good about the fact that I now have two different projects that I started that both created billion-dollar companies.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

>> I think billion is an understatement. I mean, >> yes, but I mean clearly they people built billiondollar companies on top of both. >> Yeah, I like this. It's not perfect by any means, but it's much better. And remember, we did our conversion from landscape to vertical.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Pretty smooth if you ask me, without any like big issues. So yeah, I think we can build more on this. So now we're going to move on to the next phase where we have a longer input uh video. So now that we have like a 10 minute long video, uh we can't just turn everything into vertical, right? And here is kind of where my next com uh steps comes into play because I now want to add in a step where actually we use um we need to transcribe the audio and we want to get Opus to select some interesting clips.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

we can then turn into vertical. Okay, so that is the idea. Let's say we aim for like 30 second clips or something like that. So that is what I'm going to try to explain now in the next phase. So I'm going to go back to plan mode and we're going to create a plan how Opus could actually help us turn this long form uh vertical into a short form or a shorter form with some interesting points.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Right? Okay. So now we have that successful conversion worked down. Uh we want to start something else because now we have a 10 minute long clip and that is of course too long to convert to vertical uh or like the audio the um the audio for the video. So you need to actually transcribe the full 10 minutes.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Then you're going to select up to 30 seconds of a clip you want to stitch together. But again we need to convert those parts into you have to also convert from MP4 to MP3 then that is understandable and after that you can use the previous things we created to actually grab the clips we need for that final interesting video 30 second video. So that was a pretty long explanation but now hopefully we're going to try to create a plan for that and yeah uh let's just see how that goes. That's going to be the final step. So the thing now is that we're not going to use any external APIs to actually uh pick out the clips.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

This is going to be opus in uh this uh aentic cloud code mode, right? That is going to pick out the clips. So you can see cloud opus is asking us some questions now uh that is based on our plan. And now we will finally get the plan and we can continue with this. So yeah, I'm going to take you back when we have our plan and let's do the final part of this uh hopefully working app here.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So I just answered a few questions and now we are kind of just uh finishing up the plan. So I'm going to take you back when we have the plan execute it and okay so the plan is already done. That's pretty cool. So yeah I'm just going to try to run this and see what happens and so I'm going to take you back when the agent now has executed on the plan we created. Okay.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

So we have started now. So you can see now we are actually transcribing the 10 minute version here. So uh when we have the transcription then Opus is able to select the clips we want. Then we're going to convert those into vertical hopefully and stitch everything together. So yeah like I said let's just run this uh fully and hopefully maybe it will work on the first try or if not let's just do some iteration.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Okay so we have our first iteration here. So you can see we selected some clips here. Okay, that looks pretty cool. And now we have turned this into a vertical video. It's 40 seconds.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

Uh let's just watch some of it and see how it looks. >> I actually don't remember what I wrote as >> computer which you built yourself and we actually replicated that build. What did you think of our video? >> I probably won't because I will be feeling way too self-conscious to to actually watch it. But I'm I mean there's there's literally maybe 20 tobotses in the whole world because yeah my grandfather made >> fun.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

You are actually doing amazing. It's nothing. >> Okay. I like it. I think it's pretty cool.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Uh but there's a few iterations we could do here, but basically let's just go for one more and see how that actually turned out because we need one more sample I think. Okay. So we got our second iteration now. So let's blow it up here. So, this is going to be the funny clips one.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So, yeah, it's 40 seconds, but listen, let's just do a small part of it >> is going to happen. And I am the beta Linus today, so I fully accept that that's going to be what happens. Um, what else is this is a 24 core 48thread CPU that I imagine is going to absolutely rip it up for writing emails. It's not the only thing I do, but I do spend a lot of time actually reading emails more than writing them because >> you can fit so much email in this bad boy. But >> I would not have gone through co if I had to like Zoom call every day like some people I know because I would have I mean there's no way.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

>> Maybe don't include that part. But do these make me look smarter? >> I can't tell them apart. >> Do I look like the smart Linus now? >> No.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

>> Okay, that was pretty good. I'm super happy with this. I think this turned out pretty good and with the project, I think everything uh worked out as I wanted. Of course, I had to do more iterations, but uh yeah, I'm super happy. And if I wanted to turn this into something, I could just put on like a simple streamllet UI uh make like a drop and bring in the API and stuff.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

But I just want to run this in cloud code. I think this is superb for my other project where I can turn a long form video that could be my video into yeah clips like this. So yeah, super happy with the app. This was the first day of shipmass as you saw in the title. I'm going to try to upload uh a video every day I have the chance where I do like a small uh app build with cloud code opus 4.5 as I did here.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So yeah, hope this gave you some inspiration. Hope you enjoyed it and yeah, give this a like and I'll see you again

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ24æ—¥

</div>
