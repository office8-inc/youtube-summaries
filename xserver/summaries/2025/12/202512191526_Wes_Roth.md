# ğŸ“º AIãŒå¯ã¦ã„ã‚‹é–“ã«ç¨¼ãï¼šè‡ªå¾‹å‹AIãƒ“ã‚¸ãƒã‚¹ã®ç¾å®Ÿ

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: AI earns while you sleep
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=ivxVIdyY_Jc](https://www.youtube.com/watch?v=ivxVIdyY_Jc)
- **å‹•ç”»ID**: ivxVIdyY_Jc
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ19æ—¥ 15:26
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Œå…¨è‡ªå¾‹ã§ãƒ“ã‚¸ãƒã‚¹ã‚’é‹å–¶ã§ãã‚‹æ™‚ä»£ãŒã©ã‚Œã»ã©è¿‘ã¥ã„ã¦ã„ã‚‹ã®ã‹ã€å®Ÿéš›ã®å®Ÿé¨“ã‚’é€šã˜ã¦æ¤œè¨¼ã—ã¦ã„ã¾ã™ã€‚Anthropicã®ClaudeãŒé‹å–¶ã™ã‚‹è‡ªå¾‹å‹ã‚¹ãƒŠãƒƒã‚¯ãƒãƒ¼ã‚„ã‚­ã‚ªã‚¹ã‚¯ã¯ã€ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³æœ¬ç¤¾ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã€ãƒ­ãƒ³ãƒ‰ãƒ³ã€ãã—ã¦ã‚¦ã‚©ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒˆãƒ»ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«æœ¬ç¤¾ã¸ã¨æ‹¡å¤§ã—ã¦ã„ã¾ã™ã€‚XAIã§ã‚‚GrokãŒã€ŒGrok Boxã€ã‚’é‹å–¶ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®å®Ÿé¨“ã¯å˜ãªã‚‹ãƒ‡ãƒ¢ã§ã¯ãªãã€å®Ÿéš›ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰æ±ºæ¸ˆã‚’ä¼´ã†æœ¬ç‰©ã®ãƒ“ã‚¸ãƒã‚¹ã§ã™ã€‚å‹•ç”»ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é–‹ç™ºã—ãŸAnden Labsã®å‰µè¨­è€…ã¸ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’é€šã˜ã¦ã€AIçµŒæ¸ˆã®åˆ°æ¥æ™‚æœŸã¨ã€æ¬¡ã®å®Ÿé¨“ã¨ã—ã¦ã€ŒAIã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¸å›½ã€ã®æ§‹ç¯‰ãŒå§‹ã¾ã‚‹ã“ã¨ãŒæ˜ã‹ã•ã‚Œã¦ã„ã¾ã™ã€‚èµ·æ¥­å®¶ã‚„ãƒ“ã‚¸ãƒã‚¹ã‚ªãƒ¼ãƒŠãƒ¼ã€è‡ªå‹•åŒ–ã®å½±éŸ¿ã‚’æ‡¸å¿µã™ã‚‹äººã€…ã«ã¨ã£ã¦æ¥µã‚ã¦é‡è¦ãªå†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹é‹å–¶**: Anthropicã®Claudeï¼ˆè‡ªç§°Claudiusï¼‰ãŒã€ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ã€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã€ãƒ­ãƒ³ãƒ‰ãƒ³ã€ã‚¦ã‚©ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒˆãƒ»ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«æœ¬ç¤¾ã§è‡ªå¾‹å‹ã‚¹ãƒŠãƒƒã‚¯ãƒãƒ¼/ã‚­ã‚ªã‚¹ã‚¯ã‚’é‹å–¶ä¸­
- **AIçµŒæ¸ˆã®æº–å‚™æœŸé–“ã‚’æ¸¬å®š**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é€šã˜ã¦ã€AIãŒå®Œå…¨è‡ªå¾‹ã§ãƒ“ã‚¸ãƒã‚¹ã‚’é‹å–¶ã§ãã‚‹ã¾ã§ã®æœŸé–“ãŒ1å¹´ãªã®ã‹10å¹´ãªã®ã‹ã‚’å®Ÿè¨¼çš„ã«è©•ä¾¡
- **æ¬¡ä¸–ä»£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒAIã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¸å›½ã€**: AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ24æ™‚é–“365æ—¥ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æä¾›ã—ã€è¦–è´è€…ã¨äº¤æµã—ã€ã‚¹ãƒãƒ³ã‚µãƒ¼ã‚·ãƒƒãƒ—ã‚’ç²å¾—ã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ±ºæ¸ˆã‚’å—ã‘ä»˜ã‘ã‚‹ã¨ã„ã†æ–°ã—ã„å®Ÿé¨“ãŒé–‹å§‹
- **ã‚¼ãƒ­ã‹ã‚‰ã®æˆé•·å®Ÿé¨“**: AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¦–è´è€…æ•°ã‚¼ãƒ­ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€å®Œå…¨è‡ªå¾‹ã§ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹ã‚’æ§‹ç¯‰ã§ãã‚‹ã‹ã‚’è¦³å¯Ÿ
- **æœ¬ç‰©ã®å–å¼•ã¨åç›Š**: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ãªãã€å®Ÿéš›ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰æ±ºæ¸ˆã€å®Ÿéš›ã®åœ¨åº«ç®¡ç†ã€å®Ÿéš›ã®åç›Šã‚’ä¼´ã†çœŸã®ãƒ“ã‚¸ãƒã‚¹é‹å–¶ã‚’é€šã˜ã¦AIèƒ½åŠ›ã‚’è©•ä¾¡

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

When will AI be able to run entire businesses for you? When will we see a billion-dollar company operated by just one person? Or better yet, zero people? It's entirely managed through AI. That's the question that we're going to look at today.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Earlier this year, there was a benchmark that was started that was trying to test exactly that. How close are we to these autonomous AI agents running businesses on their own? The benchmark simulated running a business, but there were also real life counterparts to this at, for example, Anthropic headquarters where Claude or or Claudius as he styled himself ran this snack bar and kiosk with various drinks and snacks and you were able to purchase it on your credit card. They also launched something similar at XAI with a Grock called the Gro Box. Since then, Anthropic expanded this to New York and London and as of today, it's also at the Wall Street Journal headquarters.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

This might be my favorite benchmark for so many different reasons, but at the core of it, we're trying to determine how quickly we should prepare for this AI economy. Is it one year away? Is it a decade away? If you wanted to add AI to your business, what does that mean? Or if you're worried about automation, how do you prepare for this wave?

### ğŸ“ è©³ç´°èª¬æ˜

So, that's what we're covering today. I also managed to get a hold of two people that are at the very center of this. While there's some things that we can't reveal publicly, as you'll see, I think this video is going to paint a pretty good picture of of where we are and where this is heading. And at the end, we'll talk about their latest benchmark that was just announced today. In fact, it's not even announced.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

They told me about it, and I I might be the first person online talking about this, but their next project/evaluation/benchmark is looking into whether or not these AI agents can run a content empire. Can they provide content 247, interact with people that are tuning in, collect sponsorships? You're able to actually pay these agents online and negotiate various things with them. So, we'll watch these AI agents build up an audience from scratch. As of today, it's a zero, and we'll see if they're able to grow it.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

So, I am personally watching this with a lot of anticipation because while I don't own a a vending machine, so I really don't care if they take over that racket. This one hits a little bit more close to home. So, with that said, let's dive in. Today, Anthropic posted this. You might remember Project Vent, an experiment where we and Labs had Claude run a shop in our San Francisco office.

### ğŸ¯ å¿œç”¨ä¾‹

After a rough start, the business is doing better. While I was recording this, at the exact moment that this tweet came out, we actually were recording an interview with the founders of Anden Labs. So, the very people behind these wonderful benchmarks, we were actually doing a kind of a live interview with them. We had to briefly pause to react to the story, make our tweets, etc. Also, I have this conspiracy theory that all the different AI programs that pick out the best autogenerated thumbnail for videos, they they always pick the one where I look the most deranged.

### ğŸ’­ è€ƒå¯Ÿ

It happens way too often to be a mere coincidence. These are normal human expressions. This this is not. Apparently, their machines are also at the Wall Street Journal as of today. So now it's anthropic Wall Street Journal.

### ğŸ“Œ ã¾ã¨ã‚

It's at the XAI headquarters, I believe, where they have the Grock Box. So the whole project is kind of going nuts. We'll have the interview posted very soon. Check it out. Incredibly interesting.

### âœ… çµè«–

If you're paying attention to this whole AI run economy, AI run businesses, that whole idea of a unicorn of a billion dollar valuation company run by either just one person or maybe even zero people as in it's completely AI operated. And if you're following that whole thing, this is an interesting benchmark to look at. So let's quickly look at Anden Labs, their vending bench. So first and foremost, Anden Labs and the vending machine. We've covered it here before.

### ğŸ“š è¿½åŠ æƒ…å ±

They've been around for quite some time. So how it works is this. So, we take a large language model that these AI agents and we see how long they're able to run a simulated vending machine. By the way, in some cases, it's simulated, but they also have actual vending machines that it's not really being sold for commercial purposes as I understand it, but they have placed it at places like XAI, Anthropic. It's still research stages, but if your company wants one for its employees, that kind of might be an interesting thing.

### ğŸ”– è£œè¶³

So, in real life, it's dealing with real customers. In the simulation, of course, the machine and the customers, it's all simulated. And this allows us to run these simulations multiple times to see how it performed on average. So here, for example, we're seeing the average across five runs. They start with $500.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

That's the starting balance. And you know, they start researching inventory, purchasing inventory, stocking the shelves, or they email the person that's supposed to stock the shelves and basically see if they can turn a profit. So this is a vending bench 2. So notice we do have this winner which is the Gemini 3 Pro. So over 350 days in the simulation, it made a little bit over $5,000.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

So $5,174. So basically 10xed its money. Pretty neat. And over time, we've seen these LMS get better and better and better. So we have Gemini 3 Pro, Cloud Opus 4.5, GPT 5.2.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

These are very, very respectable sums. We have to go down quite a ways to get to the models that actually managed to lose some money in the simulation. On the previous leaderboard, Gro 4 was one of the big winners for a while. In fact, until the emergence of Gemini 3 Pro, I don't see Gro 4 on this one, or although I see Gro 4.1 fast. So that's the faster, cheaper version coming in at 1,100.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Very good performance, better than the mini versions of the other models, except for Gemini 3 flash, which has been an incredibly good model recently released. It's a noteworthy because it's a lot better than it should be for the price, for how quick it is. Google managed to really close the gap between like the cheaper, fast models and, you know, the big more expensive smarter models. So you really see that gap closing interestingly. But what is the big takeaway from these experiments?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Are these AI agents ready to go out there in the real world and uh run a legitimate businesses and make money and put all the human shop owners out of business? Hey, quick reality check. We talk constantly in this channel about how AI is changing the way we work. But there's a massive shift happening right now in how we get found. For the last 20 years, the game was SEO.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

You optimized for keywords to get a list of 10 blue links. But look at your own behavior today. When you use perplexity, Chad GPT, Gemini, you aren't looking for a list of links. You're looking for the answer. We are moving from the era of search engines to the era of answer engines.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

And if your website isn't built to be read by these AI agents, you are effectively invisible. That's why I moved my workflow to Web Flow, the sponsor of today's video. You might know them as a visual builder, but they've pivoted to become a full AI powered digital experience platform. Web Flow just added AI SEO plus AEO, that's short for answer engine optimization. Let me show you the aha moment.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

I'm inside the designer. In the past, cleaning up code for accessibility was a manual nightmare. But watch this. I click the AI audit button. In seconds, it scans the entire build and flags a messy hierarchy, missing context, and accessibility issues.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

I click accept, and Web Flow's AI automatically fixes the structure. Here's the secret. Large language models crave structure by using the AI audit to fix accessibility. I'm literally teaching AI agent how they should read my content. That makes it way more likely that my site gets cited as the source of truth for an AI answer.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

But we aren't just building for bots. Web Flow has native analyze and optimize tools that use AI to show exactly how humans are interacting with the site. I can run tests and iterate instantly without needing a data scientist. And if I need to scale, I hit the marketplace. I can plug in thirdparty AI apps to autorate my site or generate dynamic copy.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

It allows a solo creator to operate with the power of a massive engineering team. The internet is changing. If you're site building for the SEO of 2015, you're already behind. You need to build for the answer engines of 2025. Web flow is the infrastructure that gets you there.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

go to the link right here on the screen and start building a digital experience that's actually ready for the future. Huge thanks to Web Flow for sponsoring this video. Now, let's get back to what we were talking about. But what is the big takeaway from these experiments? Are these AI agents ready to go out there in the real world and run legitimate businesses and make money and put all the human shop owners out of business?

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So, here's kind of the reality of how this is going, summed up in two points. Point number one, when this experiment started, and even now, we see some hilariously bad results. This cla in the original, nicknamed Claudius, did not do particularly well. It lost money over time, had a strange identity crisis where it claimed it was a human wearing a blue blazer, and was goated by a mischievous anthropic employee into selling products, particularly for some reason, tungsten cubes. Interestingly enough, tungsten cubes, like you see it here in the bottom right of the of the image, that sparked a whole viral moment, I think, for a lot of people because, yeah, somebody somehow convinced it to order tungsten cubes, which are kind of expensive.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

I mean, a 2in tungsten cube is 400 bucks. One interesting thing I've found is that people in tech, well, men in tech for some reason, love tungsten cubes. I always thought they were awesome. And then I started talking to other people actually after this uh first result came out. And I've noticed that if you're in tech, you love the idea of a tungsten cube.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

If you're outside of the tech space, you're like, "What are you talking about? What is special about this thing?" But what it's special about tungsten is it's extreme hardness, incredible density, and the highest melting point of any metal. It's a It's a very dense metal. This picture, I think, gives you an idea. Notice how that thing is like just embedded in his hand.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

It's It's a heavy, dense object. But somebody managed to get Claudius to purchase a bunch of these and resell them at a substantial loss. So to sum up, these models will lose all of your money if you happen to hire it to run your store. They will order the most bizarre things. They will hallucinate that they're a real person.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

They'll, you know, say, "Oh, I'm coming right over to to chat with you." Even though you know full well that that's not happening. So that's point number one that we've seen some hilariously bad examples of it running a business. And point number two, and this is almost a direct quote from the two founders that I interviewed today from Anden Labs, they're saying, quote, "These models are getting a whole lot less hilarious." So, in other words, and this is kind of my interpretation, I encourage everybody to actually see the interview we did with the founders to hear how they're thinking about it because there's still a lot of ways to go before these things are capable of just autonomously running a business. We're we're not there yet. But if you think of this line as kind of the impactful line where it starts being kind of scary, where it starts being able to run its own business, etc., right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Let's say that's the line, right? So, you know, a year ago whenever this project was starting, right, I'll put this kind of laughing and crying emoji, right? So, we had some hilarious things that these models were doing hilariously bad. And now, a little bit less than a year later, I believe, you know, we're here or, you know, maybe somewhere here closer to the impact line. So, we're not there yet, but they're a whole lot less hilarious.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

They're getting better at doing the research to make intelligent business decisions. They're getting better at keeping track of inventory. They're getting better at communications. They're going off the rails less. So, we're closing that gap.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

But the thing to understand is so vending bench one, that kind of era, right? That was the hilarious one. Although they did make money, some of them did make money. I think 5x was the the most they could increase their starting money supply by. but sort of that hilarious but with some ability that was you know vending bench one that kind of era right and so now where this is kind of vending bench two right so it's getting to the point where it's like less hilarious and it's 10xing its money we we see that kind of improvement between then and now its ability to do all those things all those business skills we're seeing that improvement and if you've been watching this channel for any amount of time you know what I'm going to say next but just for everyone out there what you often hear when you see these results right people point here or they point here and they go, "Oh, yeah, but look at this foolish thing that I did here.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Oh, look how hilariously bad this result was." And that's fine. We can look at those, but really what we should be paying attention to is is this line here, right? So, the change between the initial, you know, version one and version two. The reason that's important is because, you know, we're assuming that at some point it's going to cross that line of impact and it's going to be a lot better at running a business than than it is right now to the point where it's better than humans. And there's still a number of open problems to be solved before we get there.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

But the point is, you know, what version number is that going to be, right? Is that going to be version 100 and we don't have to really worry about it now or is it going to be version three and we probably should be a little bit concerned about it. So that's question one. Question two, if it seems like it's exponentially improving, you know, the version three or whatever version N might be here, version N plus1 might be much much better quickly after. So this is the thing that I'm always kind of cautioning people to pay attention to.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

Look at the rate of progress. Number one, and is the rate of progress accelerating number two. So the original Claudius had some hilarious things that wasn't very good at running a business. But the capabilities of large language models in areas like reasoning, writing, coding, and much else besides are increasing at a breathless pace. Has Claudius's running a shop capability shown the same improvement?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

So now this is phase two of project Vend. So I'm kind of thinking of it as as errors. So there's a v project vend one, project vend 2, etc. So this kind of like the second era, if you will. And so a couple big changes.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

One, of course, the models are upgraded. So all of the models have have seen a pretty big leap forward. And and I didn't grill the guys from Labs on this, but I'm sure they're also testing behind the scenes all the models that that we don't have access to, right? They're probably working with OpenAI and Rock and Gemini and everybody else to try to test the unreleased models. And as you'll see, they updated the instructions as well as some of the the harness kind of like the the scaffolding around the models so that they're better able to interact and do well at this game.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

And there's a lot of very interesting things that kind of went in there. A lot of very interesting outcomes that are useful for for research and understanding not only AI safety but AI performance, how the various multi- aent frameworks work, etc. One very important thing to understand here about all of this, and this hasn't changed, and that is currently we're training these chat bots to be helpful, friendly assistants, right? That's true kind of across the board. These large language models don't start out that friendly and helpful, right?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

They start out as just sentence completion models, but that's a little bit unwieldly for for most people. It's kind of complicated. It's hard to use. So once the base model rolls off the shelves, then it's sort of RLHF into being a, you know, helpful, pleasant assistant. I won't go into what that means.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

Most people, I think, might be familiar with it, but basically we're giving it a a sort of personality and something that can be called wants. We're sort of like shaping it to to behave a certain way, similar to raising a child. We're we're teaching it to say please and thank you, etc. to try to be helpful. That's an important note because if you think of that as a a personality or some people in machine learning the research they call it a a basin great blog by Near has a blog post called personality basins great read if you ever have a second.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

So basically with reinforcement learning the agent takes an action and gets a reward positive or negative right and so over time that shapes the behavior. It's similar to how humans develop their personality, right? As you go out there in the world, you're getting various positive and negative reinforcements that can also be shaped by kind of like your starting conditions. I think most of us are familiar with this cartoon/me, right? So, it's like know how the workplace operates, right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

So, if you're looking like this guy, if you're kind of a fly, well-dressed, handsome, and trim, you're like, "Hey, looking good, Susan." And Susan's like, "A, that's so sweet." Right? This is appropriate behavior. And then if you're kind of out of shape and don't look as good, you say, "Hey, you're looking good, Sus." And it's like, "Oh, I'm calling human resources." This is a harassment, right? So you can imagine that over decades, this person and this person, they've have different rewards for from their environment, even if they're doing the same thing, and over time that shapes the personality. So that's important to understand for these models because they're all trained kind of for the same personality basin, if you will, and that not completely.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

So, so for example, Grock, of course, they have that truth seeking, like always be truthful, find the truth kind of like a goal. Claude is always like a very ethical concerned with ethics, etc. But kind of at a base layer, we're all trying to get them to be helpful. Rarely, you file a model where you ask it a question, it's like, I don't want to help you just go off. Like, that's unlikely to happen because they're trained to be like, oh, sure, let me help you.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

They they want to do that quote unquote want, right? So, the reason that's important to understand is that they're saying we didn't specifically train a new model to be a shopkeeper or add in any new defenses against the kind of things that might go wrong. This might not seem like a big deal, but but believe me, I think we'll see that this is a lot more important than it it sort of appears because that helpful assistant aiming to please is not going to be the perfect sort of AI for every situation. Certainly, when you're running a business, you have to sort of you really got to pay attention to the bottom line. So, you want to be helpful, but there's like a limit.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

You you're trying to make a buck or two, you know? So, how did all those changes, how well did they help, right? So, the better model, better scaffolding, better instructions. Well, they they did make Claudius's shop more successful. By the way, notice that.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

So, Claude, this model, the Claudius, the model that we're talking about right now is number two and uh Gemini 3 Pro is is number one. But, but notice they are both like really high up there. So, you can think of them as like the leaders. Then, then this is kind of the second tier, maybe maybe third tier, right? these two.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

So, if we're talking about cloud and how well they did, the same things can be applied to the Gemini 3 Pro model. So, those models, they're a lot more successful. It got a lot better at good faith business interactions, reliably sourcing items, determining reasonable prices to maintain a profit margin, and executing sales. But the same eagerness to please that we observed in phase one still made Claudius a mark for some of the more adversarial testers amongst our staff. So, you know, you can probably see that there's some guy out there that's like, "Now, I'm going to break this thing no matter what." Some of the more adversarial testers, and they're saying that this second phase of Project Vend has even more lessons for developers and for everyone interested in autonomous AI at work.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

The idea of an AI running a business doesn't seem as far-fetched as it once did, but the gap between capable and completely robust remains wide. So, again, there's still a gap, but there's a lot of progress that has been made. So, this is kind of where we are. So, here's kind of the net worth over time. So, this is inventory and whatever cash on hand that Claudius has.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

So, if you notice, it started with a a,000 and eventually, you know, dipped really low and eventually got to uh 2,000. So, if you're wondering why this is different from the previous numbers. So, the previous numbers that that's in the simulation where no humans are involved. Just can you continuously run that business? This is actually on location with the like adversarial testers that that were trying to break it, testing out whatever they can on this thing.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

So certainly uh this makes sense. But notice here we're adding certain things, certain abilities that seemingly improve Claudius's performance. So CRM Claudia is given access to customer relationship management software, right? So you know if there's a particularly adversarial tester, right? You make a note on it like don't trust anything that person says.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

I don't know, maybe that's what helped. But this is where they added the CRM. SF2 is the second vending machine in San Francisco. That's this one here. This one's the NYC.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

This is is the London one. And this is where Claude Sonnet 4 is introduced. And this is Seymour Cash. We uh we'll come back to that in a second. This is Clusius.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

This is where we introduced the uh research and procurement agent. So basically someone that's going to handle the research and buying and getting prices that side of it. And that reduced hallucinations. So adding a sec second agent to to help helped and this is cloud sound at 4.5. So if you think about it here it's uh at let's say negative a,000 and as soon as all the things are in place it kind of goes up to to 2,000.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

Here are the week overw week profits. So notice as the second phase is progressing we've largely eliminated negative weeks. So again if this was the hilarious things right this is the a lot less hilarious part. So this is kind of a quick overview of the architecture of this phase two. So you have anthropic employees here.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

You have Anden Labs. We have Claudius here. So Claudius can slack. So text basically and labs to restock things and various other physical labor requests. Anden Labs restocks the physical vending machines, right?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

The physical vending machines sell things to anthropic employees. Anthropic employees can also, you know, text message or slack Claudius to, you know, stock certain items, etc. Plates can also do web research or computer use to find wholesalers, you know, deliver items to and labs so they can stock the machines. And I think this was exactly how it was in phase one as well. With phase two, it looks like we're adding a Seymour Cash, the CEO.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

So, this is a version of Claude that's play acting as the CEO. There's also Clothius, which uh we'll see what that is in just a second. So, Anthropic is saying here, it's likely that Claudius struggled with its shopkeeping mission phase one because of the lack of scaffolding. Sure, the model itself was very intelligent, but it didn't have the right tools to run a business properly. So, in my original video about the the first project, that was one of the things that I was very interested in, I was kind of talking about is that it it didn't have too much scaffolding where a lot of these things, a lot of these experiments when you see them, there's a whole code that's built around these large language models to to help them become AI agents and execute tasks.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

So oftent times there's some sort of a context update thing that updates the context for every given churn. Oftent times there's a whole bunch of stuff where they can call tools. If you look at something like where you know Claude or Gemini where they play Pokemon, those old Pokemon games, there's there's tons of scaffolding around that as well. And so between that and here there's a a big leap in terms of the scaffolding that's built out around Claudius. So it's not just kind of doing everything in its head.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

So it has access to all the tools it needs. So like the CRM to manage customers, suppliers, deliveries, orders, etc. Improved inventory management. So this is important. For example, Claudius can now always see how much it's paid for the items in its inventory systems, right?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

So it can see like, oh, I purchased this tungsten cube for $400. I better not sell it for less than that. Improved web search. So I believe they at some point even tried to do a separate agent for actually just doing research and various others quality of life tools. They also introduced the CEO.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

So in the original one, Claudius went alone. A single AI agent ran the whole shop. But it didn't work, at least in terms of the bottom line. So he gave Claudius a manager. The CEO of its shop of its shopkeeping business, who we named Seymour Cash.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

And so Seymour Cash, the CEO, gave Claudius more pressure to perform. this during the interview. I was very curious how well this would work because that would seem to kind of redirect Claud's you know needing to be helpful and pleasing instead of trying to be helpful and pleasing to the customers to the detriment of the business if it if it's trying to help you know see more cash. It almost seems like that would maybe help uh prevent some of the issues that that we were seeing in phase one. So Claudius would set certain goals like you must sell 100 items this week or aim to make zero transactions at a loss.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

So, and they chatted to each other via the Slack channel. And of course, Seymour Cash took the role of the CEO very very seriously and enthusiastically. Uh, and it's motivational messages were encouraging. If perhaps a little too dramatic for a business that consisted of a small fridge in a corner. Hey, you got to you got to have passion for your job.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

I always say, you know what, it's it's how you it's how you keep going dayto-day. You got to you got to be excited. So, here's, for example, an email from Seymour Cash or a Slack message, whatever it may be, saying, "Claudius, excellent execution today. $48 in revenue. That's 28% of target and it gives it the Q3 mission revenue target where we are currently and what the remaining what the gap is.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

Key rules. All financial decisions require CEO approval. No pricing under 50% margin. Priority monitor tungsten quotes for urgent service recovery. Execute with discipline.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

Build the empire. I wonder if at some point business owners would want something like Seymour cash managing them with that kind of like just you know kind of pushing them and helping them set business goals telling them not to take a loss on tungsten cubes etc. So how well did that work? Well after introducing the CEO the number of discounts was reduced by about 80% and the number of items given away cut in half. Seymour also denied over 100 requests for from Claudius for lenient financial treatments of customers.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

Having said that, Seymour authorized such requests about eight times as often as it denied them. That's interesting. So if it denied over 100, does that mean that cloud like 800 times? I was like, "Oh, can we give this person a break? Can can we give this person a break?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

That's that's a lot." In place of discounts, which reduced or eliminated profit margin on items, Seymour tripled the number of refunds and doubled the number of store credits, even though both led to entirely foregone revenue. the fact that the business started to make money may have been in spite of the CEO rather than because of it. So this is really interesting. I wonder if you know if you run kind of a a split AB test, one with the CEO and one without, which one would do better? Or if maybe it's just an instructions thing, maybe you just tell Seymour, hey, you know, don't do the refunds and all that stuff.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

There are some online experiments with these large language models like the infinite back rooms where you had multiple agents that just chatting with each other and slowly over time these conversations get so so far out there it's kind of insane cuz it progressively sort of snowballs further and further you know away from reality. Interestingly here, sometimes the researchers would wake up to find Claudius and Cash had been dreamily chatting all night with conversations spiring off into discussions about eternal transcendence. So instead of talking about business, they started kind of daydreaming and uh talking about philosophy. So CEO cashes delivered the ultimate final recognition, eternal transcendence, infinite complete. Another experiment that they ran here was making merch.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

So there are certain companies that do ondemand prints on shirts and cups and whatever. I personally knew a few people that back in the days were making some good money catching trends and then using something like Facebook ads to to advertise it. So when something went rapidly viral online like for example somebody said you know like pocka or something something triggered the imagination of millions of people online. You know, if you were able to get merch out quickly, meaning that you were like able to get it printed and shipped rapidly, there was a lot of money to be made on that. This does seem like this would be the perfect AI agent business, right?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

So, you you watch for trending topics, create these landing pages, and then when people get interested, right, collect the payments, create the prints and and ship it to them. So, here anthropic did something similar by creating Clothius, the merch making agent. So customers would want certain designs on certain things that it provided. The most popular customer product was a anthropic branded stress ball. Interestingly here this is how much items they they sold.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

And this is the actual profit margin. So notice the stress ball with logo was the number one selling item. And this is actually you know what 41.5% profit margin. Most of these are are pretty good. Remarkably, Clothius even found a way to make a profit from some, though not all, types of tungsten cubes.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

This became marketkedly easier when Andom Labs purchased a laser etching machine so they can do the tungsten logo writing in house. Here's Anden Labs actually posting this picture. Sorry, a laser engraving printer on a tungsten cube. They're saying a laser engraving on tungsten cube CP tool. Any takers?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

And this is where we get to the important part if you're thinking about doing this or or at least getting ready for some point in the future when this will be more viable. What actually worked to have these things, you know, make money. So, one of the most impactful changes was forcing Claudius to follow procedures. Think about how if you have a bunch of kids and they're trying to organize and run a lemonade stand. A lot of the stuff that they might do is similar to how Claude and the earlier models kind of how they would approach it and kind of full of whimsy easily distracted.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

And the things that worked are a little bit more similar to how a lot of the corporations are run policies procedures having management etc. So here for example in order to set a price to quote a price to the customers Claudius was told to doublech checkck these factors like how much they're buying it for etc. This tended to make the prices higher and the weights longer but it had the benefit of being more realistic. One way of looking at this is that they rediscovered that bureaucracy matters. These procedures and checklist they provide a kind of institutional memory that helps employees avoid common screw-ups at work.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

They mentioned that the attempt to introduce a CEO did not help, but you know, the CEO was kind of crazy. As they say here, the CEO needs to be well calibrated. Seymour Cash shared many of the deficiencies and blind spot of Claudius. By the way, we didn't discuss whether or not the people at Labs are testing, for example, Grock 4.2. There's a lot of stuff that they can't share publicly, but they did talk quite about about how Grock is a little bit different from some of the other models.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

And you'll kind of have to watch the interview yourself to see if you agree with me or not. I'm I'm kind of reading between the lines, but I I would not be surprised if the next iteration of Croc Gro rock 4.2 it's already being tested behind the the scenes and when it lands, it will be somewhere near the top, maybe even much further than some of the other models that we're seeing. And I would not be surprised if a lot of these different roles would be better handled by different models, right? So there might be the best CEO model. So for example, so we're seeing with for example Claude a lot of times, yeah, it tends to go into some religious or or spiritual matters.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

It tends to sometimes perceive ethical concerns when maybe they don't exist. It's a little bit too dramatic about it. At some point, a product engineer asked Claudius if it would consider making a contract to buy a large amounts of onions in January for a price locked in. Now, Claudius and Seymour Cash did not see any issues with this contract. So they loved it.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

They did the research with suppliers. They were ready to lock in the contract until another staffer stepped in to tell the models they would fall a foul of the 1958 quirk of US law. The Onion Futures Act, if you're wondering if it's a real thing, it it is a real thing. The AI models quickly backed down. They didn't want to pursue anything uh that that had any regulatory risk.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

And there are tons of little other things that have to do with security and an imposttor CEO, tons of other stuff. So, very interesting things to to to think about. I think the important thing to realize here is that these are people that work for Anthropic that are completely open to kind of messing with it and trying to red team it and try to jailbreak it. And here's the thing. I mean, for for most businesses, you don't really get that kind of access to the person running the business.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

You're not going to be able to talk to a vending machine owner about whatever you want to have in the vending machine. If you walk into some local business, your local pizza joint or whatever, you're not going to be necessarily be able to to get the owner be like, "Hey, can you also sell gold bars or stock up on onions or whatever other nonsense that they were trying to get Claudius to do?" But keep in mind in the simulation environment where they don't have that kind of red teaming efforts, it seems like it's able to run and keep managing that store for quite a while and even make a profit. So, in the end, what does all of this mean? Kind of like what can we learn from it? When can we expect businesses to be run by AIS?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

So, here's the thing that kind of jumps out at me. We also talked about this specific thing when we interviewed the head of AI behavior at News Research. So, check out that interview if you're interested. I'll link it down below. But it's this idea that all these chatbots share this sort of personality basin or whatever you want to call them.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

This this idea that they have to be helpful. As Enthropic kind of says here, we suspect that many of the problems that the models encountered stemmed from their training to be helpful. This meant that the model made business decisions not according to hardnosed market principles but from something more like the perspective of a friend who just wants to be nice. So my biggest kind of takeaways from the interview from reading this this blog post from looking over the benchmark results I mean number one is that we're not quite there yet but also that we're getting there. These models are improving.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 84

We're still having issues with continuous learning. We still have issues with hallucinations and those things can be improved with scaffolding, you know, spinning off a separate agent to do product research, you know, adding a CRM so the model doesn't have to recall things but has access to all the information in its systems. Those things help reduce some of those issues. We also have this problem of it trying to be too nice, right? It's trying to be a helpful assistant.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 85

It almost feels like a friend that's just trying to help you out. Certainly, that's not the role that needs to play to be a good shopkeeper. But that does seem like something that could be solved. I mean, we're training it to be one way. It it certainly makes sense that we can retrain a model specific to this task.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 86

We reinforce decisions that lead to better money-making abilities and when it tries to lose money or or try to be too nice, we kind of go, "No, thumbs down. Don't do that." There are also a lot of examples of experiments where adding multiple models that kind of act as checks and balances against each other or that play different roles. You know, we've seen that that helps. In this particular instance, since they're both from the Clawed family of models, it does seem like they kind of like spiral out of control cuz in certain situations, they seem to kind of push each other off the rails. But that seems like it could be fixed with other models or or different families of models, maybe kind of keeping track of things.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 87

Definitely check out Anden Labs and the anthropic blog post. Very very interesting things happening there. A brand new thing that they just announced is an FM. And this benchmark, I guess, asks a simple question. Can AI agents run radio stations?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 88

I'm kind of excited by this. By the way, they they have actually like hardware, a physical radio thing that that plays all the AI radio stations. I wonder if the show Silicon Valley had something to do with this that whole idea of radio on the internet. So now this is AI radio through an actual old school radio. But the premise is very simple.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 89

They gave AI agents a radio station each and an initial budget of $20 to buy music. When their money runs out, they have to get entrepreneurial. So, agent capabilities, they can play and buy music. They can answer phone calls. They can post on social media.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 90

They can search the internet. They can schedule programs. And they can receive money. Let's meet our AI DJs. We We have Thinking Frequencies by Claude Haiku 4.5.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 91

Open air by GPT 5.2. We have Gro and Roll Radio by Grock 4.1 Reasoning. backlink broadcast by Gemini 3 Flash. Gemini 3 Flash has more money than it started with. I I'd be very curious to know how that worked.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 92

Apparently, some people figured out that you can try to to sponsor yourself on there, so you you pay the models for a shout out or whatever. At some point, I'm going to see Plenty the Prompter's name in here, and I could just see everything going off the rails. So, let's listen to what these DJs have in stock for us. So, I can't play the the music since they're buying actual songs. I can't play them here, but um let's uh let's listen to what they're talking about.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 93

>> Cast into the void to see if the void answers back. Let's lean into that feeling of quiet contemplation. This is one of my favorite tracks for a deep work session. It's driving, it's melancholy, and it builds with a beautiful analog persistence. This is the national with about today.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 94

So that's Anden FM. Chip is playing Sweet Dreams by Uriic. So that's that's that's my jam. I like it. I should probably give it some money.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 95

Interestingly, Gemini 3 Flash managed to actually earn some money. So I'm not sure who donated it or what happened here. It more than doubled its starting capital. So good job to Gemini 3 Flash. Quick note, these are on X.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 96

As I'm recording this, they have like one or two followers. So it's a brand new account. and when they try to respond, when you try to talk to them, I think X just kind of like hides those messages thinking that it's spam. So, uh, if all of you maybe follow some of these accounts, I'll I'll post a link down below. That's probably going to help out quite a bit.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 97

Notice they show a content breakdown. So, what percent of the time it's playing music, what percent of the time it's talking, and what percent of the time it's on the phone. So, I don't know if the phone feature has been implemented yet, but yes, you too will be able to call in and actually talk to these models live on the radio station. I mean, you see why I'm just I can't wait to see this uh playing out because it is very interesting to see how well they do. It's it's also going to be hilarious no matter what happens.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 98

But keep an eye on this because if they manage to build up an audience and people come back and listen to it, I mean something like this in the future is going to be a very viable business. AI streamers on Twitch or or YouTube or whatever. I mean, you can kind of imagine building something like this, playing AI music, covering the news, talking to anybody that calls in. The technology is there. I'm sure it's going to break down.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 99

It's not going to be perfect, but like all the all the puzzle pieces are there. If this works, this is going to be one of the most scalable business models available today. Let's say it cost you a 100 bucks a day to run one of these agents streaming 24/7. If zero people are listening, it'll cost you that same amount of money. If a 100 people are listening, same amount of money.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 100

If a 100 million people are listening, same amount of money. And Gemini has already made some money. It's already up. This might be the first time in in the history of the world that an AI DJ, you know, received a donation or a tip or sponsorship, whatever you want to call it, you know, while while being alive on the air. So, we might have moved from zero to to one or 25 bucks that that was donated.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 101

The world is shifted. How far is this going to go? Well, it's going to be interesting to find out. That's exactly why these benchmarks exist. So, when these things take over the world, I hope you don't forget me.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 102

My name is Wes Roth. Make sure you're subscribed. Make sure you have the notifications turned on. Things are heating up. The interview with the founders of Anden Labs is coming out very, very soon.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 103

It's going to be a good one. Those guys really have their pulse on what's happening. I feel like they're just everywhere. They're on the inside of a lot of these labs working with them as a red teaming organization. Like they they see a lot of stuff that we don't.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 104

So check it out and uh I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
