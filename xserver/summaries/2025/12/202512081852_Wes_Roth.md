# ğŸ“º OpenAIã®ã€Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒƒãƒ‰ã€ãŒçµ‚äº†ï¼šæ¬¡ã®ä¸€æ‰‹ã¯

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: "Code Red" Over, OpenAI is about to blow...
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=F9EKRZ0wdxE](https://www.youtube.com/watch?v=F9EKRZ0wdxE)
- **å‹•ç”»ID**: F9EKRZ0wdxE
- **å…¬é–‹æ—¥**: 2025å¹´12æœˆ08æ—¥ 18:52
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

Googleã®Gemini 3.0ãƒªãƒªãƒ¼ã‚¹ã‚’å—ã‘ã¦OpenAIãŒã€Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒƒãƒ‰ã€ã‚’ç™ºå‹•ã—ãŸå¾Œã®çŠ¶æ³ã¨ã€Grok 4.20ã®ç¶šå ±ã«ã¤ã„ã¦è§£èª¬ã—ã¦ã„ã¾ã™ã€‚Grok 4.20ã¯æ ªå¼å–å¼•ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§2é€±é–“+4æ—¥ã®æ™‚ç‚¹ã§65%è¿‘ã„ROIã‚’é”æˆã—ã€å¼•ãç¶šãåœ§å€’çš„ãªæˆç¸¾ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚ä¸€æ–¹ã€LM Arenaã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ã¯ã€Gemini 3 ProãŒOpenAIã‚„Anthropicã®ãƒ¢ãƒ‡ãƒ«ã¨æ¿€ã—ãç«¶ã„åˆã†çŠ¶æ³ãŒç¶šã„ã¦ã„ã¾ã™ã€‚ã“ã®å‹•ç”»ã§ã¯ã€ä¸»è¦AIä¼æ¥­é–“ã®æŠ€è¡“ç«¶äº‰ã®æ¿€åŒ–ã¨ã€2025å¹´æœ«æ™‚ç‚¹ã§ã®AIãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã«ã¤ã„ã¦è©³ã—ãåˆ†æã—ã¦ã„ã¾ã™ã€‚AIæŠ€è¡“ã«é–¢å¿ƒã®ã‚ã‚‹è¦–è´è€…ã‚„æŠ•è³‡å®¶ã«æœ‰ç›Šãªæƒ…å ±ãŒæä¾›ã•ã‚Œã¾ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **Grok 4.20ã®ç¶™ç¶šçš„æˆåŠŸ**: å…¬å¼ã‚³ãƒ³ãƒšçµ‚äº†å¾Œã‚‚å–å¼•ã‚’ç¶™ç¶šã—ã€2é€±é–“+4æ—¥ã§16,454ãƒ‰ãƒ«ï¼ˆå…ƒæœ¬10,000ãƒ‰ãƒ«ã‹ã‚‰ç´„65%å¢—ï¼‰ã‚’é”æˆ
- **å…¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§é»’å­—**: 4ã¤ã®ç•°ãªã‚‹å–å¼•ãƒ¢ãƒ¼ãƒ‰å…¨ä½“ã§å¹³å‡22%ã®ROIã‚’ç¶­æŒã—ã€å”¯ä¸€ã®ãƒ—ãƒ©ã‚¹åç›Šãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦åœ§å€’çš„ãªå„ªä½æ€§ã‚’ç¤ºã—ã¾ã—ãŸ
- **OpenAIã®ã€Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒƒãƒ‰ã€å¯¾å¿œ**: Gemini 3.0ã®å„ªã‚ŒãŸæ€§èƒ½ã«å¯¾ã—ã€OpenAIãŒè¿…é€Ÿã«æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ã™ã‚‹å‹•ãã‚’è¦‹ã›ã¦ã„ã¾ã™
- **LM Arenaã§ã®ç«¶äº‰æ¿€åŒ–**: Gemini 3 ProãŒç·åˆ1ä½ã‚’ç²å¾—ã—ã€é›£ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€å‰µä½œã€æŒ‡ç¤ºå¾“é †æ€§ãªã©ã§é¦–ä½ã‚’ç‹¬èµ°ã—ã¦ã„ã¾ã™ãŒã€Grok 4.1ã‚„Claude Opus 4.5ã‚‚æ¥æˆ¦ã‚’ç¹°ã‚Šåºƒã’ã¦ã„ã¾ã™
- **Grok 4.20ã®å¹´å†…ãƒªãƒªãƒ¼ã‚¹äºˆå®š**: 3ã€œ4é€±é–“ä»¥å†…ï¼ˆå¹´æœ«ã¾ã§ï¼‰ã«Grok 4.20ãŒæ­£å¼ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹è¦‹è¾¼ã¿ã§ã€AIå¸‚å ´ã«ã•ã‚‰ãªã‚‹å¤‰åŒ–ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Couple really big AI news happening. First and foremost, Google can't stop winning. Some analysts believe it's going to 400. In other news, Grock 4.2 is coming in 3 or 4 weeks, as in we'll have it before the end of the year. Why is this important?

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Well, I'm sure you have seen the Alpha Arena and Gro 4.2 to oh absolutely dominating the competition and [clears throat] making some money in one of the variations of the situational awareness where each model is aware of the fact that it's in competition with other AI models and they all get to see each other's profit and loss statements. Gro 420 I'm just going to start calling it Grock 420 because why not? Grock 420 is up almost 65% and that's just in a little bit over two weeks. So, the competition began November 19th and then it ran for 2 weeks until December 3rd. I believe they called it December 3rd at 5:00 p.m.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Eastern. That's when the competition officially ended. But they just let the models keep running and making or losing money. So, it's been 2 weeks plus 4 days and this model is up to 16,454. So, it started out with 10,000 and it's up to 16,000 plus.

### ğŸ“ è©³ç´°èª¬æ˜

And if we combine all four variations that it's running, it's still up 22%. It's the only model that is, you know, profitable, that has a positive ROI. So, Grock 420 is coming out in three or four weeks. The mystery model that won the alpha arena was announced to be by Elon Musk to be an experimental version of Grock 4.2. Now, of course, Elon Musk revealed this to the world on December 4th in a response to one of my posts.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

I will never get over that. And if you recall that OpenI went code red in response to Gemini 3.0 coming out and being just really good across the board, well, it does seem like that code red did work. It seemed like they quickly galvanized and were able to quickly prepare a new model to get pushed out. This is Poly Market, right? And the question is which company has the best AI model end of 2025?

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

I believe they're using LM Marina as a way to to settle this bet. So a different way of asking the questions by the end of 2025 which model whose model is sitting at top of LM Marina. So currently of course as you might be aware so Gemini 3 Pro is dominating across a lot of different categories. In fact, Google models in general are dominating across a lot of the categories. So, here's Arena overview.

### ğŸ¯ å¿œç”¨ä¾‹

Gemini 3 Pro is very solid across the board. So, it's number one overall, right? But it's number one in hard prompts, creative writing, instruction following, but we have a lot of competition. Grock 4.1 thinking, Claude Opus 4.5. Competition is very tight.

### ğŸ’­ è€ƒå¯Ÿ

GPT 5.1 high is in sixth place. So, if this doesn't change at the end of the year, Google would win that bet. So, here again is that chart. I cut the very last portion of it off just to create some suspense. The orange line, notice that's Google.

### ğŸ“Œ ã¾ã¨ã‚

So, it was up at 91%. At some point, people were like, Google is going to continue dominating throughout the end of the year. That's going to be the number one model at the end of 2025. Then, OpenAI goes code red. And on, let's see, what date was this?

### âœ… çµè«–

Somewhere around the very very beginning of December, let's call it, the situation changes and OpenAI shoots up. So at the peak, it was a 26.6% chance, right? With Google dropping down to 66%. So what does that mean? That means that a lot of people are expecting OpenI to make some big moves and basically climb back to the number one place in LM Marina.

### ğŸ“š è¿½åŠ æƒ…å ±

So what would you bet the outcome to be? So they're using the results from Arena score section of the leaderboard at LMA.ai. AI with the style control unchecked. Meanwhile, we've been seeing some new models from OpenAI, what we believe to be OpenAI that were tested in the arena. Emperor, Rockhopper, Mumble, and Macaroni.

### ğŸ”– è£œè¶³

The different models have different reasoning budgets. So, it's very possible that OpenAI is trying to find which model would get it to the top of that arena to to beat Gemini 3.0. And of course, there's a lot of expense that goes into it. So, I mean, you can crank up the power, but it's going to be extremely expensive to run inference. So, I think it's likely that they're going to try to find something that beats it, but they they don't want to completely overshoot and spend a lot of money.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

They want to beat it by a solid lead, but not more than they have to. Meanwhile, Google recently published this paper, the two new papers actually, Titans plus Mirus, helping I have a long-term memory. We've talked about some of these papers before, nested learning, Titans, etc. So the idea of similar to how the human brain has long and short-term memory, this a little bit similar to that. They're introducing different architectures that will try to mimic that to create more of a continuous learning approach.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

This is Ali Beruse. So he's one of the main authors behind a lot of that research. So he's talking about how they approached building these new architectures. And basically the big point with transformers again another Google AI architecture back from 2017 that gets these models to understand what they should be paying attention to what's important what's not important etc. The problem with transformers is the bigger the context window the more expensive it is the harder it is to kind of keep track of it all.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

It's quadratically more expensive. So if you think about it in terms of like how the human memory works we have a short-term memory that is very accurate but with a very limited window like 30 seconds. How do we handle longer context? Well, we kind of have other memory systems that help support that. So, the idea is what do we put into long-term memory?

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

How do we forget certain things? So, over time, you might not need certain things. So, you can kind of let those memories decay. Interestingly, surprise is yet another thing that is kind of taken into consideration here, right? So, if you're surprised by something, you found something that doesn't didn't quite fit your world model.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

I'll give you an example. Have you tried things like vanilla ice cream or certain raspberry pastries or certain berry drinks where they say that it's that has natural flavors on it? Now, natural flavoring might sound great, right? Delicious, natural. Here's the problem.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

Sometimes that natural flavoring, how they harvest it, and uh you might be surprised by this. It comes from from beavers, specifically from their like anal glands. So natural flavorings could mean delicious beaver butt juice. Did you know that? If not, you're probably pretty surprised.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Also, honey is bees regurgitating stuff like they they they have it digesting their stomachs and they they throw it back up. And that's honey. Now, if you didn't know this, you were probably surprised by it. What is surprise? Sort of the delta.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

It's the difference between kind of what your world model was and this new information that you just learned. By the way, all of that is 100% true. You can just Google it. I made those images with Nano Banana Pro. It cited all the sources and everything.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

And that surprise, that difference between what you thought it was, which is delicious ice cream and honey, etc., and what it actually was, that that difference, that surprise will likely mean that it'll take you a long time to forget it. You're welcome. So, interestingly, with these AIs, with these neural net architectures, there's a lot of crossover. So notice how they're saying it's we're kind of using similar ideas that we notice exist in sort of human brains, right? So crucially, Titans doesn't just passively store data.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So it's not like this catalog or or filing cabinet where we just throw all the data into. It actively learns how to recognize and retain important relationships and conceptual themes that connect tokens across the entire input. A key aspect of this ability is what we call the surprise metric. In human psychology, we know we quickly and easily forget routine expected events. But remember things that break the pattern.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

Unexpected, surprising, or highly emotional events. Like when I told you about the beavers and the bees, we skipped the short-term memory and logged it directly in your long-term memory. I am I am sorry, but it was such a perfect way to explain it. I just I I couldn't help myself. And finally, I just want to do a quick update.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

I'm not sure if it's a correction, but I might have stated some things not 100% clearly in my last video about TPUs. We actually interviewed somebody from semi analysis. Jeremy was absolutely fantastic interview. I'm trying to publish it. Here's the problem.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

We interviewed him right before this paper was published. And this paper I believe was the first time that Google revealed the news. This is semi analysis, but they were sort of basing it on based on some some of the things that Google has revealed. One of the big reveals, as I'm sure you know, is that Google seems like it's beginning to sell TPUs. So, their own AI chips is being to sell them to customers.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

As in like you can take the physical GPU, put it in your own metal rack on a data center and build your own data center. And one of my previous videos about it, so we posted the interview with Jeremy from Semi analysis where we actually were talking at length about what would happen if Google started to sell TPUs externally. you know, this would certainly be a big deal. It make them a much bigger player. Right now, we're actually seeing that it might be beginning to happen.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

And I don't mean renting it out through the cloud, but actually selling actual physical metal TPUs that you can put your own data center, build your data center with it. It sounds like that's happening in the anthropic deal. It was a hybrid deal. So, that million TPUs that are being sold to Enthropic, right? The first phase of the deal covers 400,000 the of these TPU V7 Ironwoods that Broadcom will sell directly to Anthropic, right?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

Somebody else will handle the on-site setup, all that stuff. And the remaining 600,000 TPUs will be rented through GCP, Google Cloud. And they're in talks in potentially starting to sell GPUs. And they're in talks of selling again external TPUs, right? So externally selling it to other people starting with Anthropic and extending to Meta, SSI, XAI and even potentially OpenAI.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

So as the article begins here in the very beginning, now Google is selling TPUs physically to multiple firms. So just wanted to provide that clarification because we had that interview where we like went point by point and then like days later we had this breaking news and a lot of this is still sort of like projected in the future. So there's no deals with all those companies, SSI, Meta, I think X000 or maybe even OpenAI. I don't think they have any deals signed or at least nothing announced. But it does seem like there are talks about selling those TPUs to them which of course would be a a huge deal.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

It would have an impact on on Google, on Nvidia, on pretty much everybody else. Meanwhile, Michael J. Bur is up to something. So, there's Kakashi and him discussing this idea of Nvidia's GPUs being warehoused in mass quantities in the US, but also overseas. I'll link some of this down below, but for the people that are playing the game of GPUs and are interested in all this stuff, whether you're investing or just out of curiosity.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So, I haven't had a chance to look at this yet, and this is not really in my wheelhouse cuz they're doing a lot of calculations about, you know, how many power generators you need, etc. But if you're interested in Michael J. Bur, the man from the big short, the one that shorted the housing bubble, whatever, 2008, 2009. So, he of course does have a short against Nvidia and a Palunteer. And we're beginning to kind of see glimpses into why he's doing that.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So, you can kind of watch that developing if that's something you're interested in. Andre Carpathy posted something talking about, you know, what happens when you refer to the model as you, as in what do you think about this? Just noticed that Elon Musk just comment on this. So, this is probably going to blow up even more than it was. Techn from News Research replied, "Elie Yazerikovski, ironic given the conversation with Replicate last week.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Replicate is Janice and they wrote simulators on less wrong." And that's quite a hefty hefty blog post, article, whatever you want to call it. If you are interested in the whole idea of the psychology of LM, how they perceive things, how they think about things, this is kind of an interesting thing to dive into. We'll probably be doing another video about this because again, like this is just beginning to blow up. Maybe bookmark this cuz I I I do feel like it's going to be a big deal because you'll see that some people are going to disagree with this take. They're going to disagree with Andre's take.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

I also have a question in here. So maybe Andre will notice it, but I know for for some some of you this is going to be an absolutely fascinating thing to pay attention to. It's just beginning to break. So keep an eye out. I think it has everything.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

It has a little bit of drama, mystique, you know, the craziness about how LLM's quote unquote think. Do they think? Do they perceive themselves as something? This is like those superhero movies where like all the different universes combine. I've I mean you've got Elon Musk, Andre, you've got people from news research, people from less wrong.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

You got Elizer Replicate like it's the veritable who's who of the AI world commenting and talking about this. If this is of interest to you, we did have an actual interview with a member of news research. So this is it. So, Kuran 4D, co-founder and head of behavior news research, like if you want to know about the insanity that goes on inside these LMS, this would be a great podcast to listen to. And yeah, just pay attention because I think things will be blowing up in that particular discussion.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

In other news, we already covered this before, but Elon Musk will be planning to put solar powered AI data centers in space, similar to Google's project suncatcher. Meanwhile, Kathy Wood of Arc Invest open source her model for how they evaluate Space X. So, in their bullcase scenario, it's worth something like $3.1 trillion I believe. So, here's that. So, kind of the expected value, 2.5 trillion, bullcase, $3.1 trillion.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So, that's what they believe it's worth. Here's the thing. This is before the solar powered data centers in space idea. So Elon Musk jumps in here saying, "Hey, that's a big factor that we need that we need to consider." So we covered why it's such a big idea when we covered Project Suncatcher by Google. Basically, in a nutshell, Google tested out a lot of things and they were like, "Wo, this is very viable." Putting AI data centers in a sun synchronous orbit is fairly viable in a lot of different ways.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

Lasers can transfer data between satellites. They just have to fly in a certain formation, but it's not that complicated to to steer it. Solar panels are six times to 10 times more effective in space than they are on the surface of the planet. And all the equipment, including TPUs, don't get fried by the radiation. I forget the exact numbers, but it seems like they're more than enough for a 5-year mission.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

Like, they'll easily survive. The amount of radiation they soak up is far less than the point at which they start tripping out. Literally, there's only one thing that prevents us from doing it right now. kind of like the biggest obstacle that is the price to shoot things up into orbit. It needs to come down.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

The kilo per dollar price to put things into an low Earth orbit right now is too damn high. I think it's something like $1,500 per kilo for for the specific stuff that they need to put up there. And we need it to be something like 200 in order for it to be equivalent to what it would cost to build data centers and power plants here on Earth. But if we take a look at SpaceX and their learning rate, their ability to keep improving and optimizing things and reducing the cost, then if that learning rate is sustained, then we'll hit what where we need to be, like the $200 per kilo, we'll hit it by 2035. So, not that far away.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Here, Elon Musk is saying it's going to be less than 3 years. So, if you're taking Google, they're saying it's about 10 years away. Elon Musk is saying it's about 3 years away. Maybe it's somewhere in between. Maybe one is closer than the other.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

We'll see. The point is it's not 50 years away. It's not 100 years away. This might be the cheapest way for us to power AI data centers again by by just putting them out in space in a not tooistant future. It's easier to cool them in space.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

The dumping of the heat like if we're have all these centers all over Earth, you know, pumping heat into the atmosphere eventually that becomes a problem. If they're out in space, it's not so much a problem. There's tons of free electricity there, right? Meaning that, you know, you just generate the sun's rays that are there 24 hours a day if you're in the right orbit. It's something like six to 10 times more efficient to collect sunlight for electricity there than it is here on the planet surface.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Like, there's a lot of benefits. Anyways, we'll cover a lot more of this in a separate video. I am off. Thank you so much for watching. My name is Wes Roth and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2025å¹´12æœˆ30æ—¥

</div>
