# ğŸ“º OpenAI's new AI chip

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: OpenAI's new AI chip
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=9btw343FHb4](https://www.youtube.com/watch?v=9btw343FHb4)
- **å‹•ç”»ID**: 9btw343FHb4
- **å…¬é–‹æ—¥**: 2025å¹´10æœˆ14æ—¥ 06:09
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Some big news today in AI world. First and foremost, OpenAI and Broadcom announced strategic collab to deploy 10 gigawatts of OpenAI designed AI accelerators. That's right. OpenAI is building its own chips custommade for their own needs for training for inference. Is OpenAI building their very own Nvidia or potentially an Nvidia competitor?

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Certainly the scale here is massive. Here's a quick clip from the OpenAI podcast with Sam Alman and Greg Brockman and the CEO of Broadcom talking about their future goals. A lot of ways that you would look at the infrastructure builder right now. You would say it's the biggest joint industrial project in human history. >> We're defining civilization's next generation operating system.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

>> That is a drop in the bucket compared to where we need to go. That's a big drop. >> Today we're announcing a partnership between Broadcom and OpenAI. We've been working together for about the last 18 months designing a new custom chip. Uh more recently that we've also started working on a whole custom system.

### ğŸ“ è©³ç´°èª¬æ˜

These things have gotten so complex you need the whole thing. And we will be starting in late next year deploying 10 gawatt of these racks of these systems and our chip which is a gigantic amount of computing infrastructure to serve the needs of the world to use advanced intelligence. We closely collaborated for a while on designing a chip that is specific for our workloads. When it became clear to us just how much capacity inference capacity the world was going to need, we began to think about could we do a chip that was meant uh just for that kind of a a very specific workload. Broadcom is the best partner in the world for that obviously.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

And then to our great surprise, this was not the way we started. Um but as we realized that we were going to really need the whole system together to support this as these as this got more and more complex, it turns out Broadcom is also incredible at helping design systems. Open AI has been doing continues to do the most advanced models, frontier models in generative AI out there. And but as part of it you need you need you continue to need compute capacity the best latest compute capacity as you progress in the road map towards a better and better frontier model and towards super intelligence and compute is key part and that comes with on semiconductors and as Sam indicated more than semiconductors and we are even though I say it myself probably the best semiconductor company out there and more than that is AI is a very very exciting opportunity for us in terms of we we are my engineers are pushing the innovation envelope and newer and newer generations of tech of of semiconductor technology. >> One of the many reasons I'm so excited about that is by being able to optimize across that entire stack we can get huge efficiency gains um and that will lead to much better performance, faster models, cheaper models, all of that.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

as you get that better performance and cheaper and smarter models, one thing that we have consistently seen is people just want to use way more. 10 gawatt is a gigantic amount of capacity. And yet, if we do as good of a job as we hope, um even though it's vastly more than the world has today, we expect that very high quality intelligence delivered very fast and a very low price, the world will absorb it super fast and just find incredible new things to use it for. We've been able to apply our own models to designing this chip uh which has been really cool. We've been able to pull in the schedule.

### ğŸ¯ å¿œç”¨ä¾‹

We've been able to get massive area reductions, right? You take components that humans have already optimized and uh just pour comput into it >> and the model comes up with its own optimizations. And it's very interesting. We're at the point now where I don't think any of the optimizations we have are ones that human designers couldn't have come up with. Like usually our experts take a look at it later and say, "Yeah, like this was on my list." but it was like 20 things that it would have taken them another month to get to.

### ğŸ’­ è€ƒå¯Ÿ

>> So, as Greg Brockman put here, announcing their partnership with Broadcom to build an open AI chip. The deal is on top of Nvidia and AMD ones and it's going to allow them to customize performance for specific workloads. The world needs more compute. So, OpenAI has been absolutely going gang busters making tons of deals with a lot of different companies to secure compute and now even building their own custom chip. A lot of people are wondering if this is real or just money kind of going around in a circle.

### ğŸ“Œ ã¾ã¨ã‚

A lot of these deals are merchant financed, meaning that the merchant that's selling the chips is actually financing in part these deals. As Financial Times puts it, this mammoth chip order means Opening I could spend another 350 billion to 500 billion on top of the roughly 1 trillion of chip and data center deals it signed in recent months. Now, a lot of people are wondering where all the cash is coming from to pay for all these deals. A lot of these deals are structured in somewhat circular ways. Some people are calling the peak of the AI bubble.

### âœ… çµè«–

The former Intel CEO just said, "Yes, we are in an AI bubble." Of course, he says, but there's an asterisk there. Let's take a listen. >> Are we in some kind of AI boom? But also, some would think about it in the context of it a bubble. There's a lot of leverage in the system.

### ğŸ“š è¿½åŠ æƒ…å ±

There's a lot of cash, but then there's a whole bunch of other folks who are trying to build these data centers. Whether there's the energy component side of it or whether you think about the real estate component, I mean, there's just a whole a lot of things happening at one time. >> Yeah. And you know, are we in the AI bubble? Of course.

### ğŸ”– è£œè¶³

Right. You know, we level of course we are. I mean, you know, we're hyped. We're accelerating. We're putting enormous leverage uh into the system.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

You know, that said, I don't see it ending for several years. You know, I do think we have uh you know, an industry shift to AI as Jensen has talked about and I agree with this. You know, that businesses are yet to really start materially benefiting from it. you know, we're displacing all of the internet and the, you know, service provider industries as we think about it today. We have a long way to go.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

>> What's the sign that would be too much for you? >> Well, you know, and is what's the risk of it being too much, which I want to come back to as well. You know, to me, there's a set of technologies on the horizon, some of which we're driving like our Snowcap, you know, where we're promising to be 100x better in power performance, you know, meaning a gigawatt data center, I can do it in 10 megawatts and deliver the same AI performance. And not just Snowcap, but whole range of disruptive technologies. And I think they start materializing the latter part of the decade.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

So you know I do think in that sense nothing is changing this path uh for several years. You know that said it will change you know these are radical improvements in AI efficiency that occur this year.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ28æ—¥

</div>
