# üì∫ Self Improving AI is getting wild

## üìã ÂãïÁîªÊÉÖÂ†±

- **„Çø„Ç§„Éà„É´**: Self Improving AI is getting wild
- **„ÉÅ„É£„É≥„Éç„É´**: Wes Roth
- **ÂãïÁîªURL**: [https://www.youtube.com/watch?v=TCDpDXjpgPI](https://www.youtube.com/watch?v=TCDpDXjpgPI)
- **ÂãïÁîªID**: TCDpDXjpgPI
- **ÂÖ¨ÈñãÊó•**: 2025Âπ¥10Êúà28Êó• 12:39
- **ÂÜçÁîüÂõûÊï∞**: 0 Âõû
- **È´òË©ï‰æ°Êï∞**: 0

## üí° Ê¶ÇË¶Å

„Åì„ÅÆË®ò‰∫ã„ÅØ„ÄÅYouTubeÂãïÁîª„ÅÆÊó•Êú¨Ë™ûÂ≠óÂπïÔºàËá™ÂãïÁøªË®≥Âê´„ÇÄÔºâ„Åã„ÇâËá™ÂãïÁîüÊàê„Åï„Çå„ÅüË¶ÅÁ¥Ñ„Åß„Åô„ÄÇ

## ‚≠ê ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà

> üìå „Åì„ÅÆÂãïÁîª„ÅÆ‰∏ªË¶Å„Å™„Éà„Éî„ÉÉ„ÇØ„Å®„Éù„Ç§„É≥„Éà„Åå„Åì„Åì„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åô

## üìñ Ë©≥Á¥∞ÂÜÖÂÆπ

### üé¨ Â∞éÂÖ•

So, one of the things that a lot of us here in the AI community are watching in anticipation is the emergence of self-improving AI agents. Basically, when AI is able to improve itself to do its own machine learning research to kind of modify its own source code or weights in order to get better and better particular tasks, then things get interesting because we're not quite sure how far that's going to take it. This is where we could potentially trigger the intelligence explosion. You've no doubt seen this chart a few million times and it was because I've showed on my channel at least a million times. But the idea is once we get somewhere here, automated AI research takes over and there's this kind of explosion of AI progress.

### üìã ËÉåÊôØ„ÉªÊ¶ÇË¶Å

Now, of course, this is theoretical. We don't know if we're going to get there or not, but we are kind of in this range leading up to this theoretical intelligence explosion. And we are seeing some papers and research that's showing we're seeing some of it come to light. As Sam Alman put it, we're in the laral stages of recursive self-improvement. Now, here's Jurgen Schmidth Huber.

### ‚≠ê ‰∏ªË¶Å„Éù„Ç§„É≥„Éà

This is kind of a fascinating person because he did have a lot of papers with a lot of ideas about where AI is going. There's this joke going around that Jurgen Schmidhwer basically invented everything back in the days and a lot of the kind of the later AI researchers just sort of copied his ideas without crediting him. There's this sort of a meme going around with Jurgen Schmidh Heber here sort of writing something and we have Jeffrey Hinton assume that's Yasha Benjio Yan Lun like all sort of copying him. And here's a post by him. He's saying everybody talks about recursive self-improvement and girdle machines now and how this will lead to a GI.

### üìù Ë©≥Á¥∞Ë™¨Êòé

Now he started talking about this concept back in 2003 and today or recently he casually drops this. Our Huxley girdle machine learns to rewrite its own code estimating its own long-term self-improvement potential. It generalized on a new task on sweet bench light matching the best officially checked human engineered agents. So you can kind of see this AI agent pulling itself up by its bootstraps or whatever that is a wire coming out of its head. So yeah, we literally have a research paper about self-improving agents with Jurgen Schmidt Huber as one of the authors listed on there.

### üí° ÂÆü‰æã„Éª„Éá„É¢

And it seems like they might have cracked one of the big questions or potential limitations about how this was approached in the past. And by the past I mean I guess the last year or so. Now early this year we've seen this research out of Sakana AI the Darwin Girdle machine AI that improves itself by rewriting its own code. It talked about this idea of kind of an evolutionary search, Darwinian exploration. So, it tries different agents to see how different modifications of those agents improve their ability to code.

### üîß ÊäÄË°ìÁöÑË©≥Á¥∞

And they had a great chart that I think really illustrates this really well. So, they're using the bench, a a benchmark about software engineering tasks, and the large language model. The AI, this agent kind of creates modifications of itself and tests to see how well that performs on the sweep bench and tries different approaches. You can see some of them don't work that well. Those are the red ones.

### üéØ ÂøúÁî®‰æã

And often times if it gets a bad result, that chain kind of ends. Whereas if a certain approach works well, well then it continues. So you can think of this as a lineage in a way that we would breed dogs or horses or whatever for certain characteristics. You can think of it as something similar. This approach exhibits some improvement.

### üí≠ ËÄÉÂØü

So let's continue with it until we get the best possible solution. You can think of these as sort of generations. Each new generation is kind of a an improvement hopefully over the previous generation. And certainly this is looking phenomenal. This is looking amazing.

### üìå „Åæ„Å®„ÇÅ

bots kind of a question that comes up is well what if this you know number one the first attempt it made as you can see here it wasn't a good one and so it stopped right this didn't have any lineage that sort of a family tree died out but what if we created a second and third and fourth iteration on this what would happen if we took all these dead ends and we allowed them to continue further is it possible that maybe initially the results would have been worse but over time that would have achieved the best possible outcome. Looking at this chart, we just don't really know. So, you're seeing something happening live and that is that a lot of things are going AI native. I built my first successful website in 2010. Back then, I used WordPress because it was 100% open- source, free, it powers 43% of the web, has a community of developers, thousands of plugins, SEO, and user management.

### ‚úÖ ÁµêË´ñ

Now, 15 years later, I still use WordPress for all of my websites. It's kind of hard to beat. So, when Tenweb announced that they were building Vibe for WordPress, I was pretty excited. Big thanks to Tenweb for sponsoring this video, by the way. But getting back to why I got excited about this.

### üìö ËøΩÂä†ÊÉÖÂ†±

This is Vibe for WordPress. It's the world's first AI native Vibe coding front-end builder that's fully integrated with WordPress. Gives you the creative freedom of Vibe coding. You can build any layout, animation or theme, both the power, scalability, and plug-in ecosystem of WordPress. So, let's see if we can create a website that talks about vibe coding and has a blog and a forum where community members can chat.

### üîñ Ë£úË∂≥

I type in my prompt, and seconds later, it has a suggested layout for the website with different page structures and various features that we might want on those web pages. By the way, you're not just prototyping. You're building real launch ready websites with a full CMS. That's a content management system, SEO tools, user management, and thousands of plugins all baked in. You can edit with AI chat, or dive into the code editor.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 13

Once you're done, just hit publish. All the important but sometimes boring stuff like hosting, domain, CDN, SSL, backups, and more. It's already handled for you. And here's the best part. You own your own code.

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 14

Everything's open source, portable, and yours to extend anywhere. No lockins, no limits, and there are some big features that are just around the corner for agencies, hosts, and SAS providers. Vibe will include a full white label suite. You can resell sites under your own brand or integrate creation via API. If you've been following this channel, you know that a lot of the big AI frontier labs are making possible to interact with e-commerce sites as well as apps directly within the chat.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 15

Why is that important? Well, some of the upcoming features for Vibe will include full Woo Commerce integration. That's complete support for e-commerce and for functionality to create apps beyond websites. So, if you've ever wanted AI power with real WordPress stability, this is it. Check out Vibe for WordPress and see how fast you can build your next site literally by chatting with AI.

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 16

Links in the description and pinned comment. Let me know what you will build. Here's Alex Duffy. We interviewed him recently. a great interview, but he's commenting on this saying, "Smid Heers team casually proving recursive self-improvement works at scale and it generalizes." Coding agents rewrote themselves hundreds of times until it matched human engineers.

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 17

You can't do it by benchmark maxing, but you can track agent family trees to find which lineages actually keep improving. The acceleration continues. So, let's quickly take a look at this paper and see what they figured out. So the Huxley girdle machine human level coding agent development by an approximation of the optimal self-improving machine. So it starts out saying that some recent studies show self-improvement through coding agents that can edit their own code bases.

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 18

They grow a tree of self-modifications through expansion strategies that favor higher software engineering benchmark performance. assuming that this implies more promising subsequent self modifications. And again, this is why I wanted to show the Sakana AI because while it isn't the only study of this nature, I think they did the best job of just illustrating everything in their blog post. Sakana AI, thank you so much. This makes my job so much easier.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 19

They really were able to explain everything in a very uh approachable way. So the point of that first kind of paragraph or few sentences that we read is this idea that the star we're saying that's the final best agent and it might be obvious or not but it's kind of we're assuming that right? So if this improved and this improved and like each step is an improvement and then you know everything that does not improve dies off then we say that this is the best one. But again, we have no idea what happens if we take this branch right here that got cut off that sort of went extinct, if you will, and we continue it, right? Does the the final step here or 20 steps in, we have no idea what that looks like.

### üìù „Çª„ÇØ„Ç∑„Éß„É≥ 20

We're assuming it's worse off than this one, but it really might not be. And they introduce a concept here. They're calling it the meta productivity performance mismatch. So metarroductivity is the agent's self-improvement potential. So what that means is let's say we take this agent that we're saying this is the final best agent and let's say this final best agent has a 100% improvement over the original kind of our our starting point.

### üí° „Çª„ÇØ„Ç∑„Éß„É≥ 21

So from here to here that's 100%. I'm just making it up so it's easy to understand. The actual performance was I think a lot better. And more importantly there's a lot of generalization between tasks. We'll get to that later.

### üîß „Çª„ÇØ„Ç∑„Éß„É≥ 22

But the point I think of Jurgen Schmidzer paper and other authors as well. I apologize if I'm kind of singling him out even though he's the last name on the paper. Meaning that he probably contributed the least actively to building that paper and played more of a advisor role so to speak, but he's the big name we're going with that. But the point is like let's say we continued this extinct sort of tree and we got another result and another result and another result and eventually somewhere here the results improved and the final sort of improvement over the original was 200%. So this difference between kind of what we achieved and what we could have achieved like if we imagine this is the best possible sort of potential performance.

### üéØ „Çª„ÇØ„Ç∑„Éß„É≥ 23

So this is the meta productivity to performance mismatch. By the way, in machine learning street talk, they interviewed the actual researchers that worked on Google DeepMind's alpha evolve project, which kind of is similar in some ways, at least in the sense that there's this evolutionary search for a better, more optimized outcome. And actually, that's one of the things that those researchers talked about that there's really no way or it's difficult to know which of these little lineages or generations, which one of those things might continue and become better over time or how many generations to run this for, right? If you achieve the certain result here or what if you continued 100 more generations, is that going to be better? And as you can probably imagine, everything costs money, costs compute to run this.

### üí≠ „Çª„ÇØ„Ç∑„Éß„É≥ 24

its time and hardware resources etc. So it's not like we can just run this infinitely. So while this sort of imaginary or theoretical result might very well be the best possible potential several improvements I don't know if we have an easy way to sort of understand or predict where that would be or where this kind of meta improvement/performance gap how big it would be. All right, so back to the paper. Huxley.

### üìå „Çª„ÇØ„Ç∑„Éß„É≥ 25

Who is Huxley? It's apparently Henry Huxley, often referred to as Darwin's bulldog, a staunch supporter of Darwin. And Huxley had this concept of Clay. By the way, every once in a while, I try to look up how to pronounce certain things. I mean, this was probably Clay.

### ‚úÖ „Çª„ÇØ„Ç∑„Éß„É≥ 26

I kind of understood that, right? But like this last name of Girdle, I I've I've I think I started pronouncing as God. I tend to read a lot because I think it's like the most compact condensed way to get information into your brain better than video or audio. I believe at least for stuff like this. So, I do have something that's sometimes referred to as like the reader pronunciation because you see certain words so many times you kind of say it in your head, but it might be different from how other people say it.

### üìö „Çª„ÇØ„Ç∑„Éß„É≥ 27

And doing these YouTube videos, I got to do the habit of making sure that I I try to pronounce things correctly. So, and not all sources of pronunciation are actually accurate. There's tons of misinformation online. There's a French gentleman on YouTube that so far is just phenomenal. You know, he starts out with a kind of a heavy French accent, but then always pronounces whatever it is, whether it's an English word or a German word, which is just flawlessly.

### üîñ „Çª„ÇØ„Ç∑„Éß„É≥ 28

But sometimes it takes a second to run the YouTube search. So, today I just quickly wanted to double check with Chad GPT to make sure I pronounce it correctly. And I didn't want to say the word just in case it said it in the same way that I said it. So I wanted to kind of give it a hint and have it say it out loud. So I asked it what is the concept sort of inspired by Henry Huxley that starts with the letter C.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 29

Here's what it told me. >> You're likely thinking of Thomas Henry Huxley who was a 19th century biologist often nicknamed Darwin's bulldog. One of his well-known ideas that starts with a C is the concept of agnosticism. He coined the term agnostic. So the well-known concept that starts with a C is his concept of agnosticism.

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 30

C for agnosticism. By the way, if you ever want to know why things like that happen or why these large language models have a hard time counting the number of Rs in the word like strawberry, for example, Audrey Karpathy does a great job of explaining it. It really comes down to how LM's see our words, how they see language. And how they do it is through tokenization. So each token is, you can think of it as almost like some weird emoji.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 31

It's not like it's seeing the same word that we do, it's seeing it in tokens, each token is almost like a a symbol, right? So when we ask how many Rs are there in strawberry, you know, the question might look like this to an LLM, right? So there's no Rs and no strawberry. And that's most likely also why it thinks agnostic starts with the letter C. Anyways, at the point it seems that the word clay was introduced by a German biologist, Julian Huxley, Thomas Huxley's grandson, in 1958.

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 32

And by the way, see if you can spot this pattern as you keep researching about AI and other things. How much of our AI research, machine learning, neural net, stuff like that, how much of it is mirrored from the natural world? A lot of the concepts we used, a lot of the the breakthroughs that we reach, they oftentimes have a very distinct sort of parallel to something in biology. And it does seem like this is no exception. So in the mid 1800s, many naturalists still thought of species evolving in a linear hierarchy from lower to higher forms.

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 33

So this is the same thing we saw earlier this year with Sakana AI and others where it's like okay each step is a little bit better. It's a step in the right direction. And Huxley argued instead for a branching evolutionary tree where species diverge from a common ancestor into different lineages. So the idea is to compare anatomical features like bones, skull and nervous systems to infer degrees of relatedness. So instead of a linear line of improvements, so from worst to best, instead we're trying to find some features from different ancestors in order to kind of estimate how good that lineage could be or how good future offspring could be.

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 34

So they're saying here so inspiring by this concept of clay we propose a metric cmp that aggregates the benchmark performances of the descendants of an agent as an indicator of its potential for self-improvement. So CMP is clayed meta productivity CMP and so basically they can use this metric the CMP to kind of simulate how well this girdle machine would behave under certain assumptions. So in other words, it sounds like they're able to kind of predict this theoretical tree or I guess branch, right? So we can kind of predict based on that CMP kind of where this could potentially end up. And so with this in mind, they introduced the Huxley girdle machine HGM, which by estimating the CMP, so again that kind of like offspring, future descendants, how good they could become over time, it uses that as a guidance and it searches the tree of self-modifications.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 35

And on related benchmarks, it outperforms prior self-improving coding agents and it uses less wall clock time, which just means real time. Like you time it and it takes less time. Last but not least, HGM demonstrates strong transfer to other coding data sets and large language models, which is extremely important. We don't want something that's very narrow in how good it gets. We want it to be able to generalize across languages and approaches, etc.

### üìù „Çª„ÇØ„Ç∑„Éß„É≥ 36

We want it to be getting generally smarter. And importantly, this approach measured on the SUI bench light with GPT5 achieves human level performance matching the best officially checked results of human engineered coding agents. So this kind of seems like it could be a big deal because if we have some formulas metric that allows us to estimate which one of those branches will lead down the line to the best result. Obviously that's kind of amazing, right? So we can kind of predict which paths to follow.

### üí° „Çª„ÇØ„Ç∑„Éß„É≥ 37

we can save both time and money on compute. And as I put here, a central challenge is how to decide which self modifications to accept. And so in recent implementations, we just use self modifications that have higher benchmark performance. So we're kind of looking at the short-term results and assuming that they will lead to the best long-term results. In other words, a high scoring agent may produce unproductive descendants.

### üîß „Çª„ÇØ„Ç∑„Éß„É≥ 38

And conversely, a lowercing one seeds lineages that achieve greater long-term gains. Right? So, we term this phenomenon the metaproductivity performance mismatch. This is also kind of crazy to think about now with a lot of the advances in AI and biotechnology because it seems very reasonable to assume that there are incredible biological features and modifications that we can make that are a lot better than anything that has been sort of evolved in nature because again to get you know through this tree through the lineages through the generations like you have to get better. None of these can be a massive step backwards.

### üéØ „Çª„ÇØ„Ç∑„Éß„É≥ 39

They have to be viable out there in the real world. Otherwise, they don't survive. So, there might very well be these weird things that were bad for a while and that got really good that that are not viable in the real world, but could be a lot better than anything that we've seen that evolved naturally. So, again, really fast, CMP, clay meta productivity, or it might be clay level meta productivity. They I think they refer to it as as both things.

### üí≠ „Çª„ÇØ„Ç∑„Éß„É≥ 40

But what it is is this. We have our original coding agent that is pretty good at coding. Our large language model, this AI attempts to add code that makes that coding agent better at coding. From the Sakana AI paper, here are some examples like more granular file editing via string replacement or auto summarize on context limit. So probably if we're approaching the context window the limit of that it sort of like summarizes everything so that we don't have to keep that entire context just the things that we need to carry into the next instance and you can kind of see the jumps these different additions make right so we add this boom that's the jump between the previous version and this one when we added this so let's let's say we added one strategy and it led to this agent this agent has a plus 10 point increase on the benchmark that we're testing it on.

### üìå „Çª„ÇØ„Ç∑„Éß„É≥ 41

Right? So, it it improved 10 points. Good job. This robot here or this coding agent here, we tried a different strategy and this one only improved one point. So, it's an improvement but not that exciting, not that awesome.

### ‚úÖ „Çª„ÇØ„Ç∑„Éß„É≥ 42

So, normally before this, we would continue this agent, the one that got 10 points because the short-term results were better, right? So, we continue and we do another one and another one and uh another one and maybe got plus 10 points here and plus 10 points here, right? So, it's uh plus 30 points total if we run this little branch. My head's in the way here. Plus 30 points.

### üìö „Çª„ÇØ„Ç∑„Éß„É≥ 43

But what we didn't know because we didn't run this side of it is if we kept going with this is maybe this first iteration was bad but once we kept building on it maybe this one started getting plus 50 points plus 50 points right? So this third iteration had a total of 101 additional points on the exam whereas this one had only plus 30. So how was done in the past it was limited by a few things. one each time we would run this sort of next generation we would stop and we would evaluate this agent and this agent right so we'd run these two be like okay how many points did you get how many points did you get then we'd cut this one and we'd go here and we'd run this one and be like okay how many points did you get now we'd run this one and be like okay how many points now with this new approach CMP kind of estimates how likely we are to get a better agent if we keep running this lineage the other advantage is we don't have to do the evaluation every single a step. So we might run these two evaluate and then based on that it might say okay run these for three iterations run this for whatever number of iterations and then test the final one.

### üîñ „Çª„ÇØ„Ç∑„Éß„É≥ 44

So we're not testing it aka evaluating it every single time. And here's their clay metar productivity estimator. Here's the formula for that. And again we're trying to find the estimated performance of the [clears throat] best performing descendant in that lineage. And at each iteration, the algorithm first selects whether to evaluate or expand.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 45

So previous methods have evaluated newly created agents directly after their creation. Right? So you try it, evaluate it. This new approach has the additional benefit of collecting more samples more quickly. So you can run the expansion longer and evaluate as needed.

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 46

And finally, what were the actual results? How well did it do? Well, here's a comparison on two benchmarks, the SV Verified 60 and Polyglot. both very well-known coding benchmarks and interestingly DGM. So that's the Darwin Girdle machine from Syana AI that we've been uh talking about.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 47

So this is actually a a great comparison, right? So this is kind of apples to apples. They're doing similar things. So notice there's a modest improvement in HGM, right? The Huxley girdle machine versus the Darwin girdle machine.

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 48

So again, this is a Sakana AI and this is the new one that we're talking about. So it had an improvement, but also notice it took a lot less time. It's a lot less expensive. Same thing on Polyglot. It has a good noticeable increase in how well it performs and again much much less time to run than the previous ones.

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 49

The HGM also surpassed the best human design agent built on GPT5 Mini on the SU verified leaderboard. It's the top scoring GPT5 minibased system and it's the top 10 even when compared against other systems with much more expensive models. Some of them costing five times more like Claude 3.7. These approaches generalize well. So it's not that it's just getting good at gaming this benchmark that it's like just overfitting on the benchmark and figuring out how to crack it.

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 50

It transfers to other models as well. So if you take these agents, you use them on a bigger model, it that still transfers. So very interesting findings. You know, in conclusion, they're sort of proposing this as a kind of a good and effective approach to building these self-proving models. Definitely the idea of kind of predicting which lineage will down the road produce the best performing agent is very exciting.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 51

It's also interesting that it has some parallels to biology to the natural world. It's exciting to see Jurgen Schmidt Huber his name appearing on papers relating to this. So kind of an an interesting approach and an interesting little paper. So let me know what you thought about this. Is this interesting, exciting?

### üìù „Çª„ÇØ„Ç∑„Éß„É≥ 52

Do you think that approaches like this will get us to self-improving agents soon? Let me know in the comments. If you made this far, thank you so much for watching.

---

<div align="center">

**üìù „Åì„ÅÆË®ò‰∫ã„ÅØËá™ÂãïÁîüÊàê„Åï„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô**

ÁîüÊàêÊó•: 2026Âπ¥01Êúà06Êó•

</div>
