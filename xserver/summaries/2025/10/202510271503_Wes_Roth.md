# ğŸ“º AIãŒç­”ãˆã‚‹ã€Œç”Ÿå‘½ã€å®‡å®™ã€ãã—ã¦ä¸‡ç‰©ã€ã®ç©¶æ¥µã®å•ã„

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: AI answers the question of life, the universe and EVERYTHING
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=rrvI5EZhX58](https://www.youtube.com/watch?v=rrvI5EZhX58)
- **å‹•ç”»ID**: rrvI5EZhX58
- **å…¬é–‹æ—¥**: 2025å¹´10æœˆ27æ—¥ 15:03
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã§ã¯ã€Googleã®CTO Blaise AgÃ¼era y Arcasã¨ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’é€šã˜ã¦ã€ç”Ÿå‘½ã®èµ·æºã€æ„è­˜ã®æœ¬è³ªã€ãã—ã¦AIã®é€²åŒ–ã«é–¢ã™ã‚‹æ·±ã„æ´å¯Ÿã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚©ãƒ³ãƒ»ãƒã‚¤ãƒãƒ³ã®è‡ªå·±è¤‡è£½ã‚ªãƒ¼ãƒˆãƒãƒˆãƒ³ç†è«–ã‹ã‚‰ã€Brainfuckãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’ç”¨ã„ãŸç”Ÿå‘½ç™ºç”Ÿã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã¾ã§ã€ç”Ÿå‘½ã¨ã¯ä½•ã‹ã‚’è¨ˆç®—ç†è«–ã®è¦³ç‚¹ã‹ã‚‰æ¢æ±‚ã—ã¾ã™ã€‚æ„è­˜ã¯ä»–è€…ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹èƒ½åŠ›ã‹ã‚‰ç”Ÿã¾ã‚Œã‚‹ã¨ã„ã†ä»®èª¬ã‚„ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–å­¦ç¿’ã®æœªæ¥ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã¦ã„ã¾ã™ã€‚AIã®ç™ºå±•ãŒã€ç§ãŸã¡ã®å­˜åœ¨ã®æ„å‘³ã‚„å®‡å®™ã®æœ¬è³ªã‚’ç†è§£ã™ã‚‹æ–°ãŸãªæ‰‰ã‚’é–‹ãå¯èƒ½æ€§ã‚’ç¤ºå”†ã™ã‚‹ã€çŸ¥çš„å¥½å¥‡å¿ƒã‚’åˆºæ¿€ã™ã‚‹å†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **ãƒ•ã‚©ãƒ³ãƒ»ãƒã‚¤ãƒãƒ³ã¯DNAç™ºè¦‹å‰ã«ç”Ÿå‘½ã®ä»•çµ„ã¿ã‚’äºˆæ¸¬**ï¼š1940-50å¹´ä»£ã«è‡ªå·±è¤‡è£½ã‚ªãƒ¼ãƒˆãƒãƒˆãƒ³ã®æ¦‚å¿µã‚’æå”±ã—ã€å¾Œã«ç™ºè¦‹ã•ã‚ŒãŸDNAã®æ§‹é€ ã¨é©šãã»ã©ä¸€è‡´ã—ã¦ã„ãŸ
- **Brainfuckè¨€èªå®Ÿé¨“ã§ç”Ÿå‘½ã®å‰µç™ºã‚’å®Ÿè¨¼**ï¼šãŸã£ãŸ8ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ãªã‚‹è¨€èªã§ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰ç•°ã‚’ç¹°ã‚Šè¿”ã—ãŸçµæœã€ã‚«ã‚ªã‚¹ã‹ã‚‰çªç„¶ç§©åºãŒç”Ÿã¾ã‚Œã€è‡ªå·±è¤‡è£½ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå‡ºç¾ã—ãŸ
- **æ„è­˜ã¯ã€Œå¿ƒã®ç†è«–ï¼ˆTheory of Mindï¼‰ã€ã‹ã‚‰ç”Ÿã¾ã‚Œã‚‹**ï¼šä»–è€…ã®è¡Œå‹•ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«ç›¸æ‰‹ã®å¿ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ãã®éç¨‹ã§è‡ªå·±èªè­˜ã‚‚ç™ºé”ã™ã‚‹ã¨ã„ã†ä»®èª¬
- **ç¤¾ä¼šé›†å›£ã®è¦æ¨¡ã¨è„³ã®å¤§ãã•ã¯ç›¸é–¢ã™ã‚‹**ï¼šã‚ˆã‚Šå¤§ããªç¤¾ä¼šã§å”åŠ›ã™ã‚‹ã«ã¯ã€ã‚ˆã‚Šè¤‡é›‘ãªå¿ƒã®ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã¨ãªã‚Šã€è„³ãŒé€²åŒ–çš„ã«å¤§ãããªã£ãŸ
- **Googleã¯å¤šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–å­¦ç¿’ã‚’ç ”ç©¶ä¸­**ï¼šè¤‡æ•°ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”åŠ›ãƒ»ç«¶äº‰ã™ã‚‹ç’°å¢ƒã§ã€Theory of Mindã®ã‚ˆã†ãªé«˜åº¦ãªèƒ½åŠ›ãŒå‰µç™ºã™ã‚‹å¯èƒ½æ€§ã‚’æ¢æ±‚ã—ã¦ã„ã‚‹

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

All right, we got quite an interesting show for you today. This is going to be a little bit shorter than our long form interviews, but we want to talk today about life, the universe, and everything. We're going to reveal to you the meaning of life today, basically is what we're trying to say. Uh, how's that for a clickbait title, but um but basically I always had this suspicion that or and I thought I didn't know if suspicion is the right word, intuition, suspicion or just hope that as we discover more and more about AI that somehow it's going to allow us to understand the nature of reality better of of consciousness of what the point of existence is. It just felt like somehow our progress through AI will open up the gates to understanding everything a lot more.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Dylan, I'm wondering, did you ever have that feeling or that just me? >> You know, when I say like I'm curious about intelligence and AI, it pretty much always comes from that fundamental curiosity. I couldn't imagine a time in history where we've learned more about what it means to understand ourselves. And the tools that we have now are giving psychologists these amazing ways to think about the human brain and the the nature of consciousness and our role in the universe and the way it all connects to physics. I think about it literally so much that it I have trouble sleeping a lot.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Yeah, that that makes sense. And um for me like I I I always had that curiosity and then when I heard a lot of the machine learning researchers also say things that sounded like maybe they kind of share that belief at on some level I was like okay it's not just me being crazy. This There is something here and uh I listened to machine learning a street talk. They had an interview uh this is the last interview a couple of days ago and it absolutely floored me. So the guest was Lace Agueroa E Arcus.

### ğŸ“ è©³ç´°èª¬æ˜

He is the CTO of technology and society at Google and what they're up to is kind of wild. And so today I just wanted to kind of briefly kind of go over that and I might do another video going deeper in it. I think everyone should watch should watch that interview because it's absolutely phenomenal. But here's kind of like some of the stuff that that he initially talked about. So, and I apologize if I get some terms incorrectly.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

I'm I'm kind of deep into researching this stuff and trying to understand it. But, so basically, I guess Von Noyman back in the days, apparently one of the smartest people uh ever according to some people, he had this idea for a self-replicating automaton robot. And this is I guess must have been what in the what what year do you think that was? Like 40s, 50s. >> Yeah, probably somewhere around there.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

>> So, he was trying to imagine a robot. let's say it's made out of Lego pieces, like what would it need to have to be able to go out there and find more Lego pieces and create versions of itself? And he said, well, it would need to have I mean, you know, the Lego pieces, it would need to have a tape cuz a tape like in order to write on a tape, that's how computers were back in the days. Keep in mind, this is like 40s, 50s, etc. So a tape with instructions about how to build itself, how to build a replica of itself.

### ğŸ¯ å¿œç”¨ä¾‹

And it would also need something that would able to print that tape to to make another tape. Right? So basically what you do is you um get the Lego pieces that that you need to build another robot. You give it a copy of the tape that you've printed and uh you have a perfect replica. And that replica can now go and replicate itself all over again.

### ğŸ’­ è€ƒå¯Ÿ

if that makes sense. Now, of course, what does that sound like to you? >> Well, to me that sounds like the beginning of life, right? You have the kind of RNA world hypothesis where you end up getting these amino acids to kind of naturally just in a sense sort of magnetized to each other. They have a little bit of stickiness and a pattern that they fall into.

### ğŸ“Œ ã¾ã¨ã‚

And then you end up with kind of something that feels like a tape. It's a long string of information um with the four nucleotides. And then you end up eventually getting these proteins that read from it and you get something very similar to how these early computers were. >> I mean that's exactly I was that that was exactly kind of my thought. I was like okay so he's kind of describing DNA.

### âœ… çµè«–

What's the big deal? The big deal is we didn't discover DNA till later. Watson and Crick all of that that came later. So he what guessed I guess at the at at how DNA functions and works before we discovered it because he was like well if I was to build a selfreplicating robot this is how we build it and later it's like oh yes that's also how you know nature sort of decided to um go um anyways so I just thought that was kind of interesting. I'm glad that yeah, you also went kind of the DNA route, but is it mind-blowing that he sort of jumped to that conclusion before we discovered DNA?

### ğŸ“š è¿½åŠ æƒ…å ±

>> Yeah. And and you know, it's not that it has to be a long tape of things and it has to be like a physical kind of thing moving from left to right reading it. But you can start abstracting those concepts into more modern-day computational methods. I mean, computers are still made of components and, you know, you hear about long-term memory and short-term memory and the actual processing of it and then the bandwidth of moving things around and there's still many general analogies that still fit that role. Yeah, we a while back we were talking on a podcast and you mentioned something like um you know the the earth in the beginning there was just nothing happening and then at some point DNA was almost like a save game feature.

### ğŸ”– è£œè¶³

It was like memory, right? we were able to save some data. That's kind of uh everything changed. So, this is well, the stuff that they're talking about is is a little bit similar to that because yeah, it almost it almost works as a a way to to save data and potentially even replicate data. So, going back to Bla1 Aera E Arcus, I hope I'm I'm saying his name right.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

Uh so he did this experiment and this experiment involved um a programming language called brain and I think we should just probably refer to it as BF moving forward or brain freak whatever just so YouTube doesn't get too upset with us. Um have have you heard about this language before? >> I have not. This was the first time >> I've heard the name but I I had no idea what was special about it basically. And uh if I get things wrong, I'm sure everybody's going to correct me in the comments.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

So, which is which is great. I appreciate that. But basically, there's this idea of a touring complete language or system. And all that basically means is that you're able to run any sort of calculation on that system. You're able to run any algorithm.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

So, for example, any modern computer with, you know, if you're able to use programming languages, it can do that. It's during complete. Whereas if you think about like a calculator, it's not. There's just not enough stuff things you can put in there to be able to run anything, right? It's limited in some way.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

And so, you know, this brain freak language, this was developed, I think, in the '90s by some grad student who was like, okay, what is the minimum number of commands this language needs to have to be touring complete? Uh, and he created this language and it has eight commands. So literally like just eight charact it has eight characters eight which is bizarre right and so basically with this language you can create any calculation any algorithm etc uh it would be incredibly tedious but you could do it and so blaze and I don't fully understand exactly what he did in order to um set up the experiment but I guess what he did is he created a short tape um and these little pluses and greater symbols. These are the eight characters in brain f that is able to one like moves the thing upward and one increments it by a bite and one goes to the end. And so he basically created this sort of tape that randomly shuffle through these things and recreate them and and put them back.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So it's something that would sort of simulate slight changes in the structure. I got to think about how best explain this. I I don't fully ex I I want to really go back and dig deep and understand how he did this experiment. So this is just kind of a higher level of it. And so basically and he just let the experiment run and for millions of iterations it was random.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

I mean this was kind of like the output is just random. It just random digits, random numbers. There was no sense to it. It was um sort of just high chaos, no order, so to speak. And then something weird happened somewhere.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

You can see it kind of like right here on the screen. As you can see here, it went from just as he said, entropy rapidly collapsed. So in other words, just there was complete chaos and all of a sudden it went to highly highly ordered very very quickly. As you can see here, massive drop. And he's saying that what is this?

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

This this is life. This is like life, the emergence of life, so to speak. Uh what does that mean? Well, what happened was somewhere in there through random chance, through random permutations, uh, out of out of meaninglessness emerged one little thing that was able to self-replicate and it started self-replicating and every time there was something else, a symbiotic self-replicating organism or whatever you want to refer to it as, like sometimes it would combine. And so over time and very very rapidly, we went from meaninglessness to ordered structure and these algorithms that were non-trivial if you were trying to like replicate them.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

Um, and he's saying this is kind of the reason why life emerged on on Earth and maybe in other places because it almost seems like it's somewhat built in to the universe. Let me stop right there. Like is this does that make sense to you intuitively? >> Oh, does it? Yeah.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

>> Yeah. Yeah. No, I guess I have to say no and no. It doesn't make sense to me intuitively and sometimes it doesn't even make sense to me, but I've seen enough examples that I know it is something that happens. Conway's game of life is a simple sort of checkerboard style game and small uh lines of code or or equations or simple rules.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

You could even write them in any format that you want. Repeated hundreds, thousands, millions of times, create incredibly complex um patterns that that look a lot like biology. Oh, okay. So, this was in the video, too. >> They they did briefly mentioned it.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

Yeah. >> Yeah. Yeah. And you know, this has stuck with me for a long time and and I do now when I walk through nature see the kind of rhythms in the the leaves and the ground and sort of the organic nature of the world has all these different sort of patterns built into it. And we see in biology all these things.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So yeah, I don't think it's incredible to think that from chaos just the tiniest little pattern, the equivalent of the equation that can make a Conway's game of life creature mostly does nothing and sometimes does something really amazing that defies entropy. >> Yeah. And it's such a wild thing to think about because at some point he posed this question like what's more durable like a like a granite or or DNA? And DNA is of course like a strand of DNA. And DNA of of course is very fragile, right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

It it'll can be smashed. It can be burnt. Like it it will easily destroyed. But his point was over time the only thing that the ground can do is collapse into dust. Like given enough time it becomes nothing.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

DNA can technically be around forever because it can self-replicate. And so this idea that, you know, everything kind of like the universe goes towards stability because the things that can self-replicate are the most stable. They're the most likely to to survive. And this is just really weird to think about because and and I've mentioned this on on on podcasts before, you know, AI, what we've realized with AI is is for for most of science fiction, if you read science fiction books back in the days, everybody thought that AI is going to be this super complicated thing that humans build, you know, and there this is going to be just a lot of like advanced logic and like we're going to engineer it similar to how we engineer a rocket ship or a Formula 1 car or whatever. ever.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

And now it emerges, we're like, "No, that's not really how we're how we're building it. We're building systems that pro intelligence." Like, we don't really know even what's what's happening exactly within those neural connections. We just we're scaling up the infrastructure that builds it. But it it's similar to how bacteria grows in the petri dish or how you can grow mushrooms in a lab. It's something that is grown, not engineered.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

>> Right. And maybe I could add to that when you think about a virus that has successfully survived for as long as bacteria has like for billions of years even without high intelligence it's because it can copy and it can copy itself many many times and then it evolves to be stronger. So just the idea of any information that can copy itself and evolve to the changing environment is kind of almost unstoppable. And then we're just in a few cases, and this is where things get really interesting about where the future's going to go, where we see a little bit of intelligence emerging from an organism that it can actually protect it. So we as humans have DNA and it's, you know, vulnerable on its own, but as a whole, the species has all sorts of different copies of it and and the human, you know, basic blueprint is in all of us.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

But now we also have the intelligence to control the environment to like build a house to protect us from wind and and and tigers and all these things that used to kind of stop some of those patterns. There's error correcting code that you can write which isn't about making the code any different. It's about protecting its integrity. Humans have arguably kind of done some error correction on our DNA by creating an environment where we can thrive and we control our environment where we have food and we have all these things that normally would be kind of at risk there. And now intelligence itself in the form of a neural network on some system like Gemini or Chad GPT can now sort of notice itself too or at least that's starting to emerge and it's a whole another level to how this is all playing out.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

And later in the video, they talk about exactly that. And they talk about how potentially consciousness emerged and how how he explains it. Again, I was just absolutely floored by this interview because so many it's amazing to think about that this guy could be just right about everything because a lot of it just fits in so well into everything that we're learning. Um how he was saying that consciousness emerges from being able to model other people. other people or things that you care about.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

So, if you think about it this way, like let's say there's a a tribe of people or monkeys or whatever you want to think about, in order for them to be able to cooperate, like I have to predict what like if we're working together, I have to kind of predict what you think, what you're going to do, what you would be interested in, etc. Like, I I kind of have to have an idea about I would have I would have to model your mind in my mind, so to speak, to be able to work with you, etc. At the same time, in order for me to be able to do that, I kind of have to model myself as well, my own mind. Like, what am I going to do? If I do this, what is Dylan going to do, etc.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

And if you think about it, the more complex the interactions, the more complex the brain has to become. And in a different talk that I watched by Blaze, I think he gave a TED talk, let me pull up the image really fast. So, I'm not sure if this is the image that he used, but I think maybe kind of represents the same thing. So we're talking about the social cortex, right? So the average average social group size versus the size of the brain, right?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

So basically the bigger your squad is, so to speak, the the the bigger your society is, brains, the size of the brain tends to to correlate to that. So it's almost as if to say that in order to be able to coexist in in a society and understand other people and be able to function with a lot of other people. We have to sort of level up our brain and make it bigger. If you think about it, the ability to model your own brain, right? So if you're thinking about something like, oh, I'm nervous about giving a presentation, you can also have uh you can you can also realize that you're thinking you're like, oh, I'm realizing that I'm thinking that I'm nervous about this presentation.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

and you can sort of do a lot of these like self-reflective loops in order to like truly understand yourself. But um I think the point is he's saying that's where consciousness emerges, >> you know. Sorry. No, no, no. Go ahead.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Yeah, this is interesting because before I drop the bomb, go ahead. >> Okay. So, you know, I just have to think that that feels pretty intuitively correct for me because theory of mind makes sense. If you're a more simple creature and you're seeing your competitors, other versions of you, other humans, other whatever, you know, going back in time, you would whatever animal you are, you would start saying, "Okay, it's important if I can predict what that other one is going to do because then I can maneuver to the food before them or I could understand uh what they're going to do." and that would mean more offspring and then you would get even better at it and start thinking about cooperation like cooperation could kind of emerge from that too saying like actually there's a way that we can get more food if we work together. I can see how that sort of would have evolved and then also as an experiment I tried a couple years ago when I was learning about theory of mind for I guess maybe the first time or us really thinking about it deeply for the first time.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

It's also very hard to put yourself in someone else's shoes and be in your own mind. Like there's something and you can just take at home just experiment with this. Like imagine yourself in the shoes of your partner looking back at yourself and asking a question like would that person be angry or or did something I say offend someone else? Imagine yourself as them. Almost by default like you can't be in your own mind.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

It just it feels like the duck or um the rabbit image if you've ever seen that where your brain can kind of only interpret one at a time. There's something about theory of mind that feels like I can either be in someone else's shoes or I can be in mine but not at the same time which tends to give me more evidence that this is kind of right. >> Yeah. Yeah, it's almost like we're accessing a separate part to recently I've been reading a lot more about the default mode network in the brain which has been absolutely fascinating because you know we have different parts of our brain different networks to get access depending on what we're doing right so there's like the task positive network I'm forgetting all the names there but basically like if you're doing something that one area of your brain lights up and depending on what you're doing different areas of the brain light light up but when you're not doing anything when you're not engaged in a task, the the the brain kind of goes into its default mode network. Now, you'd think that means that it sort of is idling, so to speak, right?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

It kind of calms down because you're not doing anything. And it's actually quite the opposite. Often times, it burns more energy. It's more activated, which is weird. And so we believe that that's the part of our brain that takes all these different things and it kind of like makes a coherent representation of yourself.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

It's the thing that makes you who you are. It's like, oh, this person said this about me. How does that fit into my model of myself? It like integrates all of that into one. So the default mode network is the thing that allows you to model yourself.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

And so when they ask you deep questions like, okay, what would you do? What would you do in this sort of ethical thing? the default mode network is the thing that lights up because it's like okay what would I do? So that's the thing that models us based on all this other stuff. I kind of thought that was mind-blowing.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

>> Yeah. >> Um you know to just to build on that there is um and I'm covering that this in my next video but there is some anthropic research from just last week where they're looking at long-term memory and how to make it so the models can actually uh think longer term. They can plan further ahead. you know, sort of one of the weaknesses of all the LMS right now. And in reality, the best solution so far seems to be that you teach the current model about its history in the same way you would put data into the model in the first place to train it.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

But if you think about that and you kind of compare it to us, that would sort of imply that when you think back to like Wes Roth from 5 years ago or seven years ago, you've actually just learned that history, but it's all just generated like in the moment. And it seems like that's the way these models will be. They'll be on servers and you spin them up and they wake up and whatever memory they remember, they remember as if it was all kind of one coherent thing. And it makes me always wonder if every time I think about myself, am I just accessing the knowledge of myself in a way that feels like the past, but it's not a written record. It's not a database of of things that I've done.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

It's not a database of of even information that anthropics claude models will be remembering. Like they'll have learned it and it will all be happening reconstructed in that moment. Yeah. And it's to that point, have you ever just looked at your past? If you were just like maybe in a bad place, feeling a little bit depressed or whatever, or or the opposite, like feeling super happy and just energized, looked at some point of your life in the past and had a completely different meaning drawn from those memories.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Even though it was the same thing that happened, you experience it or or give a brand new meaning to it just cuz you're feeling different. >> Yeah. Absolutely. And it seems like sometimes when you're um in a certain emotional state, it's healthy to look back on some of the things that were bothering you because yeah, you can say like, okay, like actually I learned a lot of lessons from that and I can now put it in the past and then I've had the exact opposite where I've been in a bad mood and been like, yeah, that tiny little thing is a really big problem and I need to go address it and it was just a waste of energy. >> Yeah.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

Oh man, there's there's a lot here to unpack. I mean, we're an AI channel, but this cuz this is going into psychology, but again, I always believe that AI will also illuminate kind of how how we think, how our brains, how the system of the human being works, what our consciousness is. One of the most interesting um thing I I've brought this up so early when when I had the the Chad GPT moment and then seeing GPT4 which was just a scaled up version and how much better that was. That was one big piece of the puzzle for me that was like okay AI is here and it's going to be massive. The other piece was this little research out of Open AI.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

they were doing um they they taught four agents, so two teams of two to play hideand-seek, right? So one of them were the hiders, one of them were the seekers, and they were using reinforcement learning to teach them. One thing that was really stood out to me was that and and obviously you could see them getting better and better at playing this game. But if you read through this, one thing that becomes apparent is it's a kind of a step function. It's an intelligence arms race.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

So when the hiders figured out how to block the doors, their rate of winning went up, but then the seekers figured out how to unblock the doors or whatever, right? And then their rate of winning. So it was like this climbing sort of um arms race, I think, would be a good way to put it. So it wasn't like they were both getting smart at the same time. No, when one got better at something, the other started losing and they had to find a strategy to overcome that.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

Yeah. You know, here's another interesting example that you might um not have heard. Stop me if you have. But if you go back to our common ancestor, um humans, bonobos, chimpanzees, we all have a common ancestor from whatever probably four million years ago or something like that. Um and at that branch, you can see sort of where hominids came and sort of branched into all these like human homminids and and eventually us.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

And then the bonobos and the chimpanzees stayed connected for a while. And then they branch off. And the main difference over their whatever many years, maybe half a million or so, is the environment they were in. Right? So there is like this big mountain range.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

Some of them uh the the ancestor of the bonobo and the chimpanzeee end up in a a lush forest where there's lots and lots of food. Another group of them end up in a much more food scarce environment. And what you end up with is very different culture. So bonobos uh are just sort of famous for how much they have sex to, you know, kind of like Yeah. like repair bonds.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

Um females in that society have much much much more power. They're much less violent. Chimpanzees have an incredibly aggressive um sort of hierarchical structure. The alpha and is very clearly defined. the people all the way down the rungs are clearly defined.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

Um there is intelligence where people group together to sort of overthrow the people on the top and then they're rewarded. And it's just a much more kind of violent and and interesting system when you compare it to the fact that in a scarce environment sometimes law and order and like strictness and a more military style solution as a group is better for evolution. That created more genes, more copies of the genes. And when fruit and food is just abundant, and this is no fault of either of the two species, they're just on different sides of the mountain and there's just different uh different rain patterns. There's different like vegetation.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

There's just different food. Then bonobos end up kind of with a more sort of female oriented leadership where um the females are mostly mating with the males that are less violent, that are not hurting them, that seem safer, that seem more secure because they're not scared about food as much, right? Like food is not playing as much of a role in mating. So then yeah, it just leads to all these societal changes that you can kind of see in that example where the hiders and the seekers are are jockeying for a position and the environment itself is the main factor in how that evolves, not even the decisions of the individuals. >> Yeah.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

One thing that you mentioned that kind of um maybe a little bit earlier is you talked a little bit about viruses at some point. Interestingly, in the conversation, they did talk about how I mean, a lot of our DNA, when we finally got our DNA, the genome sequenced, they found a lot of junk DNA. So, stuff that we didn't know kind of like what it coded for. Seems like a lot of it is viruses, viral DNA that got somehow added to our sort of DNA. And some of it apparently provides crucial function.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

Apparently the placenta uh when when when humans are g giving birth the placenta that was a viral addition. I've never heard of that before uh but kind of blew my mind. The other thing that they were testing is they're testing in rats or mice. They they removed a certain viral DNA that was in their DNA and they lost the ability to form memories. So the name of that interview uh so machine learning street talk they're split testing subtitles AP testing subtitles one of them is like this book shows why Darin's theory of evolution was wrong and certainly after listening to that again I don't want to jump the gun because I I haven't done the research but man it just intuitively a lot of it makes sense to me because this might describe life and how things evolve much more clearly.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

>> Yeah. Wow. That that's a really interesting example. I hadn't heard that and that is going to stick with me. the you know the the story of memory and evolution in humans when we really come to a theory of of us like of consciousness I think it will have to include all of these all these different forms of memory like there is um there are around each DNA there is these these histones and these histones are little proteins where the DNA can be folded and if it's folded upright then it's like taking a book in a page and folding it in half and then you read the sentence in a different way cuz Now you're reading from page one to page three because there's a fold in the page and that's kind of a different story and DNA seems to be able to be read in all these different ways but then the DNA so the story itself matters like how the story is read matters and those histones can be changed throughout your life so that's why it's epigenetics and you do have control over those so your decisions matter there if oh gosh what's that one there's a somebody who's working on bioelectric memory god I wish I remembered his name right now but yeah it's sort of like cells have the ability to sort of remember these like electric gradients and the way they've come together to fight off immune system cells before they seem to have their own types of memory and there's probably another million examples of the way the body has memory.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

There's the vyro that is all in our environment that our body's been constantly like taking some of the DNA and then keeping that in us for like later protection. But then again, maybe some of those functions were helpful. There's symbiotic relationships with the mitochondria in the cell that have like evolved in these strange ways. So the whole thing along with the neurons in our brain is going to be part of yeah just part of the story you know and they're all different types of memory and they can be comparable to CPUs and GPUs and processors and yeah we're just going to have to think really differently about this whole thing and how broad it is soon. >> Yeah.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

So so so Dylan hasn't had a chance to to watch this interview yet. Dylan, this is gonna blow your just everything that you're saying >> really when you watch this thing, I think it's going to blow your mind because wow, because I think we think about a lot of the same stuff and this to me really gave me just more placed some puzzle pieces gave me the missing sort of puzzle pieces because um just what you're saying this idea of uh synergistic what was the word that you used where it's like >> symbiotic. >> Yeah, sorry. So yeah, he he had a spec specific um blaze is talking about biological symbiotic relationships that make it easier or or more likely that certain organisms certain self-replicating molecules replicate better, right? So just like what we saw with that where there was just complete uh chaos and then you start these self-replicating molecules at one point and then quickly it goes to almost like order, right?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

So that's not just because one replicating molecule just made billion copies of itself because every once in a while what you notice is that these symbiotic so one self-replicating molecule and another one they're symbiotic and when they combine they make even a better ways of being able to self-replicate. And so we're seeing this viral addition to the human genome which is the ability to make a placenta. Um what does that do? Well, probably allows the a longer gestation period or whatever of maybe a large brainial capacity. How does that affect that organism's chance of survival and reproduction probably goes through the roof, right?

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

It probably really like you're able to have smarter babies. I don't know if that's the case or not, but obviously it improves the ability of it to replicate somehow. So, guess what? The human DNA or our ancestors, whatever, right? plus this viral thing that allows for the placenta to form makes this little chunk of code that much more potent and that much more able to replicate.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

Um, and if you think about it, that makes a lot of sense from kind of an an evolutionary perspective. So, um, going okay, so based on everything that we've talked about, so this idea that that that specifically like how consciousness emerges. So when we're able to model other people and the bit bigger our brains are the better we are able to cooperate the better not just cooperate but also you know if you're in war with somebody also being able to model them uh just any sort of interaction whe it's peaceful or or or negative or whatever um creates this larger brains and a better ability to make decisions better ability to work together in groups. So based on that and based on everything that we've talked about, if you had to guess what they're working on, cuz keep in mind Blaze is at Google. He's a chief CTO at Google in a in a division and they're working on something that's AI related.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

I mean, if you had to guess, what do you think they're working on? >> Uh, so yeah, I haven't seen the video. Can't imagine, but let's just assume that theory of mind is part of it. I mean, my guess would be that there's some kind of an evolutionary uh system built where a whole bunch of agents, a whole bunch of uh, you know, Gemini 3.0's are in an environment and they're trying to solve a problem and there's some kind of evolution mechanism where the winner goes on and the weights from that model become like the new baseline and then they do another competition and the weights from that model become the new baseline. So, something like reinforcement learning but the entire agent evolving.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

It's my guess. I have no idea. >> You're spot on. This is it >> or you tell me. Yeah.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

So, I don't know >> that. Yeah. No, I'm I'm I'm just genuinely surprised cuz Yeah, we for for the w for the audience didn't like plan this ahead. I'm just I'm just spraying this stuff on him in real time. I think your intuition is 100% right.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

They're not um of course sharing all the details. So, a lot of this is conjecture, >> but I mean he did say the phrase I believe it's multi-agent. It's reinforcement learning with multi- aent um some sort of >> guy probably makes a million dollars a year as a paycheck, you know, and I make like a grand from YouTube. >> Yeah. No, I I I I'm sure that that person gets paid a lot and he gets paid a lot in Google um Google stock options which is it's interesting because Gnome Brown who used to work for MetaF Facebook on their AI side uh he's behind Cicero and a lot of the Meta stuff he went over to um he went over to OpenAI and recently maybe four to six months ago he did mention what he's talking about which is exactly the same thing that sort of reinfor enforcement learning for multi- aent frameworks or there's some specific terminology but it's many agents reinforcement learning um and so there's kind of trying to figure out how to make them work together with cooperation or not cooperating but it seems like everything that we've talked about theory of mind um you know trying to model other people's sort of what they're going to do this very likely we will see some pretty big breakthroughs and this very likely the next big thing now.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

>> Go ahead. >> So, was theory of mind the objective function? Is that what he's saying? Is like the agents are competing over which one can accurately predict like a person's decisions? >> Is that what lets them move to the next round or did he >> I don't think so.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

>> Oh, he did not talk about that. And I don't think that um cuz I I I don't know how much of this is really announced by Google yet because this is the first time I'm hearing of it. So I I don't think as far as I can recall there's no specific details and I don't think theory of mind is the sort of objective function. I think that's the thing that emerges as you try to get these agents to be great at cooperating right because how do you get things to cooperate like you almost that's like an emergent thing you're like oh I I if I know what you want I can better like I'll give you this if you give me that because I want this. But in order to even have that chain of thought, you would have to understand what you want.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

You have to model yourself. You have to model the other person. Um, and so right now Chad GBT and the model, they probably have some semblance of theory of mind because they kind of have to understand what you want, right? They kind predict like, oh, what would the user want? Oh, I think the user might want something like this.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

Um, some maybe that's an illusion or but it's some semblance of it. Um, but in order for it to expand, you would have to have that kind of reinforcement learning on multi- aent. I wish I remember exactly the terminology they use, but that's that's that's what it is. >> Yeah. Well, I mean, sometimes, you know, I didn't really think this way until about a year ago, but when I try to predict 2030 um and the and the future, I used to kind of think like, all right, what does a world with a super intelligence look like?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

I'm a dog. It's a human versus, you know, comparatively. And like how much smarter is it? What does it do? Does it fix like the food system?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

Does it like run our government? But then you have to start thinking about it like differently. You have to think, oh actually this is going to be like this whole evolving ecosystem, this whole marketplace of AI agents. And there will be there will be literally millions, billions, trillions of different agents, right? Like there'll be one on every laptop, one on every phone.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

And there'll be like on these cloud servers as many as the companies want to build and group together to solve problems. And there'll be military ones and there'll be therapy ones and there'll be all these different things. And the the ones that are bad at therapy and the ones that are bad at military and the ones that are bad at every other aspect of logistics and their deployment will be cancelled and the next ones will kind of replace them and they'll evolve to become better and better. So that makes the future even more unpredictable. But it kind of leads to a world where there's much more of that kind of tussle where like some like some models are pulling society this way and some this way and like we're kind of clamping down on this and we're encouraging this and you know different countries and different things are all sort of playing playing out together.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

>> Yeah, it's I mean that whole thing is going to be fascinating to me. What really affected me by this interview is the fact that it seems like life formation is built into like the reality of the universe and intelligence is is built into kind it's like a foundational thing just like you know gravity and other laws of physics and stuff like that and just as we continue as as as Blaze himself says like life is computational. So a lot of this stuff like it's not an accident that we're here. It's kind of just what we expect to happen. Um, and the formation of these self-replicating organisms and symbiosis, it just takes us to the next level.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

So, just like we the humans, by the way, do you have uh Neanderthal blood in you? >> Yeah. Yeah. I don't know. I get teased.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

I get teased for that all the time. Yeah. A huge amount. Yeah. I'm like I'm like more Neanderthal than most people.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

Almost 5% like 4.6% or something. I mean, Neanderthalss had it was so so interesting because they had a larger cranial capacity, I believe, but there was something that humans were better at some abstract. I have no idea, but um it it's so interesting how we incorporate all this stuff into ourselves like the viral DNA like other sort of species. I guess they're not species if we whatever other branches on the evolutionary chain. And I think AI is the next thing that we as humans will sort of like uh merge with or join forces with that's going to maybe take us to the next evolutionary step.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

Um also from the interview he does not agree with like a laser and the high doom. He disagrees with that. Another great reason to listen to the interview very positive and very sort of mindopening slashminding to me at least. I encourage people to listen to it. We'll leave the, you know, comments.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

We'll leave the links down below and we're going to reach out to to Blaze and see if maybe he wants to chat with us. Yeah, I hope so. I mean, he seems just absolutely floored. I had to pause the interview like a lot, dozens of times in order to just look up some of the words and uh what the heck they were talking about. Um, but now that I have a better grasp, I'm hoping to be able to maybe explain some of these concepts and then dive deeper if he is able to join us, which I think would be a a dream come true.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

>> Yeah. Well, I'll definitely check it out tonight and uh I'm sure I'm sure during it I'll think of like so many things I wish I would have said during this interview, but thanks for bringing it to my attention and I'm excited to uh reach out to him and hopefully we'll get him soon. >> Absolutely. Okay. Well, everybody, thank you so much for joining us for this little emergency session.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

And uh >> Wes having an existential crisis. He's like, "Film a podcast right now. Get on 20 minutes." I'm like, "All right, let's see what's up. >> What does it all mean?" Tell us talk about it. >> Yeah.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

No, this was this was a trip. But yeah, Dylan, thank you so much. Thank you so much for everyone for who joined us for being here and we will see you all in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ06æ—¥

</div>
