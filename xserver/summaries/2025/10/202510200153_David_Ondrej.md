# ğŸ“º AIæ¥­ç•Œ28ãƒ¶æœˆã®æ•™è¨“ã‚’32åˆ†ã§è§£èª¬

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: 28 months of AI lessons in 32 minutes
- **ãƒãƒ£ãƒ³ãƒãƒ«**: David Ondrej
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=bbDFPHhpkc4](https://www.youtube.com/watch?v=bbDFPHhpkc4)
- **å‹•ç”»ID**: bbDFPHhpkc4
- **å…¬é–‹æ—¥**: 2025å¹´10æœˆ20æ—¥ 01:53
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã§ã¯ã€David OndrejãŒ28ãƒ¶æœˆã«ã‚ãŸã‚‹AIæ¥­ç•Œã§ã®çµŒé¨“ã‹ã‚‰å¾—ãŸé‡è¦ãªæ´å¯Ÿã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚AIãƒãƒ–ãƒ«è«–äº‰ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å°é ­ã€æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®é€²åŒ–ã€ãã—ã¦ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆä¸è¶³ãŒæ¥­ç•Œæœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã‚ã‚‹ç†ç”±ãªã©ã€2025å¹´Q4æ™‚ç‚¹ã®AIæ¥­ç•Œã®ç¾çŠ¶ã¨2026å¹´ã®äºˆæ¸¬ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚AIèµ·æ¥­å®¶ã‚„é–‹ç™ºè€…ã€ãã—ã¦AIæŠ€è¡“ã®æœªæ¥ã«èˆˆå‘³ãŒã‚ã‚‹æ–¹ã«ã¨ã£ã¦å¿…è¦‹ã®å†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **AIã¯ãƒãƒ–ãƒ«ã§ã¯ãªã„**: å®Ÿéš›ã®åç›Šæˆé•·ã¨å®Ÿç”¨çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ã€2021å¹´ã®æš—å·é€šè²¨ãƒãƒ–ãƒ«ã¨ã¯æœ¬è³ªçš„ã«ç•°ãªã‚‹ã€‚Anthropicã‚„OpenAIã¯å¹´é–“10å€ã®åç›Šæˆé•·ã‚’é”æˆã—ã¦ã„ã‚‹
- **å¼·åŒ–å­¦ç¿’ã¨ãƒ†ã‚¹ãƒˆæ™‚è¨ˆç®—ãŒéµ**: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸ŠãŒé ­æ‰“ã¡ã«ãªã‚‹ä¸­ã€æ¨è«–æ™‚ã®è¨ˆç®—è³‡æºã‚’æ´»ç”¨ã™ã‚‹å¼·åŒ–å­¦ç¿’ãŒæ–°ãŸãªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã‚‹
- **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒè¿½ã„ã¤ã**: GLM 4.6ã‚„DeepSeekãªã©ã€ä¸­å›½ç™ºã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒClaudeã‚„GPTã¨ã„ã£ãŸã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®
- **ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãŒæœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯**: GPUä¸è¶³ãŒå…¨ã¦ã®ä¸»è¦AIä¼æ¥­ã®æˆé•·ã‚’åˆ¶é™ã—ã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å»ºè¨­ã¸ã®å·¨é¡æŠ•è³‡ãŒç¶šã„ã¦ã„ã‚‹
- **2026å¹´äºˆæ¸¬**: AIå®‰å…¨æ€§è­°è«–ã®çµ‚ç„‰ã€ã‚¸ãƒ§ãƒ–ç½®ãæ›ãˆå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¢—åŠ ã€ãã—ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã‚­ãƒ«ã®é‡è¦æ€§ãŒå†ã³é«˜ã¾ã‚‹

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

My name is David Andre and I've spent the last 28 months focused on one thing, AI. In this video, I'm going to give you a detailed analysis of the main trends, patterns, and changes I see in the AI industry as well as a set of predictions for 2026. So, the topic that everyone is talking about is whether AI is a bubble or not. And a good huristic I learned is that if everyone thinks it's a bubble, it's not a bubble. And what that means is in order for it to be a bubble, the investors, the people pouring in all the money have to be convinced that it's not a bubble.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

They have to think that the returns will keep going forever without there being any fear whatsoever. The 2008 crash is the most recent and clear example of this. However, there are some very major differences in this AI technology cycle that both the 2008 crash do not have, which I'm going to touch on in a second. First, let's break down why people think that it's a bubble. And there are some good arguments for this.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Number one, we see insane investment, right? Not only from the massive big tech companies like Google, Nvidia, OpenAI, Broadcom, AMD, Meta. I mean, Mark Zuckerberg is spending hundreds of millions if not billions on individual people. That's one thing. But also, the seed rounds, right?

### ğŸ“ è©³ç´°èª¬æ˜

The VC landscape is just crazy. I mean, the other day some company raised $17 million seed round. Not series A, not series B, a C round. There are companies who raised multi-billion dollar rounds before having any product, right? SSI from Ilia Saskatk, thinking machines from Mera.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

Now, I would make exceptions for these like foundational AI research labs because those are the best people in the world, right? There aren't many researchers better than Ilia. Maybe Andre Kbafi, right? That's a separate category. I would say these multi-billion foundational lab raises.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

But there is still tons of startups that are like consumer or application layer that are raising insane rounds with often no revenue, zero product market fit, and completely unproven track record. If I had to say that is probably the biggest indicator that we're in a bubble. However, if we compare the current state of AI as of Q4 of 2025 to, for example, the crypto bull run of 2021, there are significant major differences. First of all, use case. We're already using AI.

### ğŸ¯ å¿œç”¨ä¾‹

I'm using AI every single day. you probably are as well. crypto really didn't have a use case especially like NFTs or some esoteric coins right it was more about the greater fool theory like whoever gets last gets dumped on that is a major difference AI is already useful another difference is the revenue of the companies in 2021 obviously the biggest scam was FTX but a lot of these crypto companies didn't have any revenues any actual growth it was all speculative it was just like in the com bubble adding.com after your company's name would triple your valuation that was the came in the crypto era of 2021. The problem is that a lot of these AI companies, OpenAI Enthropic, they're seeing massive revenue growth. Growths that any other time in history would be absolutely unprecedented.

### ğŸ’­ è€ƒå¯Ÿ

And even today, they're unmatched. Like for example, Enthropic 10x every single year, not a double, right? If you do a double year over year, that is incredible growth. Like the S&P is growing like what 12%. So if you do 100% increase, that's amazing.

### ğŸ“Œ ã¾ã¨ã‚

So the revenue is there and the use case is there. Those are the major two differences. Now, is it possible that there's going to be some stock market pullback in the short to medium term? Absolutely. And in fact, I think it's likely.

### âœ… çµè«–

There might be like a 10%, 20%, even 30% crash, but that's not a recession and definitely not a depression. If anything, that might be a bubble in the VC world, right? In the private markets where all of these startups, they're not publicly traded companies. They're early stage startups with private backing either from angel or VC investors. And trust me, there's going to be a lot of those that completely crash and burn.

### ğŸ“š è¿½åŠ æƒ…å ±

But if we want to compare it to 2001.com bubble, that was a 80% market crash, right? The NASDAQ was at like 5,000 peak. It went down to like 1300 or something. 80% is a huge crash and I simply don't see it. AI is just completely transformational technology and the gains are there.

### ğŸ”– è£œè¶³

Even if we look at GBD5, a lot of people thought that GBD5 was not as good as people expected it to be. There's several reasons. First of all, it was a smaller model. OpenAI on purpose made it a lot smaller than GPD 4.5, which was a huge model, like maybe 17 trillion parameters. GBD5 is much smaller, much more compute efficient model.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

That way, they can serve it to way more users and especially on the free plan. So, that's one thing. OpenAI made it smaller on purpose to make it faster and to make it easier to serve. But the reason why this is not a good argument is that there are massive gains in reinforcement learning. This really is the frontier that keeps on giving.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Without RL, I think we would already be in a stock market crash, maybe close to a recession. But since reasoning, which only is like 12 months old, it's kind of incredible to think that 01 preview, which was the first mainstream reasoning model, is like less than a year old. It's crazy, right? But reinforcement learning, especially combined with test time compute, is really untapped. And as long as you can create a benchmark for some evil where you measure what you want, that can be saturated, which means that can be achieved and mastered by AI models.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

And this really is a incredible breakthrough that not many people understand. That's why, and this is a pro tip, there's a lot of different startups doing all these RL environments in San Francisco. This is a hot term. What that means is different environments for AI agents and AI models to do a specific task, right? A super common one is online shopping.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So you would recreate a site like Amazon and then you would train the agents on how to use it. How to pick a product, how to scan the page, how to open the cart, check out, all that stuff, right? And the reason why this is so important is that we need the models to be able to do specific actions. The models are already incredible. They're already smart, but they're trained on text.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

This is their biggest strength and their biggest weakness. All of the internet has already been scraped and saturated. So that's why the performance in the foundational models has been stagnating. But we have all of these other paradigms, notably reinforcement learning on top. And that's why we keep seeing these massive gains in coding, math.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

I mean, mainly these two dimensions, right? Because they're both deterministic and both of them can be validated. If you write a math equation or some theorem or conjecture, you can either see if the math adds up, right? If a professional mathematician goes over it and finds several flaws and you know one equals two, you can discard that easily. Same with code, right?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

If the code doesn't compile, if the program doesn't run, if there's tons of errors, you can throw it away. And this is where you can use synthetic data to your advantage. With both math and code, you can generate and use tons of synthetic data to train upon them. And even if one out of 500 examples works, you can examine that one, look into the reasoning trace, study the chain of thought of that model and see okay, what happened in this one instance that caused the model to solve the problem and then you can train on that. You cannot really do that with creating images, copyrightiting, sending emails.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

But that's the point on most creative tasks, you know, video editing, taking photographs, all of these are questions of taste. If we want to see crazy gains in AI, we do need to create these ail environments, which means reinforcement learning environments for specific set of actions to create more data, new data for these models to keep improving. And that's because data is one of the most important things, right? It's like the digital oil. You need data, you need compute, and you need talent for models to work and scale.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

This is why like a year ago, I predicted that XAI, well, it was still a new company, and everybody was saying like Elon Musk is behind, they won't catch up. I predicted that they might catch up because Elon is the best in the world at large manufacturing and infrastructure projects in the real world, solving bottlenecks and moving faster than anyone else. Elon being the richest person in the world obviously has the money and capex to invest and to catch up in terms of buying GPUs. Elon also can attract some of the best talent in the world. You know, everybody wants to work with Elon Musk.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

Everybody wants to be a part of history. And then in terms of data, Elon has acquired Twitter, which maybe he did it for free speech. That is definitely a part of that. But he also did this for all of the data and all of the real-time information that is on Twitter that other companies cannot scrape or at least they probably did it in the past while it was still Twitter. But now that is X.com.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

It's completely prohibitive for OpenAI, Enthropic Google to scrape Twitter, right? XAI is the only company that can do that and they have the data advantage plus they have a lot of real world data from Tesla. a lot of footage and video from Tesla cars driving on the roads which mainly is good for FSD but it will also be good for video models and world models right and if you follow Elon you know how hard he's pushing Grock imagine which is like their alternative to Sora basically but another untapped data mine will be Optimus which is Elon's humanoid robot which will give three-dimensional physical understanding of the world right for a human doing something like this might be super easy for a humanoid robot that is crazy like a robot couldn't even imagine doing something like that. That would be impossibly hard for a robotic arm to do. But any 10-year-old kid that can do that, no problem.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

And that is because humans have so many input tokens coming in. People don't realize how much training they've done. They think that a child is not being productive in the first few years of their life. Actually, a child is being extremely productive. A kid is like looking around their hands.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

They're testing things. They're moving object. It falls. They're trying to like move their body. They're learning physics.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

They're getting bunch of input tokens through their eyes, bunch of audio tokens through their ears, bunch of sensory tokens with their fingers and they're improving massively, right? The neuroplasticity of a child is insane. And the average human can become much smarter than an LLM by the time they're 18 or 20 with way less tokens, like orders of magnitude, probably like thousands, tens of thousands of times less, maybe millions times less tokens than these foundational models. If you look at GBD5 or Opus 4, any of the top models right now, Grog 4, there's like tens of trillions of tokens going into these models and they still aren't as useful as a college student intern that you can hire at your company and you can do like all kinds of tasks, right? So, humans are much better at the generalization than these AI models, which means there's still a lot of efficiency gains to go.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Now, tying that back to the previous point, since Elon is building these humanoid robots, that will give him tons of priceless data that companies like OpenAI do not have. Maybe that's why they're trying to partner with Figure AI to get that humanoid robot data because those tokens are not available on the internet. On the internet, humans only put text. Yeah, there are some images and videos, but it's mostly text, right? If we say that it's text, images, and videos, that's it.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

There is so much more than that that we don't realize. Let's say you get hired at a new company, right? you're the lowest person at the company. Let's say it's 500 people. If you meet the CEO in the hallway, you don't need a manual on how to act.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

You don't need to read online blog that you should be respectful, that the CEO, you know, has a higher position, that you shouldn't like make a offensive joke. All of these things we learn intuitively. Some of them are biological through you know past experience of evolution of like 50,000 years ago you offended the tribe leader and that person got killed right some of that is in our DNA some of that we've seen through you know kids on the playground or being in the school and you know offending the teacher and being punished the point is that those tokens never make it to the internet there's so much that happens in my everyday life in your everyday life that we don't even perceive is like data is potential tokens But all of that the model doesn't have access to. Another thing is feelings, right? If you do something embarrassing, you feel bad.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

If you eat some food that you shouldn't have ate, like you know, processed carbs, you feel bad. Yeah. AI models don't have any feelings. They don't know like if they get punished or not. You might say like, "Oh, that is a terrible mistake.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

Why did you delete my database?" The model doesn't have a feeling. It's a sequence model. It outputs the series of next tokens, which might seem like it has a feeling. And people who do not understand AI would cause you to believe that, right? There's a lot of AI doomers, which by the way, this is one of the biggest trends of 2025.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

All of this AI safety, all of this AI dumerism has completely evaporated. You don't see people talking about this nowadays at all. If we go back to 2023 or even the first half of 2024, everyone was talking about AI safety. Everyone was like paperclip problem, you know, this and that, escaping, hard take off, nobody talks about AI safety. Why?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

Because the more you actually use AI, the more you realize what the LLMs are. They're large language models. They're next token predictors. They're not going to eat you alive. They're not going to turn you into a paperclip.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

That is complete science fiction. Could that happen in the future in 30, 40, 50 years once there's drones, humanoid robots everywhere? Once you know there's a new AI architecture, possibly. But again, if we look at reality right now, today moment, which is Q4 2025, nobody is talking about safety anymore. And why?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

because it is evident that all of that has been mostly AI dumerism. So if I had to say whether AI is a bubble or not, I would bet my money on not a bubble. And in fact, I'm betting more than my money. I'm betting all of my time, all of my resources, all of my public reputation, my entire career and life on the fact that AI is not a bubble. I think that's a pretty good sign that I have skin in the game.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Another major trend that we've seen over the last few months is open source models truly catching up to close source models. in fact in many domains overtaking them. And the problem is a lot of people aren't paying enough attention to this and is not getting as much publicity. We can get into that in a bit, but let's talk about why. GLM 4.6 is perhaps the best example.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

It's a super powerful open- source model specifically for coding that is better than cloth for set and even set 4.5 in many different ways on many of the most popular benchmarks. But why don't we see more people talking about GLM 4.6? Why is it that it's like on the side more of a esoteric model? Well, there's many reasons. Number one, the big AI labs, whether it's Open AI, whether it's Enthropic, whether it's Google, Deep Mind, they have the all the incentive in the world to kind of bury these open source models, right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

To not talk about them or to make them seem kind of dirty, ugly. You know, they're from China, don't touch them. So, that's one thing. Everyone associated with the big big AI research labs has the incentive to ignore the open source models. But another thing is way more practical.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

It's the inference. A lot of the inference whether it's the GPUs, TPUs or just the cloud is built around the most popular models such as GPD series, cloud series models from the biggest companies. And that's why when a new architecture, a new open source model comes in, whether it's DeepSeek, whether it's Kimmy, whether it's GLM, a lot of that compute is not optimized for these open source models. So the inference is not there or it's like way worse performance and the people with the compute would just be better off selling it to the hyperscalers. However, that doesn't change the fact that open source models have nearly surpassed closed ones.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

And again, this is something I've been talking about for a year and a half, like close to 2 years now, and it's becoming true now. We literally see open source models, especially for domains, right? Because you can fine-tune models, but even general ones like GLM 4.6, a lot of people prefer using it over CLA Soret 4.5, which currently is the main model from Entropic. And Enthropic is worth like $200 billion. What's the investment into Enthropic?

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

Like 35 billion. And their most powerful model as of October 2025 is comparable to an open source model from Zipu AI, which is a Chinese lab that nobody has heard of until like 3 months ago. If you ask me, that's incredible. Another trend in the AI space that I'm seeing that not enough people are talking about is the rise of smaller models. Right.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Speaking of Enthropic, they just released cloth haiku 4.5. And I actually think that Haiku might be more useful than Sonnet. It's not better than Sonnet, but more useful. Why? First of all, it's three times cheaper.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

That already enables it to be in way more applications that otherwise you cannot do. So, not only does it enable a lot more possible applications, but it's also way faster. It's more than twice as fast as Sonet 4.5, which especially for coding is huge because there's the concept of flow zone, right? If you're doing something and if you're using a fast model, you can stay in the flow. But if a model takes like five minutes to respond, you'll be tempted to, you know, check your phone, check Twitter, you'll just get distracted.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

So having a fast model is actually very important for productivity. And also just for many different use cases, you need a fast model, right? So this is why I think we're going to see way more specialized, small, super fast models rather than these behemoth generic models that are very slow and very expensive to run. And I think the last one that was really in this category was GBD4.5 which right now you cannot even use. OpenI has completely removed it from the API and I think even on CH GPT I mean let me check it is there but you have to pay $200 a month to access it and it's still very slow.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

Why? Because it's like 178 trillion parameters while most of the cutting edge LLMs are like one or two trillion. So that's way more efficient obviously. And then thanks to reasoning, thanks to test time compute, you can use a lot more compute during inference, right? So instead of using all of the GPUs, the entire cluster, all of the compute you have on training a massive model and then running it slowly, you make like a medium-sized model such as sonet 4.5 and then you use the remaining compute that you have during inference by giving it reasoning and giving it the ability to think for longer.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

And we've seen this. This is one of the most important charts. I think the time an agent can work meaningfully by itself. And I think right now it's around 2 hours. But it used to be just 6 months.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

It used to be like 20 minutes or something. So it's rising very fast. It's like another exponential curve where models and agents are able to work for multiple hours. I think GBD5 CEX was doing like 7 hours. There are some reports of Sonet 4.5 doing 30 hours, but I don't think that's realistic at all.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

If we say it's you know 2 3 hours maybe seven that is still incredible right that unlocks another paradigm of tasks that AI can now do before deep research and it's hard it's easy to forget that deep research is still a new thing like 9 months old or something deep research didn't even exist now every single chatbot has a deep research right there is so many tokens being burnt both on actually researching the sites you know scraping the data but also on reasoning and thinking through it and you The model is analyzing what should be the next search. What data do we have regards what user requested? What is still missing? And then once it has everything, how do we make this into a concise report? How do we summarize this?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

A single deep research query takes hundreds of times if not thousands of times more than a normal chat GBD query, you know, GBD5 fast or whatever the people on the free plan use. That's one example of a longunning use case where it can run for 10, 15, 20 minutes and give you a report, right? But then if you want to execute a massive codebase refactor with GBD5 codex that could be running for 30 60 90 minutes before it's completed. And again it enables a whole new set of tasks that normally AI couldn't do because it would lose track. It would you know hit its context limit.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

It simply couldn't work for longer than a few minutes. Now we're into the multiple hour surgery. And if this trend continues, that's an if, it's not guaranteed, soon enough, models and agents will be able to work for days reliably and do actual set of actions and useful processes and useful workflows that you would need to again employ like an intern or junior engineer or just a human to do for weeks, you know, because AI is still faster, especially at processing data, summarizing data, and outputting data. So yeah, I think we're going to see a lot more small specialized models that are useful at one specific thing that can run super fast rather than these massive 15 20 trillion parameter models like GBD5. I think um that era is coming to an end.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

Now it would be a bad analysis if I didn't talk about the infinite money glitch that Nvidia, OpenAI, and similar companies are performing. Now you're probably thinking, David, what do you mean by infinite money glitch? Well, let me give you an example. Nvidia invests hundred billion dollars into OpenAI. OpenAI now has $100 billion.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

What are they going to do with it? They're going to give it to compute, right? So either directly back to Nvidia or companies like Corv or other cloud computers that guess what buy their GPUs from Nvidia. So yeah, maybe not 100% of that money will go back to the company that created the investment, which in a lot of cases is, you know, AMD, Nvidia, the companies that have extra capital to spend. But even if it's like 80 or 90% that goes back, it is still an OP loop where suddenly Nvidia has more revenue because you give OpenAI 100 bill, OpenAI spends 90 of that back.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

Boom, you have higher revenues. But also, it's good for OpenAI as well because it allows them to scale much faster than they would otherwise if they didn't have that investment because let's not forget they are still a largely unprofitable company. And this is something I should have mentioned in the bubble discussion, but people are losing money, right? And if you talk to people like Dario, they have these like different mental gymnastics models which could be valid. Absolutely could be valid.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

And what I mean by that is like the breaking it down model by model, right? Instead of saying like enthropic is losing tens of billions of dollars, that's not sexy. That's not a good message to investors. Instead, you say enthropic should be measured by different models, right? We train clot-free costs, you know, I don't know, 100 million.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

Clot free over the next few years makes more than 100 million. So clot free as a separate business is profitable. We train cloth 4. Clot 4 costs 1 billion, 2 billion, whatever. It's losing money right away, but over the next five years, it will make more than five billion in value.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

So, Clot 4 is a profitable business. So, who knows whether this is a good way or whether this is like just an explanation of revenue. I think only people at these companies really know. But this is a very strong argument for the people who think AI is in a bubble is that everyone is basically unprofitable. Good luck trying to find a profitable AI startup, let alone like a AI research lab nowadays.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

Everyone is burning money. Everyone is burning millions. And the biggest companies billions, tens of billions on training new models and on compute. So who's making the profits? Obviously Jensen and Nvidia have amazing margins.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

That's why we see deals like OpenAI and Broadcom where they start to do their own chips. That's why Amazon has their own chip. That's why Google has their own chip with TPUs. Everyone wants to make their own chip, not to be reliant on GPUs from Nvidia. Right now they obviously have the full stack.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

They have the full ecosystem. So it's going to be very hard to get away from them. And they have a great product. So I do expect Nvidia to keep growing and I wouldn't be surprised if two to three years from now Nvidia was a $10 trillion company. I think that's a very easy prediction to make.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

But we also see that all of the AI companies especially the cutting edge research labs they really they really really really want to make their own chip. And the main reason is that if you have your own chip you control your own destiny. It's not that you know Jensen and Nvidia didn't allocate enough GPUs. So then your next model cannot be as good. If you own the full stack right from the silicon all the way to the AI model, it's up to you.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

If you mess up somewhere in the process, that's your fault. But if you execute flawlessly, you can have the best model in the world and you can deploy it to how many people you want. Which brings me to the next topic of compute. This is the biggest bottleneck in AI. And just listen to anyone who matters, right?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

Whether it's the people at that are like the leaders of the cutting edge research labs or people who are the infra like designing the chips and selling the infrastructure and building the GPUs or building the data centers is all about compute. That's all they talk about. That's all they're obsessing about. Why? Because that is the bottleneck.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

There's so much more demand for enthropic and for OpenAI that they can actually serve. Good example is the pulse. Chad GDP pulse is a feature that's only available on your phone and it's only available to people who pay $200 a month. Why? Because it costs so much compute.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

They're short on compute. All of these big companies could have easily double triple their revenues if they just had more GPUs, right? If you want to enter the AI space and make ton of money, just become an expert at the chip design, silicon design, and uh build your own data centers, right? And you'll be very rich. I'm like half joking because that's like very extremely difficult to be expert in those domains.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

But I'm also not joking because that's the cap. That's the problem of all of the biggest companies. All the biggest businesses are constantly complaining that they don't have enough compute. So if you figure out like some way to do more efficient inference or more efficient training or optimize, you know, the structure of a data center or, you know, the layout of transistors on a chip. All of these things are incredible opportunities to make a lot of money, especially if you're into hardware.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

But what does that mean? Comput is the real bottleneck. Let's look at like second and third order consequences, right? This is why there's so much investment into AI because compute is the bottleneck. The smart money which is the biggest companies in the world, right?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

And the people backing them and the people who are deciding what to do with hundreds of billions of dollars, all of them are dumping most of that money into building these massive multi-gawatt data centers. I think OpenAI, the latest one with the Broadcom is like 10 gawatt, which is crazy. That could power a small country. And that's the smart money. This is not retail investors.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

This is some of the smartest investors in the world because they see the charts, they see the curves and they see the insane, insatiable demand for compute and they want some piece of that money. Also, it's easy for Wall Street to understand. If you build a data center, it's like real estate. You know, you build a house, you get a bunch of tenants, it's predictable revenue. So a lot of the Wall Street investors, people managing trillions of assets under management do understand the model of the data center and they're much more likely to invest in that than some, you know, speculative AI startup that's just yet another vibe coding tool which was actually a brilliant segment to the next topic.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

I didn't even do that accidentally. It's just subconscious. Everybody is building the same thing. It's either like a generic vibe coding tool or it's a NA10 clone, you know, a workflow builder. That's the most two common categories of apps.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

We're seeing either a vibe coding, you know, bold, lovable clone or it's a NA10 clone. And it's not just startups and new companies that are trying to clone NA10. Most notably, OpenAI on the latest dev day released Agent Kit, which is their own workflow builder, right? And I do think both NA and Agent Kit can be successful. And if I had to predict, that would be the case.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

I wouldn't be surprised if NAN was a $10 billion company a year from now. Right now, I think they're valued around 2 billion. The problem is that with everyone building the same thing, it will be the winner takes all market. Now it could be a different market. Agent kit from OpenAI might go after people who are more beginners.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

People like CHP users who want to do a bit more. If you look at agent kit and the UI, it is like that. It's super simple, super clean, but it doesn't have as many options and integrations as NA10. I think NA10 is kind of like mid-level, right? It's not for programmers.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

You don't have to be a developer to use NA10 but it's for people who are more technical and they are more businessoriented but then you look at all the other companies right like all the other clones workflow builders and it's again it's not just small companies like 11 Labs which is a amazing voice company probably the best voice company in AI released their own agentic workflow builder why god knows fire crawl which again is like one of the best crawlers for crawling websites also release an agent builder most of these will not survive Let's be honest, as a person with a business myself, as someone who's on the cutting edge of AI, at least I try to be. I don't see more use cases. I I I don't need more workflow builders. Like I have NA10. I don't see the need for adding another workflow builder into my company.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

I'll just use what I know. Same with VIP coding tools. Now here, you know, the scene is changing faster. If someone finds a better way to do it, you can just easily switch. But again, like if you're used to Bolt, if you're used to lovable, if you're used to V 0ero, why would you switch to something else?

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

And literally every single week we see another vibe coding tool. And it's it's really tiring and it's it's kind of annoying because those people could be using their creative energy, their time, their effort on innovating. This is something that's really missing is true innovation, unique products, unique services, right? And if I do have to give myself credit, this is what I did well with Vectal. Even though obviously Vector is nowhere near as successful as some of these VIP coding tools with hundreds of millions in revenue, at least it's a unique product, nothing like it exists.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

We'll see if it's successful or not. Future will tell, but I would really want to see more people building something 0ero to1. This is what the book 0ero to1 is about, right? From Peter Thiel, who's a co-founder of PayPal and the co-founder of Founders Fund, which is one of the most successful venture capital funds of all time. It's a concept of creating something that doesn't exist.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

Going after a unique problem in a small market and you know creating a monopoly in that market by delivering a superior solution that's at least 10 times better. And this is the important part. Whatever you built has to be at least 10 times better than the next best thing. These vibe coding tools, it's literally like you could close your eyes and they're all the same. Sure, maybe one is better at front end, maybe one has a better database integration, but like they're not 10 times better.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

If we give them the benefit of the doubt and we see a new vibe coding tool emerge, maybe it's 50% better. Maybe it's two times better at best. It's not 10x better, which means it will not succeed. I mean, you know, I'm just going to be honest. A lot of these people are reselling anic tokens.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

What I mean by that is like they offer these amazing plans, right, that allow them to have massive growth, but they're vastly unprofitable because they are reselling OpenAI and Enthropic tokens at a loss. So we will see a lot of startups go bust in the next 24 months. That is a another easy prediction to make. Oh, and especially if you see that startup using the hot Asian girl strat, which basically you take like a 18, 19 year old girl from somewhere, you put her as your HR girl or your chief of staff or some useless position that your five person startup definitely doesn't need. And then you make her post on Twitter, you know, with these cringe poses saying like, "Hey, I just went to SF, you know, want to make some friends.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

I I just joined X company or Y company. If your startup is doing that, it's going to almost certainly fail. But yeah, that's a side note. Another easy prediction is that there will be a massive unrest. There will be insane protests uh in the next year because why?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

AI is going to take jobs. The reason why AI is going to take jobs is because that is where the money is. If you look at the software market that is like 300 billion a year or something like that, the labor market is like 15 trillion per year. This is why we will see a lot more startups. And again, this is another prediction for 2026.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

We will see a lot more startups that are building like a single job replacement agent. We've already seen with customer support, that's the most obvious one. Also, like secretary, you know, these voice tools for like secretary or outreach like a setter or a salesman, we will see a lot more. This is nothing. We're like stage one.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

And that will mean that a lot of the revenue, a lot of the growth in the AI space will come from replacing the most repetitive and boring jobs, right? Such as the elevator replace elevator boys. We will see that with a lot of these automated low-lever jobs which not only will make for great companies as Sam Alman said and a lot of efficiency, a lot of productivity gains on the positive side and massive returns to investors for sure but on the negative side it will cause a lot of job loss which in return will cause a lot of protests and social unrest. So that's another pretty safe prediction for 2026. And lastly, I think we will see a massive swing back to learning how to code.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 84

Learning how to code will become sexy again. People will want to get into software engineering. They will want to understand computer science. Why? Because if you understand all that stuff, you can take such a massive advantage of the coding agents compared to somebody who's nontechnical at all.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 85

If someone isn't techsavvy and they're completely incompetent and they're like typing with two fingers, they're struggling to navigate around the settings around the browser. Yeah, that person can be faster with AI, but not as much as someone who's already a cracked programmer who can manage a team of agents who can build his own animated automations, save massive time. That person is going to become 100x more powerful. Whereas the average person might be 2x more powerful, 3x more powerful, right? So this is the concept of the smart gets smarter.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 86

If you are locked in, if you're at the cutting edge of AI, you'll crush everybody else. So, the biggest takeaway from this video is that if you can do one thing, get to the cutting edge of AI.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ16æ—¥

</div>
