# ğŸ“º OpenAIãŒæ˜ã‹ã—ãŸè¡æ’ƒã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ— 2028å¹´ã«è‡ªå‹•AIç ”ç©¶è€…ãŒèª•ç”Ÿ

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: OpenAI just said it
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=WrEVCsK4XOQ](https://www.youtube.com/watch?v=WrEVCsK4XOQ)
- **å‹•ç”»ID**: WrEVCsK4XOQ
- **å…¬é–‹æ—¥**: 2025å¹´10æœˆ30æ—¥ 07:04
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã¯ã€OpenAIãŒåˆã‚ã¦å…¬é–‹ã—ãŸå†…éƒ¨é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®è¡æ’ƒçš„ãªå†…å®¹ã‚’è§£èª¬ã—ã¦ã„ã¾ã™ã€‚AIæŠ€è¡“ã®æœªæ¥ã«é–¢å¿ƒã®ã‚ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ã‚„ç ”ç©¶è€…ã‚’å¯¾è±¡ã«ã€2026å¹´9æœˆã®ã€Œè‡ªå‹•AIç ”ç©¶ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ã€ã‹ã‚‰2028å¹´3æœˆã®ã€Œå®Œå…¨è‡ªå‹•AIç ”ç©¶è€…ã€å®Ÿç¾ã¾ã§ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è©³ã—ãç´¹ä»‹ã—ã¾ã™ã€‚AIç ”ç©¶ãã®ã‚‚ã®ãŒAIã«ã‚ˆã£ã¦è‡ªå‹•åŒ–ã•ã‚Œã‚‹ã€Œå†å¸°çš„è‡ªå·±æ”¹å–„ã€ã®æ™‚ä»£ãŒç›®å‰ã«è¿«ã£ã¦ãŠã‚Šã€ã“ã‚ŒãŒAGIï¼ˆæ±ç”¨äººå·¥çŸ¥èƒ½ï¼‰ã‹ã‚‰ASIï¼ˆè¶…çŸ¥èƒ½ï¼‰ã¸ã®æ€¥é€Ÿãªç§»è¡Œã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚äººé¡å²ã«ãŠã‘ã‚‹æœ€ã‚‚é‡è¦ãªè»¢æ›ç‚¹ã®ä¸€ã¤ã¨ãªã‚Šã†ã‚‹ã“ã®æŠ€è¡“é€²åŒ–ã«ã¤ã„ã¦ã€ç§‘å­¦çš„ç™ºè¦‹ã®åŠ é€ŸåŒ–ã¨ã„ã†è¦³ç‚¹ã‹ã‚‰ç†è§£ã‚’æ·±ã‚ã‚‰ã‚Œã¾ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **OpenAIã®å…¬å¼ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—**: 2026å¹´9æœˆã«è‡ªå‹•AIç ”ç©¶ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ã€2028å¹´3æœˆã«å®Œå…¨è‡ªå‹•AIç ”ç©¶è€…ã®å®Ÿç¾ã‚’ç›®æ¨™ã€‚ç•°ä¾‹ã®é€æ˜æ€§ã§å†…éƒ¨è¨ˆç”»ã‚’å…¬é–‹
- **ã‚¿ã‚¹ã‚¯å®Ÿè¡Œæ™‚é–“ã®é€²åŒ–**: ç¾ä¸–ä»£ã®AIãƒ¢ãƒ‡ãƒ«ã¯ç´„5æ™‚é–“ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼è¦æ¨¡ã®è¨ˆç®—è³‡æºæ´»ç”¨ã§ã•ã‚‰ã«å»¶é•·äºˆå®š
- **å†å¸°çš„è‡ªå·±æ”¹å–„ã®è»¢æ›ç‚¹**: AIç ”ç©¶ãŒAIè‡ªèº«ã«ã‚ˆã£ã¦è¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€äººé–“ç ”ç©¶è€…å…¨ä½“ã‚’ä¸Šå›ã‚‹è²¢çŒ®ãŒå¯èƒ½ã«ã€‚çŸ¥èƒ½çˆ†ç™ºã®å¼•ãé‡‘ã¨ãªã‚‹å¯èƒ½æ€§
- **AGIã‹ã‚‰ASIã¸ã®çŸ­ç¸®**: æ±ç”¨äººå·¥çŸ¥èƒ½ï¼ˆAGIï¼‰åˆ°é”å¾Œã€è¶…çŸ¥èƒ½ï¼ˆASIï¼‰ã¸ã®ç§»è¡ŒæœŸé–“ãŒäºˆæƒ³ä»¥ä¸Šã«çŸ­ããªã‚‹å¯èƒ½æ€§ã€‚Leopold Aschenbrennerã®ç†è«–ãŒç¾å®ŸåŒ–
- **Google DeepMindã‚‚åŒæ§˜ã®é€²å±•**: AlphaEvolveãªã©å‰ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã§æ—¢ã«å®Ÿè£…æ¸ˆã¿ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼åŠ¹ç‡åŒ–ã€TPUè¨­è¨ˆæ”¹å–„ã€Geminiè¨“ç·´å‘ä¸Šã‚’å®Ÿç¾ã€‚å„ç¤¾ãŒç«¶äº‰

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

OpenAI did a live stream yesterday talking about in part their recapitalization. They also took some questions from the audience. Most of the questions were about the 40 model. People love that model, but this was what caught my attention. Here's Sam Alman and Yakob Pachokei talking about kind of their internal goals for AI development.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

As Yakob himself said that they're going to do something that they haven't really done before and that is reveal their internal roadmap. >> AGI rolls around only once subscribe. >> This is a glimpse of where the people at OpenAI, the people at the frontier of AI development, where they think things are going and when they're going to get there. So here we are, October 2025. By September of next year, they believe that we'll have an automated AI research intern.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

And then by March 2028, we'll have automated AI research. So, just a quick 10-second recap of why this is important. Imagine that AI doesn't automate anything except for just one thing. That one thing being AI research. So similar to how now we have the world's best and brightest people working on trying to improve AI trying to work out different theories of machine learning and also how to figure out AI alignment making sure that it doesn't do anything bad to us once it's much much smarter than us.

### ğŸ“ è©³ç´°èª¬æ˜

So right now most of that is done by people by humans and the progress is going pretty fast. Think about from 2019 to today, 2019, we really didn't have AI as we know it now. The first commercial products with large language models probably started in 2021 or thereabouts. That's when you started hearing about AI writing, etc. And think about where it is now.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So those were humans mostly doing AI research. You could say 100% of this research was done by humans, maybe 99.9. Now certain things coming out of OpenAI out of Google DeepMind like Alpha Evolve Sakus AI the Darwin goal machine and the recent Jurgen Schmidhuber he also had a Huxley goal machine paper that was published him and many other researchers but they seem to imply that we're beginning to see some sort of a progress in recursive self-improving AI if that trend continues eventually it will provide as much contributions as the entire entirey of human researchers and eventually maybe more that kind of leads to that intelligence explosion right so this is automated AI research this is by Leopold Ashen Brener a ex member of open AAI and in theory this will drastically increase the rate of progress so the space in time sort of between AGI and ASI the super intelligence it might not be that long of a time meaning that once we get to a certain point that leap to super intelligence might happen quickly and kind of that inflection point where everything changes well that happens right around automated AI research in theory so going back to open AI's internal roadmap by September of next year we'll have an automated AI research intern kind of like the beginning of that and by the early 2028 we'll have automated AI research there's a lot of AI news happening right now. But this might be the most important piece not just of AI news, but it might be the most important piece of news ever because somewhere here right either at this point or approaching this point, we see that inflection point. We see that explosion in intelligence, AI progress, scientific discovery.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

And the reason all these companies are throwing billions and now even in the trillions of dollars towards this stuff is betting on this happening. This is what everyone should be paying attention to. Let's take a listen to a few clips of this live stream. And also keep in mind that Google DeepMine likely has something very similar. The stuff that was published with Alpha Evolve that was from a while ago with the previous generation of models.

### ğŸ¯ å¿œç”¨ä¾‹

It has been already implemented. It made for much more efficient Google data centers. It improved some of the the hardware designs for their TPUs. It improved some Gemini training. So, it kind of it made itself better, recursively self-improved.

### ğŸ’­ è€ƒå¯Ÿ

We're seeing the results were from a while ago from the previous generation of models. We have no idea what it's producing now. So, it's very likely that somewhere inside of Google, there's a similar road map and it probably also has something like an automated AI research intern or whatever terminology they use and they also have an automated AI research whatever terminology they use for that and it has dates next to it and it might be the same date or it might be a little bit earlier, a little bit later, but chances are it's coming. All right, take a listen. I'm going to hand this over to Yakob to talk about research and as I mentioned uh we're going to share a lot about our internal goals and our picture of where thing where things are.

### ğŸ“Œ ã¾ã¨ã‚

At the core we are a research laboratory focused on understanding a technology called deep learning. A particular focus of ours is understanding what happens as you scale up training deep learning systems. One consequence we discuss a lot there is AGI artificial general intelligence. And so in particular we believe uh that it is possible that deep learning systems are less than a decade away from super intelligence systems that are smarter than all of us on a large number of critical axes. There is a lot of implications of this to grapple with.

### âœ… çµè«–

One particular focusing impact of this technology and the technologies leading up to it and something that we organize our entire research program around is the potential to accelerate scientific discovery to accelerate the development of new technology. We believe that this will be perhaps the most significant long-term impact of AI development and it will fundamentally change the pace of progress on developing new technologies. thinking about how far along we are towards these goals. One good way to think about progress is to look at the time horizon that it would take people to accomplish the task that the models can perform. And so this is something that has been extending rapidly over the past few years.

### ğŸ“š è¿½åŠ æƒ…å ±

Where the current generation of models is at right now is about 5 hours. And we believe that this horizon will continue to extend rapidly. This is in part as a result of algorithmic innovation and a part just scaling deep learning further. If you look at how much time the model's currently spent thinking about problems and if you think about how much compute how much time you would like to spend on problems that really matter such as scientific breakthroughs you should be okay using entire data centers and so there is there is really quite a way to go there. We of course make plans around it internally and we want to provide some transparency around our thinking and so we want to take this maybe somewhat unusual step of sharing our internal goals and goal timelines towards these very powerful systems.

### ğŸ”– è£œè¶³

you know this particular dates we absolutely may be quite wrong about them but this is how we currently think this is currently how how how we plan and organize as a research organization that is working on automating research naturally we are thinking about how does this impact our own work and how will AI systems that accelerate development of future AI systems look like how can they empower research like a line and so we are making plans around getting to quite capable AI research interns that can meaningfully accelerate our researchers by expanding a significant amount of compute uh by September of next year. So we believe that is actually quite close and then we look towards getting a system capable of autonomously delivering on larger research projects and a a meaningful fully automated AI researcher by March of 2028. Right.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ04æ—¥

</div>
