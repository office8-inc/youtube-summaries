# ğŸ“º Claude Codeã§æ§‹ç¯‰ï¼šAIãƒ“ãƒ‡ã‚ªã‚ªãƒ©ã‚¯ãƒ«ï¼ˆQwen3 TTSï¼‰

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Claude Code Let's Build: The AI Video Oracle (Qwen3 TTS)
- **ãƒãƒ£ãƒ³ãƒãƒ«**: All About AI
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=Vbws3a_OmBM](https://www.youtube.com/watch?v=Vbws3a_OmBM)
- **å‹•ç”»ID**: Vbws3a_OmBM
- **å…¬é–‹æ—¥**: 2026å¹´01æœˆ24æ—¥ 04:00
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã§ã¯ã€Qwen3 TTSãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦AIå‹•ç”»ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚Gemini Flash APIã§è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã€Qwen3 TTSã§éŸ³å£°åˆæˆã‚’è¡Œã„ã€Omnihumanãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒã‚¿ãƒ¼å‹•ç”»ã‚’ä½œæˆã—ã¾ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„æƒ…å ±ã«åŸºã¥ã„ãŸ20ç§’ç¨‹åº¦ã®å‹•ç”»ãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ä»•çµ„ã¿ã§ã™ã€‚AIåˆå¿ƒè€…ã‹ã‚‰ä¸­ç´šè€…å‘ã‘ã«ã€Claude Codeã‚’ä½¿ã£ãŸå®Ÿè·µçš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã®æ‰‹é †ãŒè©³ã—ãè§£èª¬ã•ã‚Œã¦ã„ã¾ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **Qwen3 TTS 1.7Bãƒ¢ãƒ‡ãƒ«**ï¼šMacBookä¸Šã§ã‚‚é«˜é€Ÿã«å‹•ä½œã™ã‚‹è»½é‡ãªãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ãƒ¢ãƒ‡ãƒ«ã§ã€éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½
- **å®Œå…¨ãªAIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ï¼šè³ªå•å…¥åŠ› â†’ Geminiã§èª¿æŸ»ãƒ»å›ç­”ç”Ÿæˆï¼ˆ50èªä»¥å†…ï¼‰ â†’ Qwen3ã§éŸ³å£°åˆæˆ â†’ Omnihumanã§ã‚¢ãƒã‚¿ãƒ¼å‹•ç”»ç”Ÿæˆã¨ã„ã†6ã‚¹ãƒ†ãƒƒãƒ—ã®è‡ªå‹•åŒ–ãƒ•ãƒ­ãƒ¼
- **å®Ÿç”¨çš„ãªéŸ³å£°å“è³ª**ï¼š11 Labsã»ã©é«˜å“è³ªã§ã¯ãªã„ãŒã€å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«ååˆ†ä½¿ãˆã‚‹éŸ³å£°å“è³ªã‚’å®Ÿç¾
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢å¯¾å¿œ**ï¼šGemini Flashã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°æ©Ÿèƒ½ã«ã‚ˆã‚Šã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆDavos 2026ã§ã®Dario Amodeiã®ç™ºè¨€ãªã©ï¼‰ã«ã‚‚å¯¾å¿œå¯èƒ½
- **Claude Codeã§ç°¡å˜æ§‹ç¯‰**ï¼šå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¾ã›ã‚‹ã ã‘ã§ã€è¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç´ æ—©ãæ§‹ç¯‰ã§ãã‚‹

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

Daario Amade criticized US chip exports to China, likening the policy [music] to selling nuclear weapons to North Korea. >> Earlier this week, Quen released a new Quentry TTS model, and I've been trying it out for the last few days, and it's very good for the size it is. So, I thought we can do some kind of claw let's build video today just to test it out to run this locally on this MacBook. So what I came up with was basically uh yeah let me make this big screen here. So basically I wanted to build this AI video pipeline so we can ask a question.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

We're going to use Gemini to do some research online to try to answer that question in 20 seconds. We're going to generate the voice with the Quen TTS. We have some images. We're going to do some video generation using the Omnihuman model. we got to download everything and what we get back is kind of a video with the answer to our question.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

So since we're using Gemini 3 as kind of the the research part, we can kind of answer anything, right? Uh and we want to compress it down to 20 seconds. So the answer generation is of course with Gemini Flash, we just ask like Python main.py, what is the latest AI news? We go out, we do some research, right? We're going to do 50 words max, two, three sentences.

### ğŸ“ è©³ç´°èª¬æ˜

And that's going to be put into a string. So, we can send it over to Quen, right? And you can see we send this string over to Quen. It's supposed to be three here, TTS. And we use the 1.7B parameter model.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

We have some reference voice. That's going to be our Vtuber or this anime style girl, right? That's going to be a reference audio and input text. And we kind of get the audio file or the answer out, right? And the next step then is just going to be to upload this along with the image we have to the omnihuman model.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

And from there, we're going to use the the image URL and the audio URL, send it over to omni and turn this into like a avatar and generate the video that's going to be our answer. Then we're going to retrieve this and we can save it and we can play it, right? you're going to get the final video MP4 out. So, like I said, it's not the most uh advanced pipeline. Uh yeah, you can see here it's basically how many steps?

### ğŸ¯ å¿œç”¨ä¾‹

1 2 3 4 5 six steps all the way. So, let me just show you how this works now. And I think the results is pretty interesting to be honest. So, before we run the full pipeline, let me just show you kind of how Quen 3 works. And it's really easy to use.

### ğŸ’­ è€ƒå¯Ÿ

uh even on MacBook it's pretty fast because of the model size. So if you go to cursor here you can see we have this Python code here where we have kind of loaded up the Quen 3TS 1.7 base model. So you can see we have this set to MPS now. Uh but uh what we can do now is we just select this V tube VV file that is our reference audio. This is our cloned voice.

### ğŸ“Œ ã¾ã¨ã‚

Uh we can have a quick listen to it. >> Okay. So, Hightail is basically Minecraft 2 and I am So, >> yeah, you get the point, right? It's like this Vtuber anime boys. So, what happens now if we just put in something else?

### âœ… çµè«–

We put in Hello YouTube, today's Friday. You might be looking forward to weekend. Maybe have some cool plans blah blah blah. So, to use this now, we can just do Python voice clone, right? pi.

### ğŸ“š è¿½åŠ æƒ…å ±

And that's basically all we have to do. Uh, okay. I I might have to fix that. So, let me fix that. And let's run it.

### ğŸ”– è£œè¶³

Yeah, I just forgot my uh environment here, right? My cond environment. So, we're just going to do cond run, load up the model, and run the Python voice.py. This shouldn't take too long. So, let me see.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

I think it's just going to take some a minute or something. So, I'm just going to wait for this and then we're going to listen to the output. So while we wait for that everything here was just built very easy just using cloud code. So I just gathered the documentation here I needed I needed some context for yes my testing my Gemini documentation my grounding documentation for Google search. Uh I just went to the GitHub on um on Quen 3 and found all the information I needed about the model.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Right. So we got all that and and this is the omni model. Right. This is the video model. Here is everything I needed about uh the Quent TTS model.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

Uh I just went to the repo and gathered the documentation and from there cloud code basically helped me set everything up. So this is not a hard thing to create. So let's listen to the cloned output now and kind of compare it to the clone voice. >> Hello YouTube. Today is a Friday so you might be looking forward to the weekend.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

Maybe you got some cool plans anyway. Yeah, it's not exactly the same, but for this size of model, I think it's pretty good and it's very usable, right? So, it kind of saves you a lot of uh money instead of using like 11 labs, that is of course better. So, if you need like a big project, but uh just running this locally and it only spent like couple of minutes or something creating this. So, for long text that kind of cost a lot of money, that doesn't really um need a lot of quality.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

I think this is pretty good, right? So now let's do the loop here. So remember we can answer any question. So uh I'm just going to open up a new terminal and let's try this now. Okay.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

So what I'm going to do now kind of run uh the model python pipeline.py and then I'm going to ask a question. So I think I'm going to ask um will there be a season 3 of u severance in 2026? So that is my question. Right. So, I'm going to send this.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

So, hopefully now the response is going to be in video format with an avatar and kind of moving mouth and some background music I added. So, the idea behind this was I was kind of thinking like uh in the future, let's say 10 years from now and let's say you go to YouTube and you type in a search. So let's say I was thinking maybe in 10 years YouTube is now gonna produce the video for you. So you don't get like a creator or anything not like me. So you get like a fully produced video that kind of resembles with your previous history or something like that.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So that was kind of the idea behind this pipeline just to see what we can do now if we just type in a question and we get the answer back in video format. So we're just going to wait for this. This is going to take some time. Maybe like 5 10 minutes and I'll take you back. Okay.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

So, you can see that is done now. That didn't take too long. I would say maybe 5 to 7 minutes. I would say 5 minutes. Okay.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So, let's pull up the video now and kind of watch the answer to will there be a season 3 of Severance in 2026. >> But Apple TV Plus has not yet officially renewed Severance [music] for a third season. Season 2 is scheduled to premiere on January 17th, 2025. [music] While the creators have planned for multiple seasons, a 2026 release remains unconfirmed [music] and depends on production timelines following the upcoming premiere. >> Okay, so I wouldn't say that answer was maybe the best, but that is with the pipeline.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

So, I looked this up and it says uh there has no uh it won't be released in 26, so there's no set date uh yet. That is kind of what I get from the AI overview I hear at least. Uh but other than the answer, I guess uh it worked out pretty good and it sounded and looked fine, I would say. So the purpose of the pipeline at least worked. We got kind of the animated VTuber style.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

She's kind of moving her lips and we use the voice and stuff. So I want to try one more more relevant question. So let's do the same, but this time I want to ask something very specific. So let's say what did Daario Amodai say about uh AI in Davos 2026 something like that. Yeah, just from the latest news.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

I'm going to run it one more time and let's see if we get like a very up to-date answer here. So we have that. So let's play it. So, I'm just going to open up in full screen and let's hear what did Dario Amade say in Davos. >> At at at Davos 2026, [music] Dario Amade criticized US chip exports to [music] China, likening the policy to selling nuclear weapons to North Korea.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

He predicted [music] AI would automate most software engineering tasks within a year. >> Okay, so it is up to date because uh I'm pretty sure that's what he said. He said something about comparing this to North Korea and he's also talked about uh yeah software engineering 2026 or something. So yeah, I would say this is working pretty good and and so far I think this new Quen model has been yeah kind of impressive to be honest. It's so small but it performs very well.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So I think my next step uh for testing this uh it's not going to be in this video but I want to try like a long input. So, I want to try something like 20 minutes just to see how well it's going to turn out. So, but that is going not going to be in this video. But, uh I think we kind of proved that we can build um a pipeline that kind of goes through all of these steps here using the local model too. So, Gemini 3 flash for the research, Quent 3 for the TTS and the Omnihuman model for on foul for generate the avatars and yeah, put everything together.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So yeah, maybe this gave you some inspiration of how you can use cloud code and maybe the new TTS model from Quen to do some yeah, workflows or pipelines like this. So yeah, have a good weekend and I'll see you again

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ25æ—¥

</div>
