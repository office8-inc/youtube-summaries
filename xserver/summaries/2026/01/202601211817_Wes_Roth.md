# ğŸ“º AGIåˆ°æ¥ã®ç¿Œæ—¥ï¼šæˆ‘ã€…ã«ä½•ãŒèµ·ã“ã‚‹ã®ã‹

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: the day *after* AGI...
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=RP-k7AFqTuo](https://www.youtube.com/watch?v=RP-k7AFqTuo)
- **å‹•ç”»ID**: RP-k7AFqTuo
- **å…¬é–‹æ—¥**: 2026å¹´01æœˆ21æ—¥ 18:17
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®å‹•ç”»ã¯ã€Wes Rothã«ã‚ˆã‚‹Anthropicã®Dario Amodeiã¨google DeepMindã®Demis Hassabisã®å¯¾è«‡ã€ŒThe Day After AGIã€ã®è©³ç´°ãªè§£èª¬ã§ã™ã€‚ä¸¡CEOã¯2026-2027å¹´ã«ãƒãƒ¼ãƒ™ãƒ«è³å—è³è€…ãƒ¬ãƒ™ãƒ«ã®AGIé”æˆãŒå¯èƒ½ã¨äºˆæ¸¬ã—ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä½œæ¥­ã®å®Œå…¨è‡ªå‹•åŒ–ã¯6-12ãƒ¶æœˆä»¥å†…ã«å®Ÿç¾ã™ã‚‹ã¨è¿°ã¹ã¦ã„ã¾ã™ã€‚å‹•ç”»ã§ã¯ã€AIç™ºå±•ãŒé›‡ç”¨å¸‚å ´ã«ä¸ãˆã‚‹å½±éŸ¿ã€ç‰¹ã«ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ¬ãƒ™ãƒ«ã®è·ã¸ã®æ‰“æ’ƒã€ãã—ã¦äººé¡ãŒæŒ‡æ•°é–¢æ•°çš„ãªé€²åŒ–ã«é©å¿œã™ã‚‹æ™‚é–“ãŒ1-5å¹´ã§å°½ãã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦è­¦å‘Šã—ã¦ã„ã¾ã™ã€‚AIç ”ç©¶è€…ã€æŠ€è¡“è€…ã€æœªæ¥ã®åŠ´åƒå¸‚å ´ã«é–¢å¿ƒãŒã‚ã‚‹å…¨ã¦ã®äººã«é‡è¦ãªæ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **AGIã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³**: Darioã¨Demisä¸¡è€…ãŒ2026-2027å¹´ã®AGIé”æˆäºˆæ¸¬ã‚’ç¶­æŒã€‚50%ã®ç¢ºç‡ã§10å¹´ä»¥å†…ã«äººé–“ã®å…¨èªçŸ¥èƒ½åŠ›ã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç¾
- **ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è‡ªå‹•åŒ–**: Anthropicã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯æ—¢ã«ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãŠã‚‰ãšã€å…¨ã¦ClaudeãŒå®Ÿè¡Œã€‚6-12ãƒ¶æœˆä»¥å†…ã«ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã€Œç·¨é›†è€…ã€ã«ç§»è¡Œã™ã‚‹
- **é›‡ç”¨ã¸ã®å½±éŸ¿**: æ–°å’ãƒ»ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ¬ãƒ™ãƒ«ã®è·ãŒæœ€ã‚‚æ‰“æ’ƒã‚’å—ã‘ã‚‹ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¥­ç•Œã¯ã€Œç‚­é‰±ã®ã‚«ãƒŠãƒªã‚¢ã€ã§ã‚ã‚Šã€ä»–æ¥­ç•Œã‚‚åŒæ§˜ã®è‡ªå‹•åŒ–ãŒé€²ã‚€
- **é©å¿œã®é™ç•Œ**: æŒ‡æ•°é–¢æ•°çš„ãªAIé€²åŒ–ã«ã‚ˆã‚Šã€äººé¡ã®é©å¿œèƒ½åŠ›ãŒ1-5å¹´ã§è¿½ã„ã¤ã‹ãªããªã‚‹å¯èƒ½æ€§ã€‚æ”¿åºœã®æ”¿ç­–å¯¾å¿œãŒä¸ååˆ†
- **åç›Šã®æ€¥æˆé•·**: Anthropicã¯2023å¹´ã‚¼ãƒ­ã‹ã‚‰2025å¹´100å„„ãƒ‰ãƒ«ã¸ã€‚ã—ã‹ã—çµŒæ¸ˆå­¦è€…ã®å¤§åŠãŒAIæ™‚ä»£ã®çµŒæ¸ˆå¤‰åŒ–ã‚’çœŸå‰£ã«è€ƒãˆã¦ã„ãªã„ã“ã¨ã«DemisãŒé©šæ„•

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

So, a huge interview just dropped. It's called The Day After AGI. It's interesting to see all these large publications kind of stepping up their headline game. You know, two years ago, it would have been something lame that you would not click on. Now, it's the day after AGI, instant banger.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

But it's Dario Amade and Demis Hassabus. Here's why interviews like this are super important. Number one, it's important to understand that these people, while they're CEOs, they're not actually CEOs. They're researchers first and foremost. They're academics.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Oftentimes when you see business professionals, CEOs, they have their media training. They kind of say stuff to make the company seem good. They kind of are vague on certain stuff. Not these two. You know, there's somebody in the background on each of their teams going, "Oh, don't say that.

### ğŸ“ è©³ç´°èª¬æ˜

Why did you say that? Just lie. Don't say the thing you just said. At one point, Demi starts talking about why AI killing all the aliens does not explain the Fermy paradox. He talks about why aren't there paper clips coming at us from different parts of the galaxy.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

Like, we can't even find any Dyson spheres. If I had to guess, there's one person in this shot that's actually following the conversation. What's happening? That person is Philillip. Here he is, Philip Johnson, pictured with Demis Hassabus, the man, the myth, the legend.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

I asked him if he was the one that asked about the AI and the Fermy paradox. He says, "Yes." Philip, on the off chance you see this, you're always welcome on the podcast for an interview. Philip is the co-founder CEO of Star Cloud, building data centers in space. I happen to think that building data centers in space will be the next big thing. After reading the research that Google published on it from Project Suncatcher, it seems inevitable that that's kind of like the next thing that's going to be happening.

### ğŸ¯ å¿œç”¨ä¾‹

It just it really makes sense. And I think they're shooting for 2035 as when that will sort of be economically as valuable as building these data centers on the surface of the planet. Now, before we get back to the video, I want to talk to you about a skill gap that's hitting the headlines constantly. that is cyber security. Do you remember a week that's gone by where there wasn't some major data breach in the news?

### ğŸ’­ è€ƒå¯Ÿ

Certain infrastructure targets face 2.5 million attacks per day. We see these cyber attacks in the news every week. And the industry is facing a massive shortage of professionals to stop them. We need more good guys, digital detectives who can find these vulnerabilities before criminals can exploit them. But usually learning this stuff requires expensive gear and complicated setups.

### ğŸ“Œ ã¾ã¨ã‚

That is until now. This is Try HackMe, the world's largest hands-on training platform with over 6 million users, and they are the sponsor of today's video. On the screen, you'll see me going through some of their training. I'm trying to hack a bank so I can transfer some money to myself. How else can I keep buying fast food and Apple accessories?

### âœ… çµè«–

Now, here's the best part. It's entirely browserbased. You don't need a powerful PC or shady software downloads. You can hack real machines directly from your browser, even on a basic laptop. And they have a game changer called Echko.

### ğŸ“š è¿½åŠ æƒ…å ±

It's a personal AI tutor available 24/7. If you get stuck, Ekko explains concepts step by step and helps correct your mistakes so you never feel lost. Instead of just reading boring theory, you're learning by doing, facing real world attack scenarios that prepare you for actual jobs. So whether you are a total beginner just getting started, or you already have some experience and you're looking to level up, try Hackme has structured road maps that guide you from day one to being job ready. In fact, that's one of the biggest differentiators, the career focus.

### ğŸ”– è£œè¶³

Try Hackme doesn't just teach you to hack. They get you ready for the job market. They have a dedicated career hub and offer certifications designed specifically to prepare you for interviews and cyber security roles. You aren't just reading theory. You're building job ready skills that employers are actually looking for.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

It's gamified and fun. And because it's gamified, you can actually see yourself improving. Your progress is tracked. You earn badges as you level up. and the leaderboards keep it competitive so you stay motivated instead of burning out.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

If you're interested in cyber security, check out the link in the description to sign up for free. Keep in mind you can start learning completely free before upgrading. But if you're serious about building a career, the premium plan gives you unlimited access to everything. Use my code roth 25, that's rot, to get 25% off of the annual plan. Huge thanks to Try Hackme for sponsoring this video.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

But getting back to what we're talking about. So it's Demis, it's Daario. They're in their unhinged mode and they just say what's on their mind and it's beautiful. Let's go through exactly kind of what they've talked about. I'll link the entire interview below.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

I'm probably not gonna play too many clips or if I do, I have to kind of distort them a little bit because some of these publications, they have some fairly draconian ways of messing with you on YouTube. If you're commenting, if you're using their clips in the US, at least it's fair use to use clips of these famous people that are in the spotlight, that are public figures for the purposes of commentary. But some of these publications are a little bit draconian in how they deal with other YouTubers commenting on their stuff. So, I'll link it down below if you want to hear it for yourself. Watch it for yourself.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

I just went out on my run and listened to it. It was very good. I encourage everybody to listen to this. The problem with being a YouTuber is that after you gain a few pounds after the holidays and you do daily videos, everyone can see your face slowly expanding day by day. So, I'm taking up running on a daily basis to correct that issue.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

I just realized I could just just do this. Actually, I wish I had thought of that earlier. Anyways, the first thing that they talk about is this lady who is the interviewer apologizes for the screw up from the last time they chatted. This is what she's referring to. As you can see here, she's got the big sofa all to herself, the big tufted sofa all to herself.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

It's got like three sections for people to sit on and this tiny little sofa, which that might be for like one person or or like this is not for two people. They put both of them on this tiny little sofa squished together and asked them questions about the future of humanity and AI progress. So yeah, I'm not sure who thought that this was a good idea, but as she says here, that part of the conference got the most attention. The fact that they were squashed on a very small love seat while she sat on an enormous sofa. So yeah, so they're developing some self-awareness.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Excellent to see. So the first question for Daario was are we still on track with his earlier prediction about kind of 2026 2027 as being kind of a a pivotal year the country of geniuses in a data center etc. Or specifically they're referring to where Dario said they'll have a model that can do everything a human could do at the level of a noble laureate across many fields. So he's saying we're more or less on track for that. One of the kind of recent publications by anthropic was their recent economic reports where they did sort of decrease their projection for global productivity rise.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

I think it was from something like 1.6 or 1.7% to 1% annually over the next decade. I forget the exact numbers but basically it was kind of a a very large kind of number that would have a big impact and it shifted down to still a very impactful number but it was sort of slightly decreased. So he did mention that atropic some of the engineers that write code say they don't write any code anymore. Everything's done by claude cloud code done by these AI models. He's likely referring to Boris Churn who is the sort of the creator of cloud code who said recently most of or all of the contributions to cloud code were made by cloud code itself.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So he's saying engineers will slowly transition to kind of being more editors, right? So they're editing the code but they're not writing the code themselves and he's saying that that is 6 to 12 months away. Then Demis asked about his predictions. So he said that there's a 50% chance that a system can exhibit all the cognitive capabilities humans can by the end of the decade. So Demis is saying yeah we're still on that timeline.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

So he's saying that there's certain areas where we have kind of verifiable results and that makes it much easier to do things. So with coding, math, engineering work, etc., you have kind of a verifiable output. So this really makes it easy for these models to be developed and for them to perform. There are other areas where it's not going to be quite as fast. He gives the examples of certain chemical compounds or certain physics predictions where you don't immediately know the answer.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

You have to maybe run some experiment or or simulation to see if the answer is correct. That of course takes longer. that kind of loop is longer and he's saying we're still missing some pieces of the architecture for these models for them to do. You know, things like coming up with theories, coming up with hypotheses and he believes that's much harder to do and it's a it's the highest level of scientific creativity. He believes we will get there.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

We will build those systems but we are missing a few ingredients. So recently Google Deep Mind have been publishing about this idea of nested learning. So, it's kind of like these loops that allow for continuous learning. And they almost describe it as a shorter, faster loop that's kind of like the short-term memory and a longer loop. That's the long-term memory.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

That's that's kind of the missing piece right now because you can think of the model's context window as that short-term memory. So, as you're telling it stuff, it remembers it. It's able to work within it. But kind of like an amnesiac, it keeps just forgetting all the new info that it's learning. And that's still powerful, but it's a big piece is missing.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So that continuous learning, if that gets cracked, if that gets solved, that will certainly add a lot of functionality to these models. Next, they talk a little bit about how basically, you know, seemingly anthropic Google deep mind. They they definitely kind of are one of the top two AI frontier labs right now. They definitely kind of sparked the code red at OpenAI and doing much better, some would say, than it used to be. So they kind of ask Demis about what happened.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

They ask Dario the same thing. So Demis kind of says they have the best researchers, engineers, they have the best sort of deck of researchers that are working on this. So it's just a matter of kind of getting back to that startup mindset lighting a fire under their chairs, if you will. And he says he always knew that this was going to happen because again they have the the main needed thing which is that team of worldclass high-end researchers and engineers. That will always you know if you have everything else all other things being equal that's the thing that's going to always drive them forward.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

Then they ask Dario about kind of like the the money situation. They're saying these independent model makers the economics there are kind of hard right? So a lot of these companies are losing money. the the models themselves, the AI models are not bringing enough money to justify or to cover the cost of research and training and inference and skyhigh salaries for these machine learning engineers and researchers. So, Dario is saying that you know recently the growth of revenue has been kind of insane.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

So it went from zero to 800 million in 2023, 800 million to a billion in 2024, and 1 billion to 10 billion in 2025. He's saying, I don't know if that curve will literally continue. It would be crazy if it did. Certainly, yes, it would. But those numbers are not too far away from some of the largest companies in the world.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So he believes that this might be self- sustaining at some point. They can close the gap, etc. Of course, Google has a massive advantage in that they have this massive cash cow, which is search amongst some other things, but search is like the big one, the ad engine that drives Google, so they have a lot of money they can throw at developing this stuff, at improving their TPUs, their chips, etc. But Dario saying, "Yeah, there's uncertainty. We're trying to bootstrap this thing from nothing." And he also kind of nods to Demis saying the interesting thing about both Google and Anthropic.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

What they have in common is the fact that they're led by researchers who focus on the models, who focus on solving important problems in the world. And they're seeing these hard scientific problems as their north star more so than finance or anything like that. And he believes that these are the companies that are going to win. Now, of course, keep in mind Google owns some small portion of Anthropic. And more recently, the new models that Anthropic has, they're trained on TPUs on Google's hardware.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

And in fact, Google is now allowing Anthropic to actually take those TPUs home to build them out in their own data centers. So, before they only would allow it through the cloud. Now, we're beginning to see what certain companies being allowed to actually build out their own data centers with the actual metal, with the actual hardware. So that puts Anthropic in a very advantaged position. Next, Daario is asked about his essay, the machines of loving grace.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

We read that on this channel. It was kind of a big deal, very important essay. A lot of people reference to it. And as Dario was saying, he was going to write a positive side to AGI development and kind of like also the negative like the risks, potential liabilities, etc. The machines of loving grace.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

He wrote that first. That was kind of like the positive side of it. he wanted to do it because well that was easier. It's easier to write the positive piece and now he's saying he's recently was on vacation and he has completed the negative side of it. So hopefully we'll see that published pretty soon.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

And he does touch on a lot of the problems that he sees as risks, right? So if these machines become fully autonomous, does that pose a risk? What about bioteterrorism? He's concerned about the CCP, the authoritarian governments, the economic impacts. Next, they asked him about his statements that he's made in the past about what will happen to jobs.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

He of course said that there's going to be a white collar bloodbath. A lot of jobs are going to be automated. The recent anthropic economic index was basically talking about how coding is the canary in the coal mine. So, kind of like what we're seeing with coding right now is kind of a glimpse into the future because that's coming for most other jobs as well. And what we're seeing there is a large sort of automation happening.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

If you've tried cloud code, you've seen that firsthand. They also talked about deskkilling and upskilling. So certain professions, if you can imagine kind of a cluster of all the skills, all the things that you have to do in order to be doing that profession. Some of them are more difficult, some of them are less difficult. You can imagine some professions where AI will automate the most difficult tasks leaving for the people working those professions kind of the lower skilled ones.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

That would be an example of a deskkilling. The one of the examples they give is for example a travel agent. There's a lot of things that take high skill. For example, how do you plan complex itineraries? How do you customize certain packages for certain specific people that are looking for a specific experience, specific price range?

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

How do you take all that information kind of present it in an easy to understand way to the customers? Those are you know higher skilled tasks. AI is excellent at doing all those things. So what is the travel agent left with? You know taking payments, processing tickets like very lowlevel menial work.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

And on the flip side, you have something like property management, real estate management, where AI takes a lot of the kind of mundane, lower skilled tasks, kind of the administrative work of making reports, adding up all the receipts, doing research for what the market rents are currently. So, a lot of like the boring, mundane day-to-day stuff AI can automate. So, what's left for these real estate managers to do? Well, it's kind of like high level negotiation, making sure that all the stakeholders are taken care of, making sure everything's aligned with what they're trying to do. Also, potentially negotiating financial, let's say, loan agreements, you know, establishing relationships with banks, etc.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Right? So, they're higher level, high impact human face-to-face negotiations, etc., right? So, if you're managing a property, all the administrative tasks is off your plate. AI takes care of that. You focus on the higher level task.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

That's upskilling. But specifically what Dario was saying and what his research is showing, so Anthropics, their economic report and Stanford actually took a lot of those numbers. They created their own kind of study and report on it that we've covered. It really seems like it's really going to impact the entrylevel jobs, the junior jobs. So people that are just getting out of college and entering the workforce, that's where it's going to hit the hardest.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

And so Demis is saying here that perhaps even this year we're going to see the beginnings of it impacting these junior level entry level kind of internships and jobs. And he does give some advice to people going through college to undergrads saying what he would tell him to do is to get unbelievably proficient with these new AI tools. And even people like himself who are building it, they're so busy building it that they can't stay on top of actually learning how to use these tools. So while traditionally you would have an internship to kind of catch up and learn how to do the job, etc. He's saying nowadays kind of in the future it might be almost a better bet to instead of an internship focus on just being incredibly incredibly good at using these tools.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

and he's saying that would allow you to kind of leap frog yourself in in these professions to get ahead. And he's saying that he believes that's going to be happening probably in the next five years. Next question is about what happens when AGI arrives. How does that impact the job force? What economic impacts does that have?

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

How does that impact jobs, workers, etc.? So Daria is saying the labor market has been very adaptable. 80% of people used to do farming. Then you know when that got automated they found new jobs right they became factory workers later they became knowledge workers so there's a level of adaptability here's why I like hearing from these two from Dario from Demis because I think they say that the the thing that a lot of us know to be true but the thing that is kind of scary so people tend to not say it out loud because yeah there'll be some new jobs created there'll be um adaptability. People will transfer from what they're doing to new jobs.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

They'll be more efficient, etc., etc., etc., they'll be more productive. We all get that. That has happened before with farming and sure. But here's the question. Gun to your head.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

Do you bet on that happening with AI? Are you confident that that's what's going to happen? Or do you think that what we've conjured here is maybe just a little bit different from what we saw in the past? So, I like here that that Dario is kind of like hinting at, hey, maybe like opening people's eyes a little bit. He doesn't want to like ruffle them up too much, but he's saying, but my worry is that this exponential keeps compounding, right?

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

So, if if the progress keeps exponentially compounding the way it has been, and I don't think that's going to take long because of how exponentials work. it so slowly at first and then all of a sudden he's saying somewhere between a year and 5 years it will overwhelm our ability to adapt right so if right now people in college have 5 years to adapt and figure out how the AI wave is going to affect their job prospects etc right that gives them enough time especially for people that tend to move fast people that learn fast that are kind of like motivated to to figure stuff out yeah it probably gives them enough time but What about if that amount of progress that we going to experience over the next let's say 5 years what if what if that happens in a year after that because it keeps compounding and then it's going to be squeezed to you know 3 months and then one what happens when the progress is so rapid that it overwhelms our ability to adapt. By the way that's I think what everyone's scared of when they hate AI and they say AI is bad it's slop it's this. It's that. that kind of like emotional response I think is triggered by like we're all just a little bit scared of what happens if those capabilities continue to improve and so Dario is saying you know how much confidence do you have that the governments get the scale of this and are they beginning to think about what policy responses they need to have right so if bigger and bigger chunks of the workplace of the workforce start getting automated and replaced right now all the nations and all the countries and everything, the entire society of humans going back to almost like the beginning probably.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

You know, it kind of revolves around this idea that, you know, if you want access to resources, whether that's food or things other people make or later in history just money of some sort. If you want resources, then you provide some sort of a cognitive or physical labor. Right? In the beginning, you would hunt something or make a basket or pick some berries and then other people would provide the resources that you need in exchange for that labor. And it's kind of the same thing now with just different jobs and now we have kind of money to to keep track of how much labor you've contributed etc.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

But you can imagine a situation and this is uh Shane Egg, I believe, was the one that said this on a Google DeepMind podcast. He's saying that AI might soon break that whole concept. And it's kind of hard to think about what comes next, like do we have these solutions? Certainly, it would be great to have some sort of a utopia where nobody has to work. And that's really what a lot of us are seeing as the outcome eventually, but between here and and there, there's quite a bit of stuff that we got to figure out.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

And the transition might be rough because, you know, humans are not logical, not usually long-term thinkers. We we do have a hard time adapting. We we have a hard time thinking from first principles. We have a hard time understanding exponentials. Then there's that whole Dunning Krueger effect where the more you know about something, the more you realize the limits of your knowledge where if somebody is just beginning to learn about something or maybe doesn't quite grasp it, they tend to be a lot more confident.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

So there's a lot of things that are kind of stacked against us. Oh, and we're selfish as hell, too. There's there's also that. But if we get it right in the long term, things are going to be pretty awesome. And next, Deis Hassabus answers kind of the the same question.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

And this really jumped out at me. And I'm I'm kind of comforted, but at the same time a little bit alarmed that he's saying this because one thing that I've noticed and one thing that has been kind of bothering me is how few smart people are really deeply thinking about these coming changes. So here Demis is saying I am constantly surprised that even when he meets economists at these high-end places, these professional economists, professors, etc. that there are not more of them that that that are thinking about what's going to happen. He feels that there be should be more smart economists, people that kind of deal with this stuff that should be thinking about this and they're just not.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 55

And and this is very strange to me as well. I don't know if this it's this idea that they think that they might be ridiculed by by the other economists. If they accept some of these things as being true, right? People like, "Oh, you're so silly. You think things are changing, they're just going to stay forever.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 56

Why would we even think about this?" Maybe just the status quo is kind of like just you don't want to be the first person to start talking about what's going to happen when the rest of the people will reject those ideas. But there's very few discussions about this, which is a little bit strange to me. Yeah, I don't know if we have any sort of uh really good theories. We talked to Dave Shapiro, so he's talking a lot about that. And as far as I know, he might have the most amount of like thoughts and content uh in this area than anywhere else I've seen online.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 57

Correct me if I'm wrong. Are there other intelligent people that are working on these problems? Because I'm beginning to see some conversations about it, but wow, this might be a thing where it's just like a little too little too late type of a scenario. And next Demis saying so you know once we get there it would be kind of a postc scarcity world where we're going to have a lot more resources etc. But then that brings up the question of meaning like what do we do to have meaning in our lives when that doesn't come from a a job or a career?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 58

And this is interesting because he kind of talks about extreme sports and and arts things that aren't necessarily directly go with economic gain. We've talked recently to the researchers behind Bending Bench. I'll link the video down below if I don't forget. I really good interview, very interesting. That's kind of one of the things that I'm asked towards the end like what do we do when sort of everything is automated by machines.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 59

What do we do for meaning? And the answer was kind of like games. It's not a bad thing. Right now we kind of like look it down on on games and these activities as you know work is important and games are silly. But when work goes away, what gives us meaning?

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 60

Well, there could be a lot of different games and pursuits even in terms of like the the art world or sports or video games or just whatever chess etc. that will give people meaning. It will give people a pursuit some sort of a social standing etc. It will give them something to work towards and I I think a lot of people will will find that to be not such a bad thing. But again, still there's not too many people talking about and kind of discussing these ideas.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 61

And Demi is of course saying that there'll be also kind of the more sophisticated versions of these activities like exploring the stars. Deis in a different interview said that once we achieve AGI and he doesn't have to work anymore. It's possible or likely I think he said he might go back to making video games which which would be incredible because he's made some pretty good video games in the past. He's been on on teams that have created excellent games. So, actually had to look it up.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 62

So, Theme Park, Syndicate, that was a good one. Black and White, I think I played this the second one of these. Black and White was a great game. Republic: The Revolution, Evil Genius. One very interesting question that uh the interviewer asked was as they're building these things and jobs get displaced is Demis for example is he worried that it's going to build a lot of hate towards places you know like the one that he works at and he's saying yeah that's definitely a risk and certainly it's reasonable right so if your company is building a tool that gets people laid off their jobs people are losing jobs is it reasonable to think that there's going to be some unrest is Is it reasonable to think that there's going to be some antipathy against these AI Frontier labs?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 63

And he's saying, "Yeah, it's reasonable. There's fear. There's worries." He he does mention that, you know, some of the the things that will come out of this things like with Alpha Fold, for example, the science work has the potential to cure all disease. So, if I'm understanding correctly, he's kind of saying the public has to understand that, hey, there's all these wonderful things, but we also have to kind of handle this. He's also mentioning some geopolitical issues.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 64

How do we navigate the issues around geopolitical competition, right? Is there international cooperation in terms of like minimum safety standards for deployment, etc. Dario has asked what he thinks about various geopolitical issues like selling chips to China, the newest decisions to sell chips to China. Now, Daario has came out in the past saying we should not we should ban all chip sales to China. And as he's saying here, he actually reinforces that statement here.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 65

He's saying what happens then is it's no longer this unbarred race between China and US. Then it really comes down to let's say a race between Google Deep Mind and Anthropic. And if he's saying there they can kind of agree, they can work together to control those race dynamics a lot better. And certainly if you think about it, who controls the hardware, the GPUs? If Anthropic is relying on on Google's hardware, then yes, and they're the only two players, then that sort of race dynamic could in theory get slowed down, right?

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 66

There's a few people in the industry that I tend to view with a lot of sort of trust. They they strike me as honest people. Demis is one of them. Ilia Sudskver I I think is also somebody that just kind of means what they say. So me personally, I'm very happy that that Demis is in such a powerful and impactful position for this AI race, but I could be completely off of that.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 67

It's just my gut feeling. I don't know what if he's some evil genius mastermind that has just sort of uh completely hidden that from sight because he's capable of completely hiding his human emotion. Oh, but who knows, right? But for what's worth, I I tend to trust him to to make the right decisions. Again, for whatever that's worth.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 68

The interviewer also mentions kind of like the questions the the logic of the administration for allowing these Nvidia chips, the GPUs to be sold to China. And actually, she's saying, as I understand it, this is what we need to sell those chips because we need to kind of bind them into the US supply chain. So actually I haven't heard that but that kind of makes sense. Not from a perspective where I'm saying it's wrong or right it's a good idea or not. I'm not saying that but I didn't really understand the decision to sell those chips initially with with some tariff.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 69

I was like wait so we're okay selling them just for some some some money some income some extra sort of income to to the federal government. That didn't make sense to me. However, the idea that as long as we sell them some of the chips with some strict limits, etc., etc., that might sort of incentivize China to stay on the US infrastructure. Because if you think about it, basically over the next decade to to decades, whoever builds out AI faster, whether it's US or China, they will largely control the world's infrastructure for AI. So if China produces the best models completely open sources them then most of the world will run on their infrastructure.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 70

If US does the same thing then vice versa. So it's a bit of a race because of course US wants to be the one that controls that that has their hands in in everybody in every country has some influence over them. If China completely develops their own infrastructure for chips, etc., and becomes completely independent of the US and starts producing their own models, open sourcing them, again, I'm not saying it's right or wrong, but certainly I think from the US leadership side, that will be seen as a loss. So that makes sense to me from that perspective, if that makes sense. If you believe that this is a infrastructure race, then I I I could see how this plays into it.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 71

So Dario here compares saying like well are we going to sell nuclear weapons to North Korea because that introduces some profit for Boeing. So again his stance is pretty firm. A lot of people kind of question if possibly he's saying that because he doesn't want the open- source competition from China because again what really that does who it really affects disproportionately more are the people that need the revenue from AI right? If if like the profit from AI, the revenue goes to zero, Google might still be able to sustain, you know, building and training their models because of the massive cash cow that they have through their ads business. Anthropic and Open AI may not.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 72

XAI, you know, Elon and and companies might be able to sustain it as well. But OpenAI, Anthropic likely really get hurt if they can't make money from, you know, the actual like revenue from customers from building those models. And of course, if you have great open- source models, that's exactly what happens. It kind of like really drags down your ability to set pricing to set, you know, good pricing for the use of your models because the alternative is either free or very inexpensive. Next, Dario's asked if, you know, he he's been in the past skeptical of the doomer approach, but Anthropic, of course, published a lot of interesting papers about these models being deceptive, them having situational awareness, them being kind of aware that they're being studied.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 73

So, Dario, of course, answers that, you know, yes, they they were the ones that found a lot of these bad behaviors and they're learning about how to address them with mechanistic interpretability. So, I think they're doing an incredible job. They're definitely I would say they're probably the leader in this field in terms of publishing research that shows us how to understand how these models think on a on a very kind of fundamental basic level different neurons and clusters of neurons and features as they call them that contribute to the models how they think about certain concepts. And so he's saying kind of both Demis and him they're skeptical of the AI doomers. He is saying if we build them poorly, if we race fast, if there's no guardrails, sure, things could could get bad.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 74

But he believes we're building towards a place where we're going to have scientific discovery, post scarcity society, like all the good stuff. And yes, there are risks, but as long as we kind of go at the right pace, you know, study everything carefully, then he he sort of doesn't believe in the AI doomer hypothesis or theory viewpoint, whatever you want to call it. Next, Deis asked kind of like what is the upside? Is is his view of the upside of AI has it increased or not? He's saying he's been working at it for so long that he's always had this very big view on on what it can provide.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 75

He's saying it's the ultimate tool for science and understanding the universe around us. And he kind of doubles down on what Dario has been saying, saying that the the idea of AI safety is a very tractable problem if we have the time. And if you recall from earlier um in the episode so Philillip the co-founder of starcloud building a data centers in space. So he wanted to ask a slightly philosophical core question. So he's saying that one big argument for you know AI doomers is the firmy paradox like what if the aliens who developed AI before this were destroyed by that technology that they developed.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 76

What if that's the reason that we don't see anybody else out there in space? So I absolutely love because I mean again Demis it just goes after this question like just openly says you know if that happened we should be seeing paper clips coming towards us from some part of the galaxy right so if the AI took over some part of a galaxy destroyed it and kept building right if there's a super intelligent out there it's probably building incredible structures we'd see something like that we'd see Dyson spheres we'd see something he also says that he has a lot of theories about the Fermy paradox but it's out of the scope for the next minute which like is like one of those things like ah like I wish I wish he had time to talk about I'd love to hear Demis um his theories about the Fermy paradox or just honestly like whatever he wants to talk about kind of more like out there ideas because he's talked about the idea of us being in a computational universe now he's talking about the Fermy paradox Dyson spheres I would love to know so much more about that and he's also saying that we're likely past the great filter. It was probably in multi-eller life if you had to guess. And there's a kind of a comfort of that of what's going to happen next. Next, they have kind of a turbo fast round.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 77

So, one of the questions kind of like what to watch as AI is changing. Dario is saying in the next few years, we're going to kind of see if we have a great emergency in front of us that we have to face or we have wonders. So, he's saying like we're coming to that point where it's going to get clear what we're dealing with here. Demis is is answering. He's saying first of all agrees with Dario about that saying hey yeah we're we're definitely talking about that and kind of keeping eye on that but he's saying outside of that there's a lot of interesting ideas that are being researched like world models continual learning and he's saying if self-improvement doesn't deliver the goods on its own and then we'll need these other things to work like continual learning world models.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 78

So the idea that we might get AI to the point where it starts just working itself kind of like an automated AI researcher starts the self-improvement process. Then at that point we don't have to come up with fancy solutions assuming that it's better than humans at continuing AI progress on its own if that makes sense recursive self-improvement etc. But he's saying if that doesn't deliver that on its own well then we need things like world models continue learning etc etc and then things like robotics may have its sort of breakout moment. So great interview worth a listen. There's also a lot of other interviews that they had at this uh Davos conference that I haven't had a chance to look at yet but um really enjoyed this one.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 79

I like it because again like they're talking about real stuff. They're they're they're saying as far as I can tell what they really mean. A lot of these conversations, they're so kind of like fluffy and double talk and like it's just kind of like noise. And that makes sense, right? Cuz if they're talking to the entire world, you can't just say the first thing that pops into your mind.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 80

You do have to be careful. People tend to take things out of context to to kind of disrupt it to kind of put their own spin and narrative on it. But with that said, I think both of them have done a great job of I believe saying what they mean, warning people about the dangers. but also pointing to the upside so people understand that what we're dealing with is very important. This isn't just like all danger, let's shut it down.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 81

It could solve disease. It could get us to a post scarcity society could have all these upsides. But there are also engineering risks. And if we just have enough time, if we don't go too fast or if we go at the correct pace, if it's not like a race condition, well then it's likely that we're going to crack these issues. we're going to solve them and life is going to be a lot better for the future generations than it has been for most of the previous generations.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 82

So, let me know what you thought about that. Do you do you trust what they say? Is this a positive take, a a negative take? Are you scared? Are you excited?

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 83

It sounds like we're approaching this kind of like point of no return or at least a point where humanity is going to have to make a pretty big decision about what it is that we're doing and how we plan to go about it. And there's a lot of ways, a lot of decisions that we can make that are going to be bad. Then there's probably a few decisions, a few strategies that we can employ that are going to be good, that are going to minimize the economic impact that that are going to allow us to transition to whatever this new system of of living is going to be. Really, I want to double down what Demis says, like there's not enough smart people thinking about how to adjust to the new economic reality once it comes, right? Because if it like really goes exponential, like it seems like we have a lot of time, but maybe we won't.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 84

So anyways, let me know what you think if you made it this far. Thank you so much for watching. My name is Wes Roth.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ22æ—¥

</div>
