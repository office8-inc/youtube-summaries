# ğŸ“º "RED QUEEN" AI means "GAME OVER" for us....

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: "RED QUEEN" AI means "GAME OVER" for us....
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=-EgTYDKtEw8](https://www.youtube.com/watch?v=-EgTYDKtEw8)
- **å‹•ç”»ID**: -EgTYDKtEw8
- **å…¬é–‹æ—¥**: 2026å¹´01æœˆ11æ—¥ 12:14
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

All right, so this video is going to be kind of insane. Now, we've covered Sakana AI before. They every once in a while come out and drop some of the craziest AI and machine learning papers, and usually they're about a certain theme, and the theme is recursively self-improving AI. Now, most people are probably already familiar with this concept and what it means. But basically, in a nutshell, there's this theory that is rapidly becoming a reality that at some point AI will be better able to do AI research than humans.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

So, you see this massive improvement in AI abilities that's driven by humans up until a certain point. And now more and more we see examples of sort of this protorecursive self-improvement. As Somali put it, we're in the laral stages of recursive self-improvement. And when AI becomes better than humans at doing AI research, something happens. We're not quite sure.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

We've never seen this before. We've never witnessed anything like it before. But you can think of it as an intelligence explosion. And the gap between that point and super intelligence, the time might be very very quick. So the moment it starts effectively self-improving, that intelligent explosion, that vertical takeoff, you know, gets us to super intelligence very very quickly.

### ğŸ“ è©³ç´°èª¬æ˜

Obviously, as you can imagine, these are uncharted waters. Kind of scary, kind of exciting. we we have no idea how that whole thing will unfold. A lot of the papers from Sakana AI deal with this idea of self-play, recursive self-improvement, etc. And the reason this selfplay is important is that we found when we teach these AI models on human data, they get pretty good.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

They get as good as the best data they have available as the best humans. For example, if Alpha Go playing against Lisa Dole playing the game of Go, etc. But when we make it play itself to try to improve its own abilities, right? So we kind of get two versions of it. They they play against each other trying to adapt their strategies and improving over time.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

And when they start, we don't even give it any hints or explanations. Like you just you figure out how to play the game. Here are the rules. Figure it out. You know, get good basically.

### ğŸ¯ å¿œç”¨ä¾‹

We see that it does indeed get good and rather quickly and gets better than the previous models better than humans. It gets like a superhuman ability to play that game. So it's almost like us trying to teach it slows down. It teaching itself makes it super human. By the way, I rewatched Terminator 2 the other day.

### ğŸ’­ è€ƒå¯Ÿ

It holds up. Some of these older movies just don't hold up if you're re-watching it now in the modern era. Terminator 2 holds up. It's still kind of awesome. So, we kind of know what these models were capable of when it came to selfplay and improving its own abilities.

### ğŸ“Œ ã¾ã¨ã‚

And that's been around for a while, but that was usually towards some narrow task like playing chess or playing Go, etc. Then, more recently, we got LLMs, which are a little bit more kind of general purpose. And a lot of the more interesting things that the researchers are doing recently is kind of trying to combine the two. How do we get these self-play self-improvement things? How do we get LMS to do that?

### âœ… çµè«–

And that's exactly what Sakana AI did here with a game called Core War. Here's kind of what Core War looks like. It doesn't look that great. This game was made apparently in 1984. It's I don't want to say basic, but I mean it's kind of like rudimentary, but at the same time kind of surprisingly deep once you understand all of the things that you can do.

### ğŸ“š è¿½åŠ æƒ…å ±

All right, so they're calling this the digital red queen adversarial program evolution in core war with LLMs. Now, the whole idea of a red queen, if you're not familiar, so apparently it's from Louis Carol, Alice in Wonderland or Alice Through the Looking Glass. So the idea is this red queen is saying, you know, here it takes all the running you can just to stay in the same place, right? So kind of like a treadmill, you have to run really, really fast just to stay in the in the same place or else you're going to fall behind. And if you want to get somewhere else, you must run at least twice as fast.

### ğŸ”– è£œè¶³

So I got to say they have really good naming conventions for their studies. Very memorable. Certainly this is no exception. So So DRQ, digital red queen is what they're calling it. So, in this video game, Core War is a programming game where self-replicating assembly programs called warriors compete for control of a virtual machine.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

In this dynamic environment where there's no distinction between code and data, warriors must crash opponents while defending themselves to survive. So, it took me a second to understand what this game is. It's it's actually kind of interesting once you fully grasp it. I think a lot of people will miss this paper because they don't understand what the game is, which is unfortunate. So, the premise is simple.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Before the game starts, you're writing basically some code for this tiny autonomous robot. And this robot is going to go out there in the world and try to kill all the other autonomous robots. And you have to program it to handle every possible scenario because once you release it, you cannot help it. So, you write some simple code like this. Then, you throw it into the world and it goes and it competes and tries to kill every other robot.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

So basically to understand the game, imagine like this is square one. It goes all the way across all the way across like this to the very end and it kind of loops over, right? So let's say it's like one to 2,000 and it starts over. So it's kind of like a just a big circle and you and the other players, they're kind of randomly thrown somewhere here by the the referee, the judge. So you sort of spawn in some random location.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So you kind of imagine a grid like this. And let's say the red player gets put over here and the blue player gets put over here. And you can imagine each of these little lines as a whiteboard that you can write whatever code that you want on. And that code will get executed when it's time for that code to get executed. And in the beginning, each one of these are bombs.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

Basically, if you execute that code, you sort of die, you lose the game, you crash, whatever you want to call it. And so they're sort of all the way across here. But remember that code for the autonomous robot that you wrote? You're basically able to kind of delete whatever was written here. and in the next four squares and basically write whatever you want in it, whatever code that you want.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

All right, so you're writing a code here, here, here, basically in every square, the five squares containing you and the next four squares. And in the next turn, you advance one forward and you write that same code on all those squares like moving forward. So, your player is basically marching forward one step at a time, rewriting that same instructions that you gave them at the beginning of the game before the game had started and just rewriting those instructions, moving forward, kind of advancing one at a time. And the blue person did the same thing. Okay, this is where it got a little complicated.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Took me a second to understand this, but think of the computer or the referee as basically having two hands like two fingers pointing and one by default, you know, it's pointing at where the blue player started. Let's call that the blue arrow. And the other one is the red arrow pointing at where the red player has started. And just like the player, it moves forward one space at the end of the turn. The only trick to it is that whatever code is written in that cell, it executes.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

So if the code says go back 10 paces, it goes back 10 paces. So you're able to control kind of where it goes and where it does. But if it marches all the way and steps on this on the bomb, then you lose, right? So if the red arrow if the red arrow you know jumps on a square that has the bomb the red player loses. And the commands can be something like put a bomb down to wherever you're looking or advanced five or look at what's in the cell and if there's no data there then proceed.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

If there's data there then put the bomb down cuz there's probably a player there. There's also ways to kind of multiply and try to split yourself like a hydra. They call it the hydra in order to be able to do multiple commands. But the point is, since 1984, people have been playing this game, competing in this game across the world, there's apparently something called the King of the Hill, where you write your code, you submitted to this sort of community, and then your little robot battles against the thousands of other robots and then you get back kind of its winning percentage. And over time, the leaders emerge, right?

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

So you have a certain people that tend to be, you know, at the top, but even if you're a beginner and your code is good, you can still win. You can still dominate. Is basically, can you write this autonomous code that destroys everybody else or at least, you know, statistically over time wins more often than the other people do. As you can imagine, there's a meta, right? So if everybody is going towards one specific strategy, then you know, it's kind of like rock paper scissors.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

There might be a different strategy that becomes the current meta because it beats the current most popular sort of meta. But the point here is that humans or you know whatever humans wanted to take part of this. We've been trying to create the best strategy since you know 1984. People take this very seriously. They play this game over time.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

The best coded human strategies evolve right through this kind of evolutionary of everybody fighting to be the king of the hill. So what did Sakon AI do? Well, they never show the large language models anything like this. They they had it self-play to try to come up with some strategies and see if through that kind of evolutionary self-play you would figure out how to create better strategies than we have in the last whatever 40 years. All right.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

So how well did these large language models do? I'm not going to read the whole thing. It's already complicated as it is. I probably lost a lot of people just explaining the rules of the game. But I felt it's it's important to understand how the game is played to to understand kind of the complexity of it.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

There's a lot of strategies including scanning or just jumping all over the place or just like bombing one square at a time. But what was the point behind this paper? What did they discover? So, couple of things here. First and foremost, as you can imagine, as these LMS play the battle, write new code, create new warriors, they do improve and the more rounds they are, the better and better they get.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

So, here fitness is basically what percentage of the time it's winning against all the various opponents. And a couple very interesting things emerged. Number one, it beat humans without ever seeing them. Right? So after running many many evolutions, sort of 250 iterations of evolution within round, it started beating the human champions without ever encountering them before.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So it's able to in isolation through selfplay develop these strategies, then take these strategies, go to quote unquote the real world, and start just beating everybody there. It also invented or or discovered the the meta kind of like the the most winningest strategy on its own. So just like humans over decades of playing this game figured out that you can have certain bombing runs that were effective or for example self-replication was very effective. So those kind of meta strategies we we took us decades to figure them out. these large language models playing just against theself over time figured out those meta strategies again without seeing them out in the wild without ever encountering all those other humanmade champions.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

One thing that this experiment kind of proves is that the best way to get these models to be smart to to kind of increase intelligence isn't just give it a textbook and say read this and memorize it. is to actually throw it into an open-ended arms race where it has to improve, where it has to constantly adapt to survive. That's the red queen effect. One very interesting thing about this AI is it can kind of read how how lethal a different code block is going to be. So, it can look at somebody's strategies just at the code just by looking at it, can predict if it's going to be good or bad without ever running the code.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

Just by looking at it, it can say, "Wow, that's a really good autonomous machine, really good warrior. this is one that's going to do very well or it's going to look at it and say that's that doesn't have a chance again without running that code just by looking at it. So this kind of suggests that LMS have a deep sort of intuitive understanding of code logic and the danger or its abilities. And of course the implications here are huge because this same approach can be used for example for cyber defense to advance cyber defense to discover realworld computer viruses and how to protect against them. Right?

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So instead of having it be taught in what already exists in the world, create these self-play environments where it just discovers it because again it it rediscovered all the stuff that the humans discovered all the strategies on its own. So if you do the same thing but for computer viruses, it's likely going to over time be able to figure out the the best ever computer viruses, the best ever patches for cyber security, etc. I really enjoyed this because previously with games like chess and games like Go, those were humanmade games that were created so kind of so our brains could understand it. This is a little bit different in that this is a what they call a touring complete sort of environment, meaning that you're able to execute code, therefore you can run any calculation, right? So there's not like five moves like a chess.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

There's a certain amount of legal moves you can make. This is a little bit different in that this is just code, right? there's kind of almost an infinite amount of things you can do. I mean there's a limit but it's it's vast and during complete does mean that a certain system or or machine if you give it enough time and memory and resources that could run any calculation, right? So there's certain things that are not during complete like a calculator like a basic calculator is not turning complete.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

There's tons of stuff that you you can't run on there. You need to memory and and logic and loops. Weirdly, Minecraft apparently is turning complete because you see people using those red or they red diamonds in the game to create calculators and LLMs. I had to look it up so you don't think I'm crazy. Red stone is what it's called apparently.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

So, somebody recreated not chai GPT but some smaller version of a large language model within Minecraft. So that means that just like Alpha Go and all those series models, they developed brand new strategies like move 37 was a very famous one where it was an example of machines kind of having creativity of sorts. Basically in the match against Lisa Dole, the world champion in the game of Go, Alpha Go made this move that everybody looked like the humans looked at and said, "Oh, wow. That's a mistake. That's a bad move." like we thought through our wisdom and our experience and all the games that we've seen, we thought it was a bad move because no human usually plays that move.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

Of course, later Alph Go ended up beating Lisa Dole and looking back at it, we realized, oh, that's actually a pretty good move. It was kind of a pivotal move towards the win. We didn't see the value of it until much much later. So the big point here if I have to kind of summarize it is that machines are able to create things that we as humans didn't come up with or or couldn't figure out or at the very least it's able to for example like in this kind of paper it's able to match a lot of the strategies. It sort of has this convergent evolution of strategies that over time matches the decades and decades of experience that humans did to get to the same conclusion.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

Right? So over decades thousands of people figure out oh these are some of the best strategies. Then we run these LLMs in their little pocket universe. They do a bunch of iterations. They're like, "Oh yeah, these are the best strategies." And they're right.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

Right. So decades of humans working together slowly trying to figure out the strategies and these large language models kind of rapidly getting to the same place. So I don't know if I did a good job of like explaining everything. I hope this captured your attention, captured your imagination. This was really hard to explain or maybe I'm just over complicated.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

I don't know. But I I did want to try it and attempt to try to kind of put this into perspective because for a lot of the progress that we're seeing with with AI, the sort of average person might not be able to to tell a difference like if Chad GBT got 10 times smarter, would the average person using Chad GBT really be able to to tell that it's 10 times smarter based on the questions that they ask and you know the interactions that they have? But at the same time, when we're running things like this, it's becoming kind of obvious that of of course these LLMs probably couldn't do this a year or two ago, right? So GPT 3.5 definitely would not be able to replicate, you know, the last decades of humans trying to figure out how to play this game effectively. But the new modern models can, right?

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

So the question is what happens 5 years, 10 years from now? We will be able to understand how it's coming up with those solutions less and less. it'll probably become a little bit more opaque to us, right? If you're interested in, you know, checking out for yourself, they do have a GitHub. It's open source, so you're able to just kind of download everything.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

I did install this, but now I need to kind of figure out all of this stuff here and see if I can actually run it. Looks like they have a visualization so you can see how that battle unfolds. And their data set of discovered warriors is coming soon. So, I'd be curious if you can kind of grab them from here and then go to the leaderboards. I don't know.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

I don't even know if they're still running it or not. I mean, I have really no idea if this community is still alive or not, but I'm sure some of them are still running, right? Like, I'm wondering if things like this would just completely destroy this competitive environment because the large language models will be able to come up with with the best possible warrior, the autonomous bot for any given meta, any given competition. How long is it before the top 100 people are using code written by LMS? Anyways, fun times ahead.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

Right now, as I'm recording this, everybody's losing their mind over Claude Code. So, again, it sounds like the latest iterations of Claude Code and GPT 5.2. I believe there's some inflection point where it went from good to some inflection point where people are like, okay, there's something really magical happening here. People are just building more and more apps, vibe coding more and more things. And of course, since these models are generally intelligent, that that also means that they're going to be better at stuff like this and everything else that requires this sort of thinking.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

If you enjoyed it, please give it a thumbs up. If you're not subscribed, please subscribe. That helps. Leave a comment and I'll see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ12æ—¥

</div>
