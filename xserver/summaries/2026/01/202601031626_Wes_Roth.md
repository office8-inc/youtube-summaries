# ğŸ“º Googleã®ã€Œç„¡é™å­¦ç¿’ã€ã¨OpenAIã®ã€ŒAIãƒšãƒ³ã€

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Google's "Infinite Learning" and OpenAI's leaked "AI Pen"
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Wes Roth
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=yCYGNXNKoqw](https://www.youtube.com/watch?v=yCYGNXNKoqw)
- **å‹•ç”»ID**: yCYGNXNKoqw
- **å…¬é–‹æ—¥**: 2026å¹´01æœˆ03æ—¥ 16:26
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

2026å¹´ã¯AIã®ã€Œç¶™ç¶šå­¦ç¿’ï¼ˆContinual Learningï¼‰ã€ã®å¹´ã«ãªã‚‹ã¨äºˆæ¸¬ã€‚Google DeepMindãŒç™ºè¡¨ã—ãŸNested Learningï¼ˆãƒã‚¹ãƒ†ãƒƒãƒ‰å­¦ç¿’ï¼‰ã«ã‚ˆã‚Šã€AIãŒäººé–“ã®è„³ã®ã‚ˆã†ã«çŸ­æœŸè¨˜æ†¶ã¨é•·æœŸè¨˜æ†¶ã‚’ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ã‚’è§£èª¬ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€OpenAIãŒé–‹ç™ºä¸­ã®ãƒšãƒ³å‹ãƒ‡ãƒã‚¤ã‚¹ã¯ã€ã‚«ãƒ¡ãƒ©ã¨ãƒã‚¤ã‚¯ã‚’æ­è¼‰ã—ã€æ‰‹æ›¸ããƒ¡ãƒ¢ã‚’è‡ªå‹•ã§ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦ChatGPTã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã€‚AIç ”ç©¶è€…ã‚„æœ€æ–°æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã«èˆˆå‘³ãŒã‚ã‚‹æ–¹ã€AIè£½å“ã®æœªæ¥ã‚’çŸ¥ã‚ŠãŸã„æ–¹ã«æœ€é©ãªå†…å®¹ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- **2026å¹´ã®AIãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬**: 2024å¹´ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€2025å¹´ã¯å¼·åŒ–å­¦ç¿’ã€2026å¹´ã¯ç¶™ç¶šå­¦ç¿’ï¼ˆContinual Learningï¼‰ã®å¹´ã«
- **Nested Learningé©å‘½**: Googleã®Ali BiruseãŒé–‹ç™ºã€äººé–“ã®è„³ã®ç¥çµŒå¯å¡‘æ€§ã‚’æ¨¡å€£ã—ã€çŸ­æœŸè¨˜æ†¶ã¨é•·æœŸè¨˜æ†¶ã‚’å®Ÿç¾
- **ã€Œé©šãã€ãŒå­¦ç¿’ã®éµ**: é‡è¦ãªæƒ…å ±ã‚’åˆ¤æ–­ã™ã‚‹åŸºæº–ã¨ã—ã¦ã€Œé©šãã€ï¼ˆæœŸå¾…ã¨ç¾å®Ÿã®ã‚®ãƒ£ãƒƒãƒ—ï¼‰ã‚’æ•°å­¦çš„ã«å®šç¾©ã—ã¦é•·æœŸè¨˜æ†¶åŒ–
- **Hope architecture**: Titansã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ãè‡ªå·±ä¿®æ­£å‹ã‚·ã‚¹ãƒ†ãƒ ã€ç„¡é™ãƒ«ãƒ¼ãƒ—å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã§ç¶™ç¶šçš„ã«è¨˜æ†¶ã‚’æœ€é©åŒ–
- **OpenAI AIãƒšãƒ³**: ã‚«ãƒ¡ãƒ©ã¨ãƒã‚¤ã‚¯æ­è¼‰ã®ãƒšãƒ³å‹ãƒ‡ãƒã‚¤ã‚¹ã€æ‰‹æ›¸ããƒ¡ãƒ¢ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ChatGPTã¨é€£æºå¯èƒ½

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

All right, so we just cruised into 2026. This year it's going to be big, but let's check out some of the AI happenings. First and foremost, this is somebody that's working for Google DeepMind. His name is Ronak Mald. So he's from Stanford doing reinforcement learning at Google DeepMind.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

Previously doing research at Windsurf, which was of course acquired by DeepMind. Actually, there's like three different companies that either acquired or tried to acquire Windsurf. But whatever the case, Ronic is saying this. 2024 was the year of the agents. 2025 was the year of reinforcement learning.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

2026 will be the year of continual learning. Now, tons of people had an issue with that whole thing about 2024 being the year of the agent. And obviously, depends if we're talking, you know, frontier development research, or we're talking adoption being put into actual use cases. But whatever, that's not even the point of the tweet. The point of the tweet is 2026 will be the year of continual learning.

### ğŸ“ è©³ç´°èª¬æ˜

In November of this year, Google research published this introducing nested learning, a new machine learning paradigm for continual learning. So notice this is Ali Biruse. So you'll be seeing that name quite a bit moving forward most likely. Here he is getting absolutely swarmed at one of the machine learning conventions talking about this nested learning. He was also behind the Titans architecture.

### ğŸ’¡ å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢

So, it definitely seems like Google has someone that's really focusing their time and attention on building out all the different architecture to make these machines, this machine learning to be better doing these tasks. And it does seem like they're mimicking how biology did it with human brains. from the nested learning blog post. They're saying that as great as the machine learning and LM progress has been, a few fundamental challenges persist, especially around continual learning, the ability for a model to acquire new knowledge and skills over time without forgetting the old ones. When it comes to continual learning and self-improvement, the human brain is the gold standard.

### ğŸ”§ æŠ€è¡“çš„è©³ç´°

It adapts through neuroplasticity. And that's the thing. While these large language models, they have a lot of like knowledge that they can rely on, they don't really have the ability to quickly learn new facts, skills, information to to adapt. You can think of it as crystallized intelligence versus fluid intelligence. Fluid intelligence in humans at least is usually at its highest when we're younger.

### ğŸ¯ å¿œç”¨ä¾‹

That's what allow us to quickly adapt to new situations to to learn from limited interactions with some new environment or some new puzzle or whatever that may be. Whereas crystallized intelligence is kind of drawing on your previous knowledge to be able to figure out what to do next. I think it's safe to say that's probably more common in older people. They can draw a lot on their past experience. So these large language models are kind of like grumpy old people.

### ğŸ’­ è€ƒå¯Ÿ

They don't do too well with anything new. They've lost their childlike wonder. How do we fix this? Well, if we're looking at the human brain, you know, there's a solution. Neuroplasticity.

### ğŸ“Œ ã¾ã¨ã‚

The remarkable capacity to change its structure in response to new experiences, memories, and learning. And so the paper the nested learning as as far as I can tell kind of my interpretation of it is this. We have the shortterm memory or at least that's the equivalent of what it would be in in the human brain. This is what allows you to listen to a story that somebody's telling you and not kind of lose track of the progress, you know, hopefully, but then you probably won't recall a lot of the details, let's say, you know, in 10 days or in 20 days. But as you go throughout your life, there are certain things that you do need to kind of store in that long-term memory.

### âœ… çµè«–

So you can think of that as kind of this other loop that's a little bit slower. There's less things that get stored in there. It doesn't update quite as fast. So you can think of it as kind of a quickly moving short-term memory that is very, you know, short-term updates fast and gets kind of like erased and reset pretty quickly. And then you have the long-term memory where you store things that you need, you know, for the long haul.

### ğŸ“š è¿½åŠ æƒ…å ±

And so in these large language models, we've had this short-term memory that's kind of like the context window, right? If you upload a bunch of documents and you ask it questions, it's going to be able to kind of remember what the documents are about and then answer your questions, there's only so much that it will hold in that short-term memory at any given time. And no matter how important that information is, it will never get stored to its long-term memory. Now, of course, a lot of these chatbots, they do have workarounds. They do have memory where some of your conversations, they kind of get summarized, kind of get stored like almost in a different file where it's like remember this about this person.

### ğŸ”– è£œè¶³

they like these things, whatever. But that's almost like a kind of like a hack. It's like a pseudo long-term memory. It's a workaround. What I believe Google DeepMind is doing here.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 13

What they're talking about is building something that's a little bit more, you know, quote unquote real, permanent. This long-term memory where you store important things. And the paper also goes into some detail about what important might mean. They kind of describe how do we sort of mathematically represent what's important, what's not. As an example, one of the things that they've talked about is surprise.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 14

Surprise is a kind of the difference between your world model, how you perceive the world to be and how it actually is. So when you're surprised by something, you have to kind of update your beliefs. And usually that means storing something in the long-term memory. So for example, if I told you that honey is made out of flower nectar, you're probably not that surprised. But if I told you that bees drink that nectar, it's kind of digested and then regurgitated into these little honeycomb looking things so that you know the water water evaporates and it thickens.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 15

It's basically bee puke. That delicious honey we all like. They put it into those little bare bottles because they don't want you thinking about what it actually is. And if you didn't know this before, there's a chance that we've just taken something from your short-term memory. Right?

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 16

So as you're watching this video, you'll remember some things, you'll forget some things. But if you didn't know about this B regurgitation, and that's where honey comes from, likely we took that thing from your short-term memory. We put it into your long-term memory. Now, next time you're at a party and somebody brings up honey, you can actually uh, you know, regurgitate this fact for them because it's important. It surprised you at the time that you've heard it and now it's stored in your long-term memory.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 17

So, if this or something like it is indeed what Google DeMine is working on and 2026 will be the year of continual learning, that certainly seems like a big big deal. The lack of continuous learning is seen by many as a big stumbling block for these large language models. If you recall that whole thing where people would ask it if there's such a thing as a seahorse emoji, these are some of the things you would get. I think some of it has been patched, but at the time it was absolutely hilarious because this large language model would erroneously think that there's a seahorse emoji and say, "Yes, of course, here it is. A horse." Then it kind of realizes it's not right.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 18

Kind of tries to back door. It's like, "Oh, well, no. Okay, so it's it's more like this." Puts a unicorn and a starfish. Realizes that's wrong. Goes, "Oh, just kidding.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 19

Here's the real one. Nope. Not this. And not this. Okay.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 20

Nope. Still wrong. Here it is for real." And then just outputs a whole string of different emojis. That's not it. It's got the little sweaty, laughing, uncomfortably face and goes, "Okay, okay, jokes aside, here's the real seahorse emoji.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 21

Nope, that's a seal. Nope, that's a shrimp." And it would go on like this for quite some time when the various large language models were playing a Pokemon when Claude did it in GPT5 and Gemini 3. They also kept doing the same silly mistakes. You'd think at some point they they kind of figure it out, but there wasn't anything that they had to update their their beliefs or update their their knowledge. they could write things down, but that's not quite the same as, you know, learning something on the fly.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 22

There was a movie called Momento that was kind of about this, a person that couldn't form any memories kind of past a certain point. So, no short-term memories were getting sent to the long-term memory. So, he had to actually just jot things down, even tattoo things on himself so that he would remember what he's trying to do. And with a lot of these goofy things that large language models do, it it kind of seems similar. Like unless it has a little sticky note somewhere that tells it something obvious that it learned, you know, 2 minutes ago, it might keep blindly stumbling into that thing over and over again.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 23

the ability to kind of figure out what what data is important, what learnings or or details, which ones are important, and then permanently adding it to its knowledge base, to its weights, however they they do that. That seems like a big big deal. It certainly could be. It could solve a lot of the issues that we're having today. If this is where things are going, if if this is correct and 2026 will be the year of continual learning, number one, I think Google's going to do pretty well.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 24

Number two, notice that they're publishing a lot of this information. They're they're sharing their research publicly. And I think we got to give them some credit for that because of course they were the original attention is all you need paper publishers. They've created the transformer architecture. They, you could say, really kind of kicked off this AI revolution that we're seeing.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 25

And here it is. They're publishing this proof of concept new design called Hope. It's a variant of the Titans architecture. The Titans architectures are long-term memory modules that prioritize memories based on how surprising they are. Right?

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 26

So, Honey is BPU. Ah, I didn't know that. I'll keep that in mind. You will remember this video next time you have honey. Believe me.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 27

Now, on top of that, Titan's architecture. What hope is adding? Hope is a self-modifying recurrent architecture that can take advantage of unbounded levels of inconext learning and also is augmented with CMS blocks to scale to larger context windows. So it can essentially optimize its own memory through a self-referential process creating an architecture with infinite looped learning levels. So Titans was published in December 2024.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 28

So just about almost exactly 1 year ago. And this paper we're looking at now that was roughly 11 months after that. So I must see Titans as more of a file drawer, right? So oh this is important. I'll file away.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 29

And you keep filing important things away based on some criteria, right? So if it's important, you file it into the file cabinet for later use. This new hope architecture is different. It's infinite looped learning levels as they put it here. So not only is it filing things away, but it's continuously shuffling and reorganizing and adding and forgetting.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 30

That's the important part, I think, because certain long-term memories, they slowly, it's okay to forget them if you're not referencing them quite as often. So if they're not that important, they should fade away over time. get replaced with new ones. So the human brain, I think, is exactly what they're describing here, right? It's infinite looped learning levels.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 31

So in 2024, we we really had no long-term memory. By 2025, we had the Titans. So this idea of filing it away into a filing cabinet. And now as we're entering 2026, we have kind of this next level, at least, you know, on paper, this this research showing us that we can have something more akin to the human brain with its continuous learning. So, wild times ahead.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 32

In other news, we finally kind of know what the new OpenAI device will look like. It will be a pen, or at least a pen-shaped device that integrates AI, aiming to become a third core device following the iPhone and the Mac so you can carry it in a pocket. You can wear it around your neck. It will feature a microphone and a camera to perceive and understand the user's surrounding environment. Interestingly, you'll be able to convert handwritten notes directly into text and instantly upload them to Chad GPT.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 33

this kind of interesting. So, if you have a pen, you can just jot down your notes. It doesn't even have to be a real pen. As long as you're jutting it down, you can kind of like just transcribe it as you're writing it. So, one, it'll be interesting to see how useful it is, what it looks like.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 34

Also, how the reception to it is going to be. Again, something that has a a camera and a microphone that could potentially be recording all the time. Certainly, people don't necessarily like seeing that in public. Sometimes, you know, if I hold up my phone, if I'm out somewhere, I hold my my phone like this as I'm read, you know, reading something or looking at it. People will look at me weird if they think that I'm recording them.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 35

We certainly heard some people attacked back in the days of Google Glasses or whether they were called the ones that would record or at least have the the ability to record just by, you know, having it on your face. So, that's a whole separate thing that we're going to have to kind of deal with. How well is this going to be received by, you know, the public at large? Interesting bit of news. Also, this is from the information.com.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 36

OpenAI ramps up audio AI efforts ahead of device. So, this is the device we're talking about. It looks like there's going to be its own special model that's going to be powering this device. So, the device is largely going to be audiobased. And it sounds like this new audio model is a lot better than the previous one.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 37

The previous one, I got to say, is pretty good. There's a little bit of a problem with how it handles interruptions because sometimes you almost have to start speaking and get through the first few words before it stops. Now, I don't know about you, but for me, whenever somebody sends me to the store to pick something up, I'm sure we've we've all had that experience, and they'll tell me, "Okay, get get items 1, two, and three. Make sure item three is this specific type." I I I already habitually I always answer the same thing. I'm like, "Text me what you need or or it's not happening." Coming back to our diagram of the short-term and the long-term memories in people with ADHD, you know, if this is the short-term memory, it kind of looks like like that.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 38

So, whatever you told me to get from the store, it's already gone. So, definitely something that's intelligently able to remind you of things like that. I mean, if it's really fully fleshed out, it's very effective, it's very good, I can see that being a a huge help to a great number of people. It can definitely help people that that struggle with certain things, struggle with a memory. It can help the elderly, you know, make sure they turn the the fire off on the stove before they leave the house, something like that.

### ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 39

It can help people that are forgetful, remind them of certain things. They can kind of quickly jot down notes. The ability to speak into to quickly take notes. There's less friction of doing that. And with AI, it's ability to kind of figure out what's important, what's not makes it easier for actually, you know, getting that information back to you when you need it.

### ğŸ’­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 40

And even if you're one of those people that just is always on top of everything and you're just running a life, in which case good for you have a cookie. I don't know. But even then, I feel like there will be some marginal benefit to having a device like this. Again, once it's working really really well with no issues, I'm finding myself reaching more and more for now. I use ChadBT and Gemini 3.

### ğŸ“Œ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 41

How much I use that model, the usage has really went up quite a bit since Gemini 3 got released. It's surprisingly good at a lot of things. I've seen an acquaintance of mine that has to deal with a person that has a certain personality disorder, some some condition, some divergence, whatever you want to call it. I'm just going to say it's it's BPD. That person has BPD.

### âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 42

You might know it from TV shows like The Sopranos. So Tony's mother has that personality disorder. Probably the sister, too. By the way, Eminem, Marshall Matters, apparently his mom. Same thing.

### ğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 43

Anyways, there's a few personality disorder in that kind of a cluster, borderline, narcissism, etc. that can be hard to diagnose. It can be hard to deal with. It can be extremely unpredictable, very damaging. I had a good friend of mine, acquaintance, somebody that I knew for for quite some time that was dealing with somebody with the BPD in their life and oftent times really struggling with it.

### ğŸ”– ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 44

But recently with the Gemini 3, they were able to, you know, put some of the conversations and some of the things that were happening into Gemini 3 and kind of get some insights into why they were happening. And I was really blown away by how well that worked. Often times, if there's some narcissistic rage or borderline rage, whatever you want to call it, it comes out as a very toxic thing and it's hard to keep your cool. And it's hard to understand why it's happening because it usually seems disconnected from reality. As we say here, it's like intense or inappropriate anger that seems out of proportion to the situation at hand.

### ğŸ¨ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 45

So, if you're on the receiving end of it, you're like, I don't know what is happening. I don't know where this is coming from. And it's it's really bad for relationships. And what I saw kind of happening firsthand, I don't know if it's firsthand cuz it was between two other people. I was just kind of observing it or at least this person friend of mine.

### ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 46

and I was able to put it into Gemini 3 to get some insights into what's happening and it very clearly outlined exactly what was going on. So, it took out all the anger, frustration, all the toxicity and really broke down kind of like the the root cause of what was happening. Now, of course, this could be really abused using a Gemini 3 to psycho diagnose other people can be a problem, can cause issues. in this particular case used intelligently, used carefully, used by somebody that that did a lot of research. They they understand the condition.

### âš¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 47

I mean, they they get what they're doing. They're just using this as almost like a dictionary. Like what I saw was night and day difference because of how easy it became to deal with that situation. I've tested this with some other situations that try to see how different people especially if they're neurode divergent or you want to call it or even if they had some events in their past that maybe are shaping how they behave giving something like Gemini 3 and I I have tested this with other models they're they're okay they're good Gemini 3 currently stands alone in its ability to get the kind of insight that that I've seen but it's incredibly incisive how it cuts to the root of the issue. You just got to you got to give it enough context and once you do it can really help navigate some of the more like turmoil parts of the relationships, understand other people's viewpoints.

### ğŸŒŸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 48

What we were talking about is the opening eyes, their their new device and audio model. Where it could be useful is for relationship advice, especially if you're dealing with something difficult. Obviously, there's all sorts of privacy and ethical concerns. Should you be recording a fight that you're having with a family member or significant other? Probably not.

### ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 49

At least, you know, not without their consent. But from my current perspective, I'm sure all of you had the situation where you're interacting with somebody and they're you completely just don't understand where they're coming from. Like you can't even believe that they are acting the way they are or they believe the things that they do. Like their behavior or their words seem disconnected from reality. I've recently just in the last 3 4 months have seen Gemini 3 specifically able to kind of translate what's happening that if if you give enough context about the person and what's going on it can often kind of shine the light on why they might be behaving that way and I've personally kind of went like wow I it really made me understand why certain behaviors are triggered the way they they are and that's of course like the first step towards understanding and resolving those issues.

### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 50

So there's there's a lot of power here, but of course also a lot of opportunity for misuse. Anyways, I plan to do a kind of a predictions for 2026. I probably should have been doing it for the last 2 years, but I haven't. But I'm going to start this year, make my predictions for what I think will happen in 2026, then review them at the end of 2026 here live to see what I was right about, what I was wrong about. But I can tell you one of the things will 100% be number one that will have more benchmarks that are testing long-term horizon kind of pursuing tasks over a long-term horizon.

### â­ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 51

That usually includes you need the ability to store information to do that kind of a long-term memory and this continual learning plays into that perfectly. So I think I'll tell you right now 2026 we'll see much more interesting benchmarks where these large language models will pursue goals as opposed to just you know getting a question correct or incorrect. And my second prediction is that we'll probably at least hear research and and things being kind of like rolled out in this area of continual learning. Maybe hopefully even see actual utilization in actual large language models that we work with. Maybe we'll see that with Gemini 4 or GBT 6 or Croc 5, Cloud 5, whatever it is.

### ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 52

Hopefully, we'll maybe even start seeing those being rolled out. And I think that's exactly where we're going to see a massive leap on those benchmarks. So, here's vending bench for example. also how these large language models, how well they're able to run a a vending machine over time, things like this, I believe once that continual learning gets perfected, improved, you know, installed, integrated, whatever you want to call it. I think a lot of these benchmarks, which are great, but I think we're going to see them really start to skyrocket with with that new ability.

### ğŸ’¡ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 53

I think right now for a lot of these benchmarks, the scaffolding, the stuff that you build around it really determines how well these large language models are able to how well they're able to navigate those environments. And it seems like right now they're little hacks or workarounds because these models don't have that kind of longterm memory updates. If that gets fixed, I think that would be a huge unlock. Anyways, let me know what you think if you made it this far. Thank you so much for watching.

### ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 54

My name is Wes Roth and I will see you in the next

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´01æœˆ03æ—¥

</div>
