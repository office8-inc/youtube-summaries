# ğŸ“º Automating an ANNOYING Video Effect ğŸ“¸

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: Automating an ANNOYING Video Effect ğŸ“¸
- **ãƒãƒ£ãƒ³ãƒãƒ«**: Coding with Lewis
- **å‹•ç”»URL**: [https://www.youtube.com/watch?v=DDJhn232eYw](https://www.youtube.com/watch?v=DDJhn232eYw)
- **å‹•ç”»ID**: DDJhn232eYw
- **å…¬é–‹æ—¥**: 2026å¹´02æœˆ12æ—¥ 03:35
- **å†ç”Ÿå›æ•°**: 0 å›
- **é«˜è©•ä¾¡æ•°**: 0

## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®æ—¥æœ¬èªå­—å¹•ï¼ˆè‡ªå‹•ç¿»è¨³å«ã‚€ï¼‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

### ğŸ¬ å°å…¥

I see this effect everywhere. So, I decided to automate it and open source it. In basically any documentary you watch, this effect is used to simulate virality or talking about a specific subject. And thanks to Python, we can actually do this pretty easily. You drag all the images in it and it converts it to grayscale.

### ğŸ“‹ èƒŒæ™¯ãƒ»æ¦‚è¦

It dinoises and then uses something called testact OCR to get the bounding box of a word which we compute the position and width and height. Now, this would normally take a while, but with cloud code, it was easy considering as a developer, I already know the requirements. Then when it just gets it wrong, I can just go in myself and fine-tune the details or just prompt. Again, vibe coding here, folks. Here's the result.

### â­ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ

Now, I'm a little bit mixed with coding with AI, but for scripts like this, that's not really important for reliability, it's great, but the need to understand how your code works has never been more important than it is today. Let me know your thoughts.

---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: 2026å¹´02æœˆ12æ—¥

</div>
