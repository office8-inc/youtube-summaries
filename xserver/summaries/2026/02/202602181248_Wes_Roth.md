# üì∫ GROK 4.20 is... different

## üìã ÂãïÁîªÊÉÖÂ†±

- **„Çø„Ç§„Éà„É´**: GROK 4.20 is... different
- **„ÉÅ„É£„É≥„Éç„É´**: Wes Roth
- **ÂãïÁîªURL**: [https://www.youtube.com/watch?v=d4tbdFpcuSQ](https://www.youtube.com/watch?v=d4tbdFpcuSQ)
- **ÂãïÁîªID**: d4tbdFpcuSQ
- **ÂÖ¨ÈñãÊó•**: 2026Âπ¥02Êúà18Êó• 12:48
- **ÂÜçÁîüÂõûÊï∞**: 0 Âõû
- **È´òË©ï‰æ°Êï∞**: 0

## üí° Ê¶ÇË¶Å

„Åì„ÅÆË®ò‰∫ã„ÅØ„ÄÅYouTubeÂãïÁîª„ÅÆÊó•Êú¨Ë™ûÂ≠óÂπïÔºàËá™ÂãïÁøªË®≥Âê´„ÇÄÔºâ„Åã„ÇâËá™ÂãïÁîüÊàê„Åï„Çå„ÅüË¶ÅÁ¥Ñ„Åß„Åô„ÄÇ

## ‚≠ê ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà

> üìå „Åì„ÅÆÂãïÁîª„ÅÆ‰∏ªË¶Å„Å™„Éà„Éî„ÉÉ„ÇØ„Å®„Éù„Ç§„É≥„Éà„Åå„Åì„Åì„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åô

## üìñ Ë©≥Á¥∞ÂÜÖÂÆπ

### üé¨ Â∞éÂÖ•

So today is the day we've all been waiting for. Grock 420 goes live. So that's Grock 4.2. The beta is beginning to roll out. And this model is weird because it's not really one model.

### üìã ËÉåÊôØ„ÉªÊ¶ÇË¶Å

It's actually four models arguing with each other before they talk to you. I'm not sure if anybody expected this. So Grock 4.0 introduces a four agent multi-agent collaboration system, but this isn't Grock Heavy. In Gro Heavy, you can have four agents running in parallel, but there those are four instances of separate agents. This this is different.

### ‚≠ê ‰∏ªË¶Å„Éù„Ç§„É≥„Éà

All right, so let's start with kind of the easy stuff and then go into kind of the more weird stuff. Okay, so we got the four agents. This is kind of the core innovation. So if you ask it a complex query, it triggers all four agents simultaneously. Our main agent, if you will, that's Grock.

### üìù Ë©≥Á¥∞Ë™¨Êòé

That's the captain of the ship. This is the coordinator. So he breaks down the tasks, hands off the tasks to different agents, formulates the strategy, right? He's the boss, he's the captain. He also apparently resolves conflict between the other agents and then he kind of sums everything up, synthesizes the final answer and presents it to you.

### üí° ÂÆü‰æã„Éª„Éá„É¢

So imagine Grock as a sort of on top of the pyramid and underneath him you have three employees or sub agents, however you want to think of that. First we have Harper. Harper is the research and facts agent. This is the fact checker. This is the one that's running realtime searches drinking from the X fire hose.

### üîß ÊäÄË°ìÁöÑË©≥Á¥∞

So, TwitterX has something like 68 million English tweets every single day, right? It's this fire hose of information. And Harper, that agent is the one that's like drinking it all in, trying to sort it, gathering evidence, verifying claims. And Harper is the reason why Grock 420 has a near real-time awareness of breaking events. In the short period of time that I've been messing around with Crock 420, I gotta say it seems much more up to-date, it has a lot more sources.

### üéØ ÂøúÁî®‰æã

And as of right now, for real-time data, if you need like real time updates, I don't think there's anything close even remotely close to this thing. The Gemini models are very good. They can search, they can search the web, find sources, etc., but nowhere as real time as Gro 420. Our next agent is Benjamin. This is the math, code, logic, etc.

### üí≠ ËÄÉÂØü

This is the rigorous thinker, step-by-step reasoning, mathematical proofs, computational verification, code generation, etc., etc. If Harper finds some data, Harper, remember that's our Twitter fire hose, real-time information research guy. If Harper finds some information, then Benjamin sort of stressed tests it, checks it, make sure that it passes the sniff test. And then we have the third agent. Can you guess kind of what that personality looks like?

### üìå „Åæ„Å®„ÇÅ

Right? We have the hustler, the real-time information guy, like the math, reasoning, etc. The third one here is Lucas. So, he's the creative balance type. He's kind of the wild card.

### ‚úÖ ÁµêË´ñ

He provides that sort of a divergent thinking, contrary opinion. He's that annoying person, the group that's willing to argue with you about anything and everything. I'm totally kidding. Obviously, no one's actually annoying. I mean some people are but my point is and this is kind of interesting how they built this is that we have noticed in a lot of these generations when you have multiple agents working together the models will often converge on one idea and the more they kind of talk about it the more they see that idea reflected in their context window the more they converge on it so a conversation between two models might go something like oh I think this might be a great idea another model goes oh yeah that's a great idea no it's a terrific idea it's the best idea ever and they just sort of keep doubling down on whatever what they came up with.

### üìö ËøΩÂä†ÊÉÖÂ†±

At least we've seen those instances before. If you're interested in that, you can check out our interview with the founders of Anden Labs. They're the people behind Vending Bench 1 and two, Vending Bench Arena. And they've seen that in a number of their simulations, as they've explained to us, where these models can converge on on some ideas and gets a little bit I don't want to say incestuous, but it kind of like they they just cling on one thing and they just roll with it. Interestingly, here the Lucas agent.

### üîñ Ë£úË∂≥

Again, theoretically, I I haven't had too much time to play with this. So, take some of the stuff a grain of salt. We're just kind of basing this on the first available information that we have. I'm not able to get Grock 420 with an API yet, so I can't really run it through the ringer quite yet. But if this is the case, then theoretically, Lucas would be kind of that contrarian opinion that would prevent the other agents from converging too quickly on some narrow answer.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 13

So, he kind of is that wildcard chaos that makes sure that people think outside the box. Speaking of AI video, we've all seen the AI tools, but as creators, we need something that actually fits into the professional workflow. Today's video is sponsored by Art List, and they just gave me early access to their brand new AI toolkit. Most AI tools are scattered. The AI toolkit brings image, video, and AI voiceover tools into one organized workspace, so you don't have to jump between five different tabs.

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 14

This isn't just another model. It's the first image model trained exclusively on artist's professional footage. Every generation is grounded in real cinematography with production ready color science and depth. For filmmakers, you can actually direct the look by using a dedicated style. >> You don't have to follow me anymore.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 15

>> I know, but I still want to. >> Like cinematic or commercial, interpreting prompts with insane accuracy. You get deeper controls with things like negative prompts, prompt guidance scales and the ability to use more reference images to really dial in your vision. Keep in mind, this is early access, so they're still polishing the mobile experience and finalizing features like voice cloning and speech to text. Whether you're just starting out with the AI starter plan or want the full premium catalog with Art List Max, there's a fit for every creator.

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 16

Use the link in the description to join over 50 million creators and start creating with the art list AI toolkit today. So you ask Grock 420 question and Grock the captain, right? I know it's a little bit confusing, but right, that's one of the sort of agents that's the main agent. Grock the captain analyzes the prompt, breaks it down into subtasks, and then just activates all agents simultaneously. All four agents start thinking in parallel, right?

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 17

So this is not sequential where they go one at a time go around the room asking for opinion. They they start processing it in parallel and they all think through it from their own special personalized perspective. Then this triggers an internal debate. These agents engage in kind of these peer review rounds. Harper the researcher will flag factual claims right double check like is that true?

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 18

Let me fact check it. Benjamin checks logic calculations etc. Lucas will spot various biases and things of that nature. They iteratively question and correct each other until they reach consensus. I just realized you might be wondering why I'm wearing sunglasses.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 19

I I scratched my face a little bit and I'm being super vague about it, but so I'm not trying to be cool or anything, but let's continue. So, they go through that group discussion. They kind of test each other, grill each other, give each other the fifth degree, and eventually reach consensus. And then at this point, Grock, the captain, one of the four agents, he kind of gathers all the strongest elements of each. He resolves the remaining disagreements and it delivers one coherent response.

### üìù „Çª„ÇØ„Ç∑„Éß„É≥ 20

Now, this is critical and this is kind of like where it gets a little bit weird. Maybe not weird, but it's new. It's novel because we've seen things like chat dev or autogen. In one of my previous videos, I talked about building a society of mind. So basically getting the best models are available, the four of them from the four labs to basically chat with one another and more or less kind of go through that same kind of round very very similar to what I just talked to you about with how Grockport 20 does it.

### üí° „Çª„ÇØ„Ç∑„Éß„É≥ 21

And I do that because there's tons of research in the past papers that we've covered in this channel that show that you know what that approach really does seem to work. It produces better ideas. These agents are greater than the sum of the parts. they come together and they're able to do more than they could, you know, individually or if you just sort of sum up their output. I hope that makes sense.

### üîß „Çª„ÇØ„Ç∑„Éß„É≥ 22

I'll give you one quick example. In my own experiments, I had these four agents building out something that basically checks to see if there's a new video online about a certain topic and then just kind of keeps track of that video, how it's sort of changing, and that uses the YouTube API to gather that data. And so Claude and Codeex, they're building that thing that I asked for, and they did it spectacularly. like they fulfilled all the criteria, it works, it gets the data that I need, it's like everything's perfect except for one detail and that is if I wanted to run those checks too often, then it would kind of run up a balance, right? So every API call costs a little bit of money.

### üéØ „Çª„ÇØ„Ç∑„Éß„É≥ 23

So if you want to update the thing, you know, every 5 minutes, every 10 minutes, that ends up costing quite a bit over, you know, weeks and months. So I kind of looked at that, I said, this might not be viable. But running it through that society of minds where every model kind of got to weigh in and kind of explain how it could be improved. Interestingly, this is kind of obvious in retrospect kind of looking back at it, but Gemini comes up with an idea. Now, Gemini is of course Google Deep Mind.

### üí≠ „Çª„ÇØ„Ç∑„Éß„É≥ 24

YouTube is part of that same umbrella corporation, part of Alphabet. So, maybe this should not have been a surprise, but the Gemini model says, "Hey, you know guys, what are you doing? Why don't you just use the RSS feed to check if there's a new video? And if there's a new video, then you can use the API to start gathering whatever data you need. But with the RSS feed, I mean, it's free.

### üìå „Çª„ÇØ„Ç∑„Éß„É≥ 25

You can run it an infinite amount of times a day. You could ping it every second if you wanted to. It's free. I'm sure you don't want to ping it every second, but my point is there isn't a a cost associated with it. And by using that to for just the checks to see if there's an update and then using the API which has a cost associated a limit associated with it.

### ‚úÖ „Çª„ÇØ„Ç∑„Éß„É≥ 26

This turned the app which would have cost maybe you know let's say 100 bucks a month or more if I wanted frequent check-ins. It turned it into it costing like pennies maybe potentially even free because it was below the free limit. Here's the thing. I don't think that the Gemini model could have designed the code as good as Opus 4.6 six or Codex 5.3. I feel like Google Deep Mind is getting ready to release their new model and I'm sure it will, but these are like the latest releases and currently the best at coding.

### üìö „Çª„ÇØ„Ç∑„Éß„É≥ 27

But Gemini did have this idea of how to, you know, make it very elegant. So just that idea of going around the room and asking every single model for its thoughts because they're very different models from different labs. I mean it created a piece of software that was much much better than any single one of them could. Sorry if that was a bit of a tangent, but the point is that this isn't exactly brand new. We've been talking about it for a few years.

### üîñ „Çª„ÇØ„Ç∑„Éß„É≥ 28

We've covered a few paper where they've demonstrated this. Google had a societies of mind paper that was interesting and tons of other papers that reference that paper that kind of built on top of it. So you might say, well, what's the big deal about this? This is just that, right? No, this, as far as we can tell, is something different.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 29

So what we were talking about with those models, that's kind of a user orchestrated framework, autogen or whatever. Several models kind of working together. So you can think of that as like four individuals in a room. Grock 4 heavy. You can think of it as four clones working together, right?

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 30

It's the same model clone four times or I guess it could be up to 32 times. This is different. This is almost like what? A hydra, a a fourheaded dragon, a cberus, I don't know what to call it, but it's it's kind of one model. So, it's baked into the inference.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 31

The agents share the model weights. They share the input context. Xi is saying that the sort of the marginal cost of running this is like one and a half times more than than using a single agent up to two and a half times more but not four times more as it would if you clone this thing four times and ran it in parallel. These debate rounds are short. They're RL optimized, right?

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 32

So there's reinforcement learning pressure for all four of them to work together to achieve better answers and there's just efficiency. This architecture minimizes waste. And we heard Elon Musk talking about the secret sauce that XAI has in in training Grock. Lots of the different researchers that have posted about it that are at XAI, they've referenced it kind of vaguely, but all of them kind of point to this idea that this is some special secret sauce for RL reinforcement learning. So if pre-training is like just reading through the textbooks and trying to absorb the knowledge, that's pre-training.

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 33

Reinforcement learning is kind of like doing the answers at the back of the book, right? So, you kind of look at the answer, you solve it, then you check to see if you're correct. If you're correct, you get a high five, you did it, and if you're wrong, well, you try again, and hopefully learn something, get better. So, this is a reinforcement learning. But definitely, it seems like they've cooked up something that's that's unique, that's different, they found some new approach.

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 34

It's kind of how like they advertise food. They're like, "Oh, now with more protein per serving or whatever, this kind of like that, but this is like more brains per brain or something." And of course, it was trained on the Colossus supercluster, right? We have, I think, 200,000 GPUs up and running. And I'm sure a lot of that power, a lot of those GPUs go burr went into RL with the RL training specifically for this new approach. So, it sounds like this is a three trillion parameter model, and it does have the mixture of experts architecture.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 35

But this thing that we're talking about with the four I mean agents for experts that's note that's not what we refer to as with the mixture of experts. You have some sort of a logic gate a router that figures out where your question needs to go and then routes it to that expert. This is different. This is a a debate style, right? So it's not routing.

### üìù „Çª„ÇØ„Ç∑„Éß„É≥ 36

It's everybody's talking. All the experts are talking. As far as I can tell, we haven't seen anything like this. Let me know down in the comments if if I'm wrong. Does anyone else has anything like this been published with this kind of a new approach?

### üí° „Çª„ÇØ„Ç∑„Éß„É≥ 37

Was there any papers out there kind of talking about it? Cuz this seems different from all the other stuff we saw. It's it's similar but but different. And if you're wondering, well, so what I mean, does it perform better at anything? You know, the benchmarks are just beginning to roll out.

### üîß „Çª„ÇØ„Ç∑„Éß„É≥ 38

And Elon Musk did say that they're not focusing on kind of those standard static benchmarks anymore. So, we're not interested in humanity's last exam or anything like that. Right now, we're more interested in actual kind of agentic performance. Can you pursue a task over some long horizon? Can you, you know, not go off the rails, remember what you're doing, etc.

### üéØ „Çª„ÇØ„Ç∑„Éß„É≥ 39

So, actual useful realworld stuff. And so the benchmarks that we've seen that featured Gro 420 before its release, I got to say they were very interesting. We've have the alpha arena season 1.5. That's our live stock trading. Everybody can follow along.

### üí≠ „Çª„ÇØ„Ç∑„Éß„É≥ 40

It's actually on the blockchain. So all the transactions can be verified and they had every single model, both the open- source models as well, you know, the Chinese models and the western labs, everybody participated there. Now, of course, over time, the several weeks that that arena ran, most of them lost money. How they did it is each model participated in sort of four variations. One is sort of the standard one, another one, it's aware that it's competing against the other models.

### üìå „Çª„ÇØ„Ç∑„Éß„É≥ 41

One was more focused on capital preservation. I forget all the scenarios, but each had its own sort of flavor to it. So, each model, opening eye, Google, every single model had sort of four variants. All those lost money. All of those were in the red once the competition finished except for the four models that were the Gro 4.2 variety.

### ‚úÖ „Çª„ÇØ„Ç∑„Éß„É≥ 42

They were the only profitable models returned something like 35% over those few weeks that it ran. What's interesting is at the time I assumed that they were sort of not getting real-time news or at least they weren't searching for real-time news themselves. with each kind of day that passed or whatever time unit that passed for the alpha arena simulation, they were prompted with the current sort of here's what the market's doing. Here's how much your stocks are worth. Here's some news that that's happening currently.

### üìö „Çª„ÇØ„Ç∑„Éß„É≥ 43

And then these models made decisions kind of based on that. Now, interestingly, I think since Grock 4.2 to since it had whatever the name of the first agent I guess Harper right the real time researcher it sounds like it was just going through in real time through the entire Twitter/X kind of a data feed the the massive fire hose of information and I mean that must have been used in the calculations right if it's one model you can't really shut off that part of the brain it has to be included in there I'm just guessing but it's going to be very interesting to see hopefully we get some more information on this this is kind of fascinating so currently in the LM arena which is a very speced kind of a leaderboard in how well these models are able to do right we have claude opus 4.6 six at the top and it has an ELO score of 1506 at you know kind of text the main kind of ranking at code it has an ELO rating of 1561 so at text kind of normal one is 1506 that's the top score um then Grock 4.1 thinking is at 1483 or thereabouts with all the stuff that we're seeing here I would not be surprised if once Grock 420 is fully ranked and everybody votes on their favorite models that it's going to land at the number one overall position. I don't know if it's going to happen or not, but I just I would not be surprised if it jumps to the front of the line. Of course, Pliny, the Liberator, the notorious gel breaker of models, already broke Grock 420 and the entire system prompt is posted online on his account if you want to check it out. A big part of it is how to handle politically incorrect questions or how to handle what happens if there's a politically incorrect answer to the user's query.

### üîñ „Çª„ÇØ„Ç∑„Éß„É≥ 44

And the main kind of steering for that is saying that you can say these politically incorrect things as long as you can kind of back them up. So it's not going to shy away from subjects that other models might kind of delicately handle. It will tell you the thing that it thinks and uh give you sources for it. And of course, keep in mind that XAI is one of the few companies that does open source their prompts on GitHub. So you'll be able to go there and see everything they've open sourced.

### üé® „Çª„ÇØ„Ç∑„Éß„É≥ 45

You can see what kind of system prompts are running any given model of Grock. Grock 420 isn't there yet, but every single model, as far as I can tell, up to that point up to, you know, yesterday, let's say it is in there. You can see the the system prompts. So, let me know what you think about that. It seems kind of awesome.

### üöÄ „Çª„ÇØ„Ç∑„Éß„É≥ 46

I'm going to be playing around with it quite a bit more in the short testing window that I've done with it. Mainly, I've been focusing on real time information. I haven't been able to test too much of it outside of that. But when it comes to real time, upto-date information, organized, verified, fact checked. From that perspective, this thing is looking good.

### ‚ö° „Çª„ÇØ„Ç∑„Éß„É≥ 47

In 30 seconds, it returned an answer to a query that had 28 sources. One of the sources was next big future.com written by Brian Wang, who actually covered some of the stuff that that I've talked about here. Excellent source of information. So definitely kudos to him for writing such an action-packed blog talking about XAI and this new release. This is the first time I've heard of his blog and just looking at some of the other stuff that he's posted, I kind of want to read more.

### üåü „Çª„ÇØ„Ç∑„Éß„É≥ 48

So it definitely seems like Grock 420 is not just choosing a very high quality sources to kind of get information from. It also is able to find them very quickly to find a lot of them and kind of aggregate all the info into an very easy to find, easy to follow write up. And by the way, I'll leave a link down below with a full write up. I'm trying something different on the blog and uh I'll be talking about in the upcoming videos, but it's something that I'm very excited about. So, if you have a second, check out that link down below and check out natural20.com.

### üé¨ „Çª„ÇØ„Ç∑„Éß„É≥ 49

That's natural20.com. The new version just went live today and it's uh also a little bit different from stuff that we've seen in the past. So, I'll talk about that in a future video, but uh yeah, check it out. Let me know what you think about Gro 420 as well. What are your initial impressions of it?

### üìã „Çª„ÇØ„Ç∑„Éß„É≥ 50

If you want to test it out, go to grock.com. That's probably the the easiest way of doing it on your phone. You got to get the Grock app. But I'll have all the show notes and all that stuff in the link down below. So, thank you for watching.

### ‚≠ê „Çª„ÇØ„Ç∑„Éß„É≥ 51

I'll see you in the next

---

<div align="center">

**üìù „Åì„ÅÆË®ò‰∫ã„ÅØËá™ÂãïÁîüÊàê„Åï„Çå„Åü„ÇÇ„ÅÆ„Åß„Åô**

ÁîüÊàêÊó•: 2026Âπ¥02Êúà18Êó•

</div>
