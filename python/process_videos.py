"""
æ–°ç€å‹•ç”»ã‚’ä¸€æ‹¬å‡¦ç†ã—ã¦ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import json
from datetime import datetime
from improved_summarize_youtube import main as summarize_video
from github import Github
from dotenv import load_dotenv
import pytz

load_dotenv()

GH_TOKEN = os.getenv('GH_TOKEN')
GITHUB_REPO = os.getenv('GITHUB_REPO')
QUALITY_THRESHOLD = 50  # ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ã®é–¾å€¤


def create_output_directory(video_info):
    """å‹•ç”»æƒ…å ±ã‹ã‚‰å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    jst = pytz.timezone('Asia/Tokyo')
    published_at = datetime.fromisoformat(video_info['published_at'].replace('Z', '+00:00'))
    published_jst = published_at.astimezone(jst)
    
    year = published_jst.strftime('%Y')
    month = published_jst.strftime('%m')
    
    output_dir = os.path.join('summaries', year, month)
    os.makedirs(output_dir, exist_ok=True)
    
    return output_dir


def create_github_issue(video_info, quality_score, file_path):
    """ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒä½ã„å ´åˆã«GitHub Issueã‚’ä½œæˆ"""
    if not GITHUB_TOKEN or not GITHUB_REPO:
        print("âš ï¸  GitHubè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“ã€‚Issueã‚’ä½œæˆã§ãã¾ã›ã‚“ã€‚")
        return None
    
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(GITHUB_REPO)
        
        title = f"ğŸ“ è¦ç´„ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦: {video_info['title']}"
        body = f"""## è¦ç´„è¨˜äº‹ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒä½ã„ãŸã‚ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦ã§ã™

### å‹•ç”»æƒ…å ±
- **ã‚¿ã‚¤ãƒˆãƒ«**: {video_info['title']}
- **ãƒãƒ£ãƒ³ãƒãƒ«**: {video_info['channel']}
- **URL**: {video_info['url']}
- **æŠ•ç¨¿æ—¥**: {video_info['published_at']}

### ã‚¯ã‚ªãƒªãƒ†ã‚£è©•ä¾¡
- **ã‚¹ã‚³ã‚¢**: {quality_score}/100
- **é–¾å€¤**: {QUALITY_THRESHOLD}/100

### ãƒ•ã‚¡ã‚¤ãƒ«
- `{file_path}`

### å¯¾å¿œæ–¹æ³•

1. ç”Ÿæˆã•ã‚ŒãŸMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
2. å†…å®¹ã‚’æ‰‹å‹•ã§ä¿®æ­£ãƒ»æ”¹å–„
3. å•é¡Œãªã‘ã‚Œã°ã“ã®Issueã‚’ã‚¯ãƒ­ãƒ¼ã‚º
4. å‰Šé™¤ã™ã‚‹å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ã‚¯ãƒ­ãƒ¼ã‚º

---

âš ï¸ **è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ãŒä¸ååˆ†ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™**
"""
        
        issue = repo.create_issue(
            title=title,
            body=body,
            labels=['review-needed', 'auto-generated']
        )
        
        print(f"âœ“ GitHub Issueã‚’ä½œæˆã—ã¾ã—ãŸ: #{issue.number}")
        return issue.number
        
    except Exception as e:
        print(f"GitHub Issueã®ä½œæˆã«å¤±æ•—: {e}")
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # æ–°ç€å‹•ç”»ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    if not os.path.exists('new_videos.json'):
        print("new_videos.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    with open('new_videos.json', 'r', encoding='utf-8') as f:
        videos = json.load(f)
    
    if not videos:
        print("å‡¦ç†ã™ã‚‹å‹•ç”»ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"å‡¦ç†é–‹å§‹: {len(videos)}ä»¶ã®å‹•ç”»")
    
    results = []
    processed_video_ids = []
    
    for i, video in enumerate(videos, 1):
        print(f"\n[{i}/{len(videos)}] {video['title']}")
        print(f"  ãƒãƒ£ãƒ³ãƒãƒ«: {video['channel']}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        output_dir = create_output_directory(video)
        
        # è¦ç´„è¨˜äº‹ã‚’ç”Ÿæˆ
        try:
            result = summarize_video(video['url'], output_dir)
            
            if result:
                processed_video_ids.append(video['video_id'])
                
                # ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
                if result['quality_score'] < QUALITY_THRESHOLD:
                    print(f"  âš ï¸  ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ä½: {result['quality_score']}/100")
                    issue_number = create_github_issue(
                        video, 
                        result['quality_score'],
                        result['file_path']
                    )
                    result['needs_review'] = True
                    result['issue_number'] = issue_number
                else:
                    print(f"  âœ“ ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {result['quality_score']}/100")
                    result['needs_review'] = False
                
                results.append({
                    'video': video,
                    'result': result
                })
            else:
                print(f"  âœ— å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        except Exception as e:
            print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å‡¦ç†æ¸ˆã¿å‹•ç”»IDã‚’ä¿å­˜
    if processed_video_ids:
        # æ—¢å­˜ã®å‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        if os.path.exists('processed_videos.json'):
            with open('processed_videos.json', 'r', encoding='utf-8') as f:
                existing_ids = json.load(f)
        else:
            existing_ids = []
        
        # æ–°ã—ã„IDã‚’è¿½åŠ 
        all_ids = list(set(existing_ids + processed_video_ids))
        
        with open('processed_videos.json', 'w', encoding='utf-8') as f:
            json.dump(all_ids, f, indent=2)
        
        print(f"\nâœ“ {len(processed_video_ids)}ä»¶ã®å‹•ç”»ã‚’å‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆã«è¿½åŠ ")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "="*50)
    print("å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("="*50)
    print(f"ç·å‡¦ç†æ•°: {len(results)}")
    print(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦: {sum(1 for r in results if r['result'].get('needs_review', False))}")
    print(f"å•é¡Œãªã—: {sum(1 for r in results if not r['result'].get('needs_review', False))}")
    
    # çµæœã‚’ä¿å­˜
    with open('process_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)


if __name__ == "__main__":
    main()
