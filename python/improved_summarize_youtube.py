"""
YouTubeå‹•ç”»ã‚’è¦ç´„è¨˜äº‹ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
æ—¥æœ¬èªåŒ–ã¨è£…é£¾ã‚’è‡ªå‹•ã§è¡Œã„ã¾ã™
"""
import sys
import os
import re
import json
import subprocess
import pytz
from datetime import datetime
from youtube_transcript_api import YouTubeTranscriptApi
from googleapiclient.discovery import build
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')


def get_channel_id(channel_url):
    """ãƒãƒ£ãƒ³ãƒãƒ«URLã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’æŠ½å‡º"""
    # @handleå½¢å¼
    handle_match = re.search(r'@([\w-]+)', channel_url)
    if handle_match:
        # YouTube Data APIã§ãƒãƒ³ãƒ‰ãƒ«ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—
        if YOUTUBE_API_KEY:
            try:
                youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
                request = youtube.search().list(
                    part='snippet',
                    q=f'@{handle_match.group(1)}',
                    type='channel',
                    maxResults=1
                )
                response = request.execute()
                if response['items']:
                    return response['items'][0]['snippet']['channelId']
            except Exception as e:
                print(f"ãƒãƒ³ãƒ‰ãƒ«ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # UC...å½¢å¼ã®ãƒãƒ£ãƒ³ãƒãƒ«ID
    channel_id_match = re.search(r'(UC[\w-]{22})', channel_url)
    if channel_id_match:
        return channel_id_match.group(1)
    
    # /channel/å½¢å¼
    channel_match = re.search(r'/channel/(UC[\w-]{22})', channel_url)
    if channel_match:
        return channel_match.group(1)
    
    return None


def get_channel_latest_videos(channel_id, max_results=10, output_dir=None):
    """ãƒãƒ£ãƒ³ãƒãƒ«ã®æœªå‡¦ç†å‹•ç”»ã‚’å–å¾—ï¼ˆæ—¢ã«å‡¦ç†æ¸ˆã¿ã®å‹•ç”»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸é€²ã‚€ï¼‰"""
    if not YOUTUBE_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: YOUTUBE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return []
    
    try:
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆIDã‚’å–å¾—
        channel_request = youtube.channels().list(
            part='contentDetails',
            id=channel_id
        )
        channel_response = channel_request.execute()
        
        if not channel_response['items']:
            print(f"ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {channel_id}")
            return []
        
        uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        
        # æœªå‡¦ç†ã®å‹•ç”»ã‚’max_resultsä»¶é›†ã‚ã‚‹ã¾ã§ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        unprocessed_videos = []
        next_page_token = None
        total_checked = 0
        
        while len(unprocessed_videos) < max_results:
            # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã‚’å–å¾—
            playlist_request = youtube.playlistItems().list(
                part='snippet',
                playlistId=uploads_playlist_id,
                maxResults=50,  # 1å›ã‚ãŸã‚Šæœ€å¤§50ä»¶å–å¾—
                pageToken=next_page_token
            )
            playlist_response = playlist_request.execute()
            
            if not playlist_response['items']:
                break  # ã“ã‚Œä»¥ä¸Šå‹•ç”»ãŒãªã„
            
            # å„å‹•ç”»ã‚’ãƒã‚§ãƒƒã‚¯
            for item in playlist_response['items']:
                video_id = item['snippet']['resourceId']['videoId']
                total_checked += 1
                
                # æ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
                if output_dir and is_video_processed(video_id, output_dir):
                    continue  # ã‚¹ã‚­ãƒƒãƒ—
                
                # æœªå‡¦ç†ã®å‹•ç”»ã‚’è¿½åŠ 
                unprocessed_videos.append({
                    'video_id': video_id,
                    'title': item['snippet']['title'],
                    'url': f'https://www.youtube.com/watch?v={video_id}',
                    'published_at': item['snippet']['publishedAt']
                })
                
                # å¿…è¦ãªä»¶æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
                if len(unprocessed_videos) >= max_results:
                    break
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            next_page_token = playlist_response.get('nextPageToken')
            if not next_page_token:
                break  # ã“ã‚Œä»¥ä¸Šãƒšãƒ¼ã‚¸ãŒãªã„
        
        if total_checked > 0:
            print(f"  ãƒã‚§ãƒƒã‚¯ã—ãŸå‹•ç”»æ•°: {total_checked}ä»¶")
            print(f"  æœªå‡¦ç†ã®å‹•ç”»: {len(unprocessed_videos)}ä»¶")
        
        return unprocessed_videos
    
    except Exception as e:
        print(f"ãƒãƒ£ãƒ³ãƒãƒ«å‹•ç”»å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def parse_channel_list(file_path='channel-list.md'):
    """channel-list.mdã‚’è§£æã—ã¦ãƒãƒ£ãƒ³ãƒãƒ«URLãƒªã‚¹ãƒˆã‚’å–å¾—"""
    if not os.path.exists(file_path):
        print(f"ã‚¨ãƒ©ãƒ¼: {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ»ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’é™¤å¤–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    exclude_patterns = [
        '@channelname',
        'UCxxxxxxxxxxxxxxxxxxxxxx',
        '/channel/UCxxxxxx',
    ]
    
    channels = []
    in_code_block = False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã¯ã‚¹ã‚­ãƒƒãƒ—
            if line.startswith('```'):
                in_code_block = not in_code_block
                continue
            if in_code_block:
                continue
            
            # URLã‚’å«ã‚€è¡Œã‚’æŠ½å‡º
            if 'youtube.com' in line or line.startswith('UC'):
                # ã‚µãƒ³ãƒ—ãƒ«URLã‚’é™¤å¤–
                if any(pattern in line for pattern in exclude_patterns):
                    continue
                
                # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡º
                url_match = re.search(r'https?://[^\s\)]+', line)
                if url_match:
                    channels.append(url_match.group(0))
                elif line.startswith('UC') and 'xxxx' not in line:
                    channels.append(line)
    
    return channels


def is_video_processed(video_id, output_dir):
    """å‹•ç”»ãŒæ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰"""
    if not output_dir:
        return False
    
    processed_file = os.path.join(output_dir, 'processed_videos.json')
    
    if not os.path.exists(processed_file):
        return False
    
    try:
        with open(processed_file, 'r', encoding='utf-8') as f:
            processed = json.load(f)
        return video_id in processed.get('video_ids', [])
    except (json.JSONDecodeError, IOError):
        return False


def mark_video_processed(video_id, output_dir, video_info=None):
    """å‹•ç”»ã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦è¨˜éŒ²"""
    if not output_dir:
        return
    
    os.makedirs(output_dir, exist_ok=True)
    processed_file = os.path.join(output_dir, 'processed_videos.json')
    
    # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    processed = {'video_ids': [], 'details': {}}
    if os.path.exists(processed_file):
        try:
            with open(processed_file, 'r', encoding='utf-8') as f:
                processed = json.load(f)
        except (json.JSONDecodeError, IOError):
            pass
    
    # video_idsãƒªã‚¹ãƒˆã«è¿½åŠ 
    if video_id not in processed.get('video_ids', []):
        if 'video_ids' not in processed:
            processed['video_ids'] = []
        processed['video_ids'].append(video_id)
    
    # è©³ç´°æƒ…å ±ã‚‚ä¿å­˜
    if 'details' not in processed:
        processed['details'] = {}
    
    processed['details'][video_id] = {
        'processed_at': datetime.now().isoformat(),
        'title': video_info.get('title', '') if video_info else '',
        'channel': video_info.get('channel', '') if video_info else ''
    }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(processed_file, 'w', encoding='utf-8') as f:
        json.dump(processed, f, ensure_ascii=False, indent=2)


def get_video_id(url_or_id):
    """YouTubeã®URLã¾ãŸã¯IDã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º"""
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:embed\/)([0-9A-Za-z_-]{11})',
        r'^([0-9A-Za-z_-]{11})$'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url_or_id)
        if match:
            return match.group(1)
    return None


def get_video_info(video_id):
    """YouTube Data APIã§å‹•ç”»æƒ…å ±ã‚’å–å¾—"""
    if not YOUTUBE_API_KEY:
        return None
    
    try:
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        request = youtube.videos().list(
            part='snippet,statistics',
            id=video_id
        )
        response = request.execute()
        
        if response['items']:
            item = response['items'][0]
            return {
                'title': item['snippet']['title'],
                'channel': item['snippet']['channelTitle'],
                'published_at': item['snippet']['publishedAt'],
                'description': item['snippet']['description'],
                'view_count': item['statistics'].get('viewCount', 'N/A'),
                'like_count': item['statistics'].get('likeCount', 'N/A')
            }
    except Exception as e:
        print(f"å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
    
    return None


def get_transcript(video_id):
    """å‹•ç”»ã®å­—å¹•ã‚’å–å¾—"""
    try:
        api = YouTubeTranscriptApi()
        transcript_data = api.fetch(video_id, languages=['en'])
        return transcript_data, 'en'
    except Exception as e:
        try:
            api = YouTubeTranscriptApi()
            transcript_data = api.fetch(video_id)
            return transcript_data, 'auto'
        except Exception as e2:
            print(f"å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e2}")
            return None, None


def format_transcript(transcript_data):
    """å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢"""
    text = ""
    for entry in transcript_data:
        if hasattr(entry, 'text'):
            text += entry.text + " "
        elif isinstance(entry, dict):
            text += entry.get('text', '') + " "
        else:
            text += str(entry) + " "
    
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def create_summary_sections(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†å‰²"""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    sections = []
    current_section = []
    
    for i, sentence in enumerate(sentences):
        current_section.append(sentence)
        if (i + 1) % 5 == 0 or i == len(sentences) - 1:
            sections.append(' '.join(current_section))
            current_section = []
    
    return sections


def translate_section_title(index):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã‚’å†…å®¹ã«å¿œã˜ãŸæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã«"""
    titles = [
        "å°å…¥", "èƒŒæ™¯ãƒ»æ¦‚è¦", "ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ", "è©³ç´°èª¬æ˜",
        "å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢", "æŠ€è¡“çš„è©³ç´°", "å¿œç”¨ä¾‹", "è€ƒå¯Ÿ",
        "ã¾ã¨ã‚", "çµè«–", "è¿½åŠ æƒ…å ±", "è£œè¶³"
    ]
    if index < len(titles):
        return titles[index]
    return f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {index + 1}"


def get_section_emoji(index):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«é©åˆ‡ãªçµµæ–‡å­—ã‚’å‰²ã‚Šå½“ã¦"""
    emojis = [
        "ğŸ¬", "ğŸ“‹", "â­", "ğŸ“", "ğŸ’¡", "ğŸ”§", "ğŸ¯", "ğŸ’­",
        "ğŸ“Œ", "âœ…", "ğŸ“š", "ğŸ”–", "ğŸ¨", "ğŸš€", "âš¡", "ğŸŒŸ"
    ]
    return emojis[index % len(emojis)]


def create_markdown_article(video_id, transcript_text, url, video_info=None):
    """Markdownå½¢å¼ã®è¨˜äº‹ã‚’ç”Ÿæˆï¼ˆè£…é£¾ç‰ˆï¼‰"""
    today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    # å‹•ç”»æƒ…å ±
    title = video_info['title'] if video_info else f"Video ID: {video_id}"
    channel = video_info['channel'] if video_info else "Unknown Channel"
    
    # å…¬é–‹æ—¥æ™‚ã‚’å–å¾—
    published_date = ""
    if video_info and 'published_at' in video_info:
        published_at = video_info['published_at']
        pub_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
        jst = pytz.timezone('Asia/Tokyo')
        pub_date_jst = pub_date.astimezone(jst)
        published_date = pub_date_jst.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
    
    markdown = f"""# ğŸ“º {title}

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: {title}
- **ãƒãƒ£ãƒ³ãƒãƒ«**: {channel}
- **å‹•ç”»URL**: [{url}]({url})
- **å‹•ç”»ID**: {video_id}
"""
    
    if published_date:
        markdown += f"- **å…¬é–‹æ—¥**: {published_date}\n"

    if video_info:
        view_count = int(video_info['view_count']) if video_info['view_count'] != 'N/A' else 0
        like_count = int(video_info['like_count']) if video_info['like_count'] != 'N/A' else 0
        markdown += f"""- **å†ç”Ÿå›æ•°**: {view_count:,} å›
- **é«˜è©•ä¾¡æ•°**: {like_count:,}
"""

    markdown += """
## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

"""
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
    sections = create_summary_sections(transcript_text)
    
    for i, section in enumerate(sections):
        emoji = get_section_emoji(i)
        section_title = translate_section_title(i)
        markdown += f"### {emoji} {section_title}\n\n"
        markdown += f"{section}\n\n"
    
    markdown += f"""---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: {today}

</div>
"""
    
    return markdown


def calculate_quality_score(transcript_text, sections):
    """è¦ç´„è¨˜äº‹ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    score = 100
    
    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    if len(transcript_text) < 500:
        score -= 30
    elif len(transcript_text) < 1000:
        score -= 10
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°ãƒã‚§ãƒƒã‚¯
    if len(sections) < 3:
        score -= 20
    
    # å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—ãŒå¤šã„å ´åˆï¼‰
    words = transcript_text.lower().split()
    unique_ratio = len(set(words)) / len(words) if words else 0
    if unique_ratio < 0.3:
        score -= 20
    
    return max(0, score)


def auto_commit_and_push(file_path, video_info):
    """ç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«git commit & push"""
    try:
        # git add
        subprocess.run(['git', 'add', file_path], check=True, capture_output=True)
        
        # ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        title = video_info['title'][:50] if video_info else "YouTubeè¦ç´„"
        channel = video_info['channel'] if video_info else "Unknown"
        commit_msg = f"ğŸ“ è¦ç´„è¿½åŠ : {title}\n\nãƒãƒ£ãƒ³ãƒãƒ«: {channel}"
        
        # git commit
        result = subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # ã‚³ãƒŸãƒƒãƒˆæ¸ˆã¿ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼
            if 'nothing to commit' in result.stdout:
                print("  â„¹ï¸  å¤‰æ›´ãªã—ï¼ˆæ—¢ã«ã‚³ãƒŸãƒƒãƒˆæ¸ˆã¿ï¼‰")
                return False
            else:
                print(f"  âš ï¸  ã‚³ãƒŸãƒƒãƒˆå¤±æ•—: {result.stderr}")
                return False
        
        print("  âœ“ ã‚³ãƒŸãƒƒãƒˆå®Œäº†")
        
        # git push
        print("  ğŸ“¤ ãƒ—ãƒƒã‚·ãƒ¥ä¸­...")
        push_result = subprocess.run(
            ['git', 'push'],
            capture_output=True,
            text=True
        )
        
        if push_result.returncode == 0:
            print("  âœ“ ãƒ—ãƒƒã‚·ãƒ¥å®Œäº† - Copilotãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã¾ã™")
            return True
        else:
            print(f"  âš ï¸  ãƒ—ãƒƒã‚·ãƒ¥å¤±æ•—: {push_result.stderr}")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"  âœ— Gitæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
        return False
    except FileNotFoundError:
        print("  âœ— gitã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False


def main(video_url, output_dir=None, auto_push=False):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"å‹•ç”»ã‚’å‡¦ç†ä¸­: {video_url}")
    
    # å‹•ç”»IDã‚’å–å¾—
    video_id = get_video_id(video_url)
    if not video_id:
        print("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªYouTube URLã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return None
    
    print(f"å‹•ç”»ID: {video_id}")
    
    # å‹•ç”»æƒ…å ±ã‚’å–å¾—
    print("å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")
    video_info = get_video_info(video_id)
    if video_info:
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {video_info['title']}")
        print(f"ãƒãƒ£ãƒ³ãƒãƒ«: {video_info['channel']}")
    
    # å­—å¹•ã‚’å–å¾—
    print("å­—å¹•ã‚’å–å¾—ä¸­...")
    transcript_data, lang = get_transcript(video_id)
    
    if not transcript_data:
        print("ã‚¨ãƒ©ãƒ¼: å­—å¹•ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    print(f"å­—å¹•ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆè¨€èª: {lang}ï¼‰")
    
    # ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
    transcript_text = format_transcript(transcript_data)
    print(f"ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é•·ã•: {len(transcript_text)} æ–‡å­—")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
    sections = create_summary_sections(transcript_text)
    
    # ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢è¨ˆç®—
    quality_score = calculate_quality_score(transcript_text, sections)
    print(f"ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {quality_score}/100")
    
    # Markdownè¨˜äº‹ã‚’ç”Ÿæˆ
    markdown_content = create_markdown_article(
        video_id, transcript_text, video_url, video_info
    )
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        
        if video_info:
            # æŠ•ç¨¿æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            published_at = video_info['published_at']
            # ISO 8601å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹ (ä¾‹: 2024-12-15T03:20:00Z)
            pub_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            
            # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
            jst = pytz.timezone('Asia/Tokyo')
            pub_date_jst = pub_date.astimezone(jst)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— (å¹´æœˆæ—¥æ™‚åˆ†)
            timestamp = pub_date_jst.strftime('%Y%m%d%H%M')
            
            # ãƒãƒ£ãƒ³ãƒãƒ«åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼ˆå®‰å…¨ãªæ–‡å­—ã®ã¿ï¼‰
            safe_channel = re.sub(r'[^\w\s-]', '', video_info['channel'])
            safe_channel = re.sub(r'[-\s]+', '_', safe_channel)
            
            # å¹´/æœˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
            year = pub_date_jst.strftime('%Y')
            month = pub_date_jst.strftime('%m')
            dir_path = os.path.join(output_dir, year, month)
            os.makedirs(dir_path, exist_ok=True)
            
            output_file = os.path.join(dir_path, f"{timestamp}_{safe_channel}.md")
        else:
            output_file = os.path.join(output_dir, f"summary_{video_id}.md")
    else:
        output_file = f"summary_{video_id}.md"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"âœ“ è¦ç´„è¨˜äº‹ã‚’ä½œæˆã—ã¾ã—ãŸ: {output_file}")
    
    # å‡¦ç†æ¸ˆã¿ã¨ã—ã¦è¨˜éŒ²
    mark_video_processed(video_id, output_dir, video_info)
    
    result = {
        'file_path': output_file,
        'quality_score': quality_score,
        'video_id': video_id,
        'video_info': video_info
    }
    
    # è‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆ
    if auto_push:
        print("\nğŸ”„ Gitæ“ä½œã‚’å®Ÿè¡Œä¸­...")
        auto_commit_and_push(output_file, video_info)
    
    return result


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹:")
        print("  å˜ä¸€å‹•ç”»: python improved_summarize_youtube.py <YouTube URL> [å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª] [--push]")
        print("  ãƒãƒ£ãƒ³ãƒãƒ«: python improved_summarize_youtube.py --channel <Channel URL> [--limit N] [å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª] [--push]")
        print("  ãƒªã‚¹ãƒˆã‹ã‚‰: python improved_summarize_youtube.py --from-list [--limit N] [å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª] [--push]")
        print("\nã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
        print("  --channel <URL>  æŒ‡å®šãƒãƒ£ãƒ³ãƒãƒ«ã®æœ€æ–°å‹•ç”»ã‚’å‡¦ç†")
        print("  --from-list      channel-list.mdã®å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å‡¦ç†")
        print("  --limit N        å–å¾—ã™ã‚‹å‹•ç”»æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰")
        print("  --push           ç”Ÿæˆå¾Œã«è‡ªå‹•çš„ã«git commit & push")
        print("\nä¾‹:")
        print("  python improved_summarize_youtube.py --channel https://www.youtube.com/@AllAboutAI --limit 1 xserver/summaries --push")
        print("  python improved_summarize_youtube.py --from-list --limit 5 xserver/summaries")
        sys.exit(1)
    
    # å¼•æ•°è§£æ
    mode = 'single'  # single, channel, list
    video_url = None
    channel_url = None
    output_dir = None
    auto_push = False
    limit = 10
    
    i = 1
    while i < len(sys.argv):
        arg = sys.argv[i]
        
        if arg == '--channel':
            mode = 'channel'
            if i + 1 < len(sys.argv):
                channel_url = sys.argv[i + 1]
                i += 2
            else:
                print("ã‚¨ãƒ©ãƒ¼: --channel ã«ã¯URLãŒå¿…è¦ã§ã™")
                sys.exit(1)
        elif arg == '--from-list':
            mode = 'list'
            i += 1
        elif arg == '--limit':
            if i + 1 < len(sys.argv):
                limit = int(sys.argv[i + 1])
                i += 2
            else:
                print("ã‚¨ãƒ©ãƒ¼: --limit ã«ã¯æ•°å€¤ãŒå¿…è¦ã§ã™")
                sys.exit(1)
        elif arg == '--push':
            auto_push = True
            i += 1
        elif not arg.startswith('--'):
            if mode == 'single' and not video_url:
                video_url = arg
            else:
                output_dir = arg
            i += 1
        else:
            i += 1
    
    # ãƒ¢ãƒ¼ãƒ‰åˆ¥å‡¦ç†
    if mode == 'single':
        # å˜ä¸€å‹•ç”»å‡¦ç†
        if not video_url:
            print("ã‚¨ãƒ©ãƒ¼: å‹•ç”»URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            sys.exit(1)
        
        result = main(video_url, output_dir, auto_push)
        
        if result and result['quality_score'] < 50:
            print(f"\nâš ï¸  è­¦å‘Š: ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ ({result['quality_score']}/100)")
            print("æ‰‹å‹•ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    
    elif mode == 'channel':
        # ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰æœ€æ–°å‹•ç”»ã‚’å‡¦ç†
        if not channel_url:
            print("ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ãƒãƒ«URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            sys.exit(1)
        
        print(f"\nğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰æœ€æ–°{limit}ä»¶ã®å‹•ç”»ã‚’å–å¾—ä¸­...")
        print(f"ãƒãƒ£ãƒ³ãƒãƒ«: {channel_url}\n")
        
        channel_id = get_channel_id(channel_url)
        if not channel_id:
            print("ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            sys.exit(1)
        
        print(f"ãƒãƒ£ãƒ³ãƒãƒ«ID: {channel_id}")
        
        videos = get_channel_latest_videos(channel_id, limit, output_dir)
        if not videos:
            print("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            sys.exit(1)
        
        print(f"\nå–å¾—ã—ãŸå‹•ç”»: {len(videos)}ä»¶\n")
        
        processed_count = 0
        skipped_count = 0
        failed_count = 0
        
        for i, video in enumerate(videos, 1):
            print(f"\n{'='*60}")
            print(f"[{i}/{len(videos)}] å‡¦ç†ä¸­: {video['title']}")
            print(f"{'='*60}")
            
            # æ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
            if output_dir and is_video_processed(video['video_id'], output_dir):
                print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™")
                skipped_count += 1
                continue
            
            result = main(video['url'], output_dir, auto_push)
            
            if result:
                processed_count += 1
                if result['quality_score'] < 50:
                    print(f"âš ï¸  ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ä½: {result['quality_score']}/100")
            else:
                failed_count += 1
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å‡¦ç†å®Œäº†")
        print(f"{'='*60}")
        print(f"âœ… å‡¦ç†æˆåŠŸ: {processed_count}ä»¶")
        print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
        print(f"âŒ å¤±æ•—: {failed_count}ä»¶")
        print(f"åˆè¨ˆ: {len(videos)}ä»¶")
    
    elif mode == 'list':
        # channel-list.mdã‹ã‚‰å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®å‹•ç”»ã‚’åé›†ã—ã€æ–°ã—ã„é †ã«å‡¦ç†
        print(f"\nğŸ“‹ channel-list.mdã‹ã‚‰å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å‡¦ç†ä¸­...\n")
        
        channels = parse_channel_list()
        if not channels:
            print("ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            sys.exit(1)
        
        print(f"ç™»éŒ²ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(channels)}ä»¶")
        print(f"å–å¾—ä»¶æ•°: å…¨ãƒãƒ£ãƒ³ãƒãƒ«åˆè¨ˆã§æœ€æ–°{limit}ä»¶\n")
        
        # å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å‹•ç”»ã‚’åé›†
        all_videos = []
        
        for ch_idx, channel_url in enumerate(channels, 1):
            print(f"[{ch_idx}/{len(channels)}] ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å‹•ç”»ã‚’å–å¾—ä¸­: {channel_url}")
            
            channel_id = get_channel_id(channel_url)
            if not channel_id:
                print("  âš ï¸  ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            # å„ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å¤šã‚ã«å–å¾—ï¼ˆæœ€å¤§50ä»¶ï¼‰
            videos = get_channel_latest_videos(channel_id, 50, output_dir)
            if videos:
                for video in videos:
                    video['channel_url'] = channel_url  # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’è¿½åŠ 
                all_videos.extend(videos)
                print(f"  âœ“ {len(videos)}ä»¶ã®æœªå‡¦ç†å‹•ç”»ã‚’å–å¾—")
            else:
                print(f"  â„¹ï¸  æœªå‡¦ç†å‹•ç”»ãªã—")
        
        if not all_videos:
            print("\nå…¨ãƒãƒ£ãƒ³ãƒãƒ«ã§æœªå‡¦ç†ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            sys.exit(0)
        
        # å…¬é–‹æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        all_videos.sort(key=lambda x: x['published_at'], reverse=True)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š åé›†çµæœ")
        print(f"{'='*60}")
        print(f"å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åé›†ã—ãŸæœªå‡¦ç†å‹•ç”»: {len(all_videos)}ä»¶")
        print(f"ã“ã‚Œã‹ã‚‰å‡¦ç†ã™ã‚‹å‹•ç”»: {min(limit, len(all_videos))}ä»¶")
        print(f"{'='*60}\n")
        
        # ä¸Šä½limitä»¶ã ã‘ã‚’å‡¦ç†
        total_processed = 0
        total_failed = 0
        
        for i, video in enumerate(all_videos[:limit], 1):
            print(f"\n{'='*60}")
            print(f"[{i}/{min(limit, len(all_videos))}] å‡¦ç†ä¸­")
            print(f"{'='*60}")
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {video['title']}")
            print(f"å…¬é–‹æ—¥: {video['published_at']}")
            print(f"å‹•ç”»URL: {video['url']}")
            
            result = main(video['url'], output_dir, auto_push)
            
            if result:
                total_processed += 1
            else:
                total_failed += 1
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ å…¨ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†å®Œäº†")
        print(f"{'='*60}")
        print(f"âœ… å‡¦ç†æˆåŠŸ: {total_processed}ä»¶")
        print(f"âŒ å¤±æ•—: {total_failed}ä»¶")
