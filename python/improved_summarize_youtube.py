"""
YouTubeå‹•ç”»ã‚’è¦ç´„è¨˜äº‹ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
æ—¥æœ¬èªåŒ–ã¨è£…é£¾ã‚’è‡ªå‹•ã§è¡Œã„ã¾ã™
"""
import sys
import os
import re
from datetime import datetime
from youtube_transcript_api import YouTubeTranscriptApi
from googleapiclient.discovery import build
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')


def get_video_id(url_or_id):
    """YouTubeã®URLã¾ãŸã¯IDã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º"""
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:embed\/)([0-9A-Za-z_-]{11})',
        r'^([0-9A-Za-z_-]{11})$'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url_or_id)
        if match:
            return match.group(1)
    return None


def get_video_info(video_id):
    """YouTube Data APIã§å‹•ç”»æƒ…å ±ã‚’å–å¾—"""
    if not YOUTUBE_API_KEY:
        return None
    
    try:
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        request = youtube.videos().list(
            part='snippet,statistics',
            id=video_id
        )
        response = request.execute()
        
        if response['items']:
            item = response['items'][0]
            return {
                'title': item['snippet']['title'],
                'channel': item['snippet']['channelTitle'],
                'published_at': item['snippet']['publishedAt'],
                'description': item['snippet']['description'],
                'view_count': item['statistics'].get('viewCount', 'N/A'),
                'like_count': item['statistics'].get('likeCount', 'N/A')
            }
    except Exception as e:
        print(f"å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
    
    return None


def get_transcript(video_id):
    """å‹•ç”»ã®å­—å¹•ã‚’å–å¾—"""
    try:
        api = YouTubeTranscriptApi()
        transcript_data = api.fetch(video_id, languages=['en'])
        return transcript_data, 'en'
    except Exception as e:
        try:
            api = YouTubeTranscriptApi()
            transcript_data = api.fetch(video_id)
            return transcript_data, 'auto'
        except Exception as e2:
            print(f"å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e2}")
            return None, None


def format_transcript(transcript_data):
    """å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢"""
    text = ""
    for entry in transcript_data:
        if hasattr(entry, 'text'):
            text += entry.text + " "
        elif isinstance(entry, dict):
            text += entry.get('text', '') + " "
        else:
            text += str(entry) + " "
    
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def create_summary_sections(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½ã«åˆ†å‰²"""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    sections = []
    current_section = []
    
    for i, sentence in enumerate(sentences):
        current_section.append(sentence)
        if (i + 1) % 5 == 0 or i == len(sentences) - 1:
            sections.append(' '.join(current_section))
            current_section = []
    
    return sections


def translate_section_title(index):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã‚’å†…å®¹ã«å¿œã˜ãŸæ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã«"""
    titles = [
        "å°å…¥", "èƒŒæ™¯ãƒ»æ¦‚è¦", "ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ", "è©³ç´°èª¬æ˜",
        "å®Ÿä¾‹ãƒ»ãƒ‡ãƒ¢", "æŠ€è¡“çš„è©³ç´°", "å¿œç”¨ä¾‹", "è€ƒå¯Ÿ",
        "ã¾ã¨ã‚", "çµè«–", "è¿½åŠ æƒ…å ±", "è£œè¶³"
    ]
    if index < len(titles):
        return titles[index]
    return f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {index + 1}"


def get_section_emoji(index):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«é©åˆ‡ãªçµµæ–‡å­—ã‚’å‰²ã‚Šå½“ã¦"""
    emojis = [
        "ğŸ¬", "ğŸ“‹", "â­", "ğŸ“", "ğŸ’¡", "ğŸ”§", "ğŸ¯", "ğŸ’­",
        "ğŸ“Œ", "âœ…", "ğŸ“š", "ğŸ”–", "ğŸ¨", "ğŸš€", "âš¡", "ğŸŒŸ"
    ]
    return emojis[index % len(emojis)]


def create_markdown_article(video_id, transcript_text, url, video_info=None):
    """Markdownå½¢å¼ã®è¨˜äº‹ã‚’ç”Ÿæˆï¼ˆè£…é£¾ç‰ˆï¼‰"""
    today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    # å‹•ç”»æƒ…å ±
    title = video_info['title'] if video_info else f"Video ID: {video_id}"
    channel = video_info['channel'] if video_info else "Unknown Channel"
    
    markdown = f"""# ğŸ“º YouTubeå‹•ç”»è¦ç´„

## ğŸ“‹ å‹•ç”»æƒ…å ±

- **ã‚¿ã‚¤ãƒˆãƒ«**: {title}
- **ãƒãƒ£ãƒ³ãƒãƒ«**: {channel}
- **å‹•ç”»URL**: [{url}]({url})
- **å‹•ç”»ID**: {video_id}
- **è¦ç´„ä½œæˆæ—¥**: {today}
"""

    if video_info:
        view_count = int(video_info['view_count']) if video_info['view_count'] != 'N/A' else 0
        like_count = int(video_info['like_count']) if video_info['like_count'] != 'N/A' else 0
        markdown += f"""- **å†ç”Ÿå›æ•°**: {view_count:,} å›
- **é«˜è©•ä¾¡æ•°**: {like_count:,}
"""

    markdown += """
## ğŸ’¡ æ¦‚è¦

ã“ã®è¨˜äº‹ã¯ã€YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã§ã™ã€‚

## â­ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

> ğŸ“Œ ã“ã®å‹•ç”»ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨ãƒã‚¤ãƒ³ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

## ğŸ“– è©³ç´°å†…å®¹

"""
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
    sections = create_summary_sections(transcript_text)
    
    for i, section in enumerate(sections):
        emoji = get_section_emoji(i)
        section_title = translate_section_title(i)
        markdown += f"### {emoji} {section_title}\n\n"
        markdown += f"{section}\n\n"
    
    markdown += f"""---

<div align="center">

**ğŸ“ ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™**

ç”Ÿæˆæ—¥: {today}

</div>
"""
    
    return markdown


def calculate_quality_score(transcript_text, sections):
    """è¦ç´„è¨˜äº‹ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    score = 100
    
    # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    if len(transcript_text) < 500:
        score -= 30
    elif len(transcript_text) < 1000:
        score -= 10
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°ãƒã‚§ãƒƒã‚¯
    if len(sections) < 3:
        score -= 20
    
    # å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—ãŒå¤šã„å ´åˆï¼‰
    words = transcript_text.lower().split()
    unique_ratio = len(set(words)) / len(words) if words else 0
    if unique_ratio < 0.3:
        score -= 20
    
    return max(0, score)


def main(video_url, output_dir=None):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"å‹•ç”»ã‚’å‡¦ç†ä¸­: {video_url}")
    
    # å‹•ç”»IDã‚’å–å¾—
    video_id = get_video_id(video_url)
    if not video_id:
        print("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªYouTube URLã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return None
    
    print(f"å‹•ç”»ID: {video_id}")
    
    # å‹•ç”»æƒ…å ±ã‚’å–å¾—
    print("å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")
    video_info = get_video_info(video_id)
    if video_info:
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {video_info['title']}")
        print(f"ãƒãƒ£ãƒ³ãƒãƒ«: {video_info['channel']}")
    
    # å­—å¹•ã‚’å–å¾—
    print("å­—å¹•ã‚’å–å¾—ä¸­...")
    transcript_data, lang = get_transcript(video_id)
    
    if not transcript_data:
        print("ã‚¨ãƒ©ãƒ¼: å­—å¹•ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    print(f"å­—å¹•ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆè¨€èª: {lang}ï¼‰")
    
    # ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
    transcript_text = format_transcript(transcript_data)
    print(f"ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é•·ã•: {len(transcript_text)} æ–‡å­—")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
    sections = create_summary_sections(transcript_text)
    
    # ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢è¨ˆç®—
    quality_score = calculate_quality_score(transcript_text, sections)
    print(f"ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {quality_score}/100")
    
    # Markdownè¨˜äº‹ã‚’ç”Ÿæˆ
    markdown_content = create_markdown_article(
        video_id, transcript_text, video_url, video_info
    )
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        
        if video_info:
            # æŠ•ç¨¿æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            from datetime import datetime
            published_at = video_info['published_at']
            # ISO 8601å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹ (ä¾‹: 2024-12-15T03:20:00Z)
            pub_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            
            # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
            import pytz
            jst = pytz.timezone('Asia/Tokyo')
            pub_date_jst = pub_date.astimezone(jst)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— (å¹´æœˆæ—¥æ™‚åˆ†)
            timestamp = pub_date_jst.strftime('%Y%m%d%H%M')
            
            # ãƒãƒ£ãƒ³ãƒãƒ«åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼ˆå®‰å…¨ãªæ–‡å­—ã®ã¿ï¼‰
            safe_channel = re.sub(r'[^\w\s-]', '', video_info['channel'])
            safe_channel = re.sub(r'[-\s]+', '_', safe_channel)
            
            # å¹´/æœˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
            year = pub_date_jst.strftime('%Y')
            month = pub_date_jst.strftime('%m')
            dir_path = os.path.join(output_dir, year, month)
            os.makedirs(dir_path, exist_ok=True)
            
            output_file = os.path.join(dir_path, f"{timestamp}_{safe_channel}.md")
        else:
            output_file = os.path.join(output_dir, f"summary_{video_id}.md")
    else:
        output_file = f"summary_{video_id}.md"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"âœ“ è¦ç´„è¨˜äº‹ã‚’ä½œæˆã—ã¾ã—ãŸ: {output_file}")
    
    return {
        'file_path': output_file,
        'quality_score': quality_score,
        'video_id': video_id,
        'video_info': video_info
    }


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python improved_summarize_youtube.py <YouTube URL> [å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª]")
        sys.exit(1)
    
    video_url = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = main(video_url, output_dir)
    
    if result and result['quality_score'] < 50:
        print(f"\nâš ï¸  è­¦å‘Š: ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ ({result['quality_score']}/100)")
        print("æ‰‹å‹•ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
